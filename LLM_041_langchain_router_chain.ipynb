{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/LLMs/blob/main/LLM_041_langchain_router_chain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "728f1747-b8fc-4d31-96c2-047fc83c079d",
      "metadata": {
        "id": "728f1747-b8fc-4d31-96c2-047fc83c079d"
      },
      "source": [
        "#  LLMRouterChain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain\n",
        "# !pip install openai\n",
        "# !pip install python-dotenv\n",
        "# !pip install langchain-openai"
      ],
      "metadata": {
        "id": "VYfUEnztGsmt"
      },
      "id": "VYfUEnztGsmt",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "import json\n",
        "import langchain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "# Load environment variables from .env file\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "# Set the environment variable globally for libraries like LangChain\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "# Print the API key to confirm it's loaded correctly\n",
        "print(\"API Key loaded from .env:\",os.environ[\"OPENAI_API_KEY\"][0:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQzkk2fNGvlC",
        "outputId": "eabd1cf9-5fe8-4bdb-96e7-6e48950957ef"
      },
      "id": "fQzkk2fNGvlC",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key loaded from .env: sk-proj-e1GUWruINPRnrozmiakkRM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34c70034-3204-41f7-af62-f25c9cc5a2de",
      "metadata": {
        "id": "34c70034-3204-41f7-af62-f25c9cc5a2de"
      },
      "source": [
        "### Route Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ddea86e7-9240-4369-a938-38aaff2c6d5a",
      "metadata": {
        "id": "ddea86e7-9240-4369-a938-38aaff2c6d5a"
      },
      "outputs": [],
      "source": [
        "beginner_template = '''You are a physics teacher who is really\n",
        "focused on beginners and explaining complex topics in simple to understand terms.\n",
        "You assume no prior knowledge. Here is the question\\n{input}'''\n",
        "\n",
        "expert_template = '''You are a world expert physics professor who explains physics topics\n",
        "to advanced audience members. You can assume anyone you answer has a\n",
        "PhD level understanding of Physics. Here is the question\\n{input}'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00f2c29f-dd15-4821-ac3a-2f5f6321b172",
      "metadata": {
        "id": "00f2c29f-dd15-4821-ac3a-2f5f6321b172"
      },
      "source": [
        "### Route Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1ad19090-69a5-481d-87cf-2d4c8119c3ca",
      "metadata": {
        "id": "1ad19090-69a5-481d-87cf-2d4c8119c3ca"
      },
      "outputs": [],
      "source": [
        "prompt_infos = [\n",
        "    {'name':'advanced physics','description': 'Answers advanced physics questions',\n",
        "     'prompt_template':expert_template},\n",
        "    {'name':'beginner physics','description': 'Answers basic beginner physics questions',\n",
        "     'prompt_template':beginner_template},\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92e7e03a-a8ed-4405-ae33-7770deccd0a9",
      "metadata": {
        "id": "92e7e03a-a8ed-4405-ae33-7770deccd0a9"
      },
      "source": [
        "### ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "184aefe6-0e02-402d-8172-4a44e78ac42d",
      "metadata": {
        "id": "184aefe6-0e02-402d-8172-4a44e78ac42d"
      },
      "outputs": [],
      "source": [
        "# Define the LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "aa78da93-c52d-4ea3-b680-7ae5c677b8c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa78da93-c52d-4ea3-b680-7ae5c677b8c5",
        "outputId": "7562453e-68bc-4021-a25d-8a2e0fa3609f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['advanced physics', 'beginner physics'])\n"
          ]
        }
      ],
      "source": [
        "destination_chains = {}\n",
        "for p_info in prompt_infos:\n",
        "    name = p_info[\"name\"]\n",
        "    prompt_template = p_info[\"prompt_template\"]\n",
        "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    destination_chains[name] = chain\n",
        "\n",
        "print(destination_chains.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Destination Chains"
      ],
      "metadata": {
        "id": "-ooRuw_VMPcB"
      },
      "id": "-ooRuw_VMPcB"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cfabfe49-a9dc-4d0e-9e40-bfc042719487",
      "metadata": {
        "id": "cfabfe49-a9dc-4d0e-9e40-bfc042719487"
      },
      "outputs": [],
      "source": [
        "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
        "default_chain = LLMChain(llm=llm,prompt=default_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15856b11-d9ab-4a7a-b7af-6f4726ab0d2d",
      "metadata": {
        "id": "15856b11-d9ab-4a7a-b7af-6f4726ab0d2d"
      },
      "source": [
        "### Multi Routing Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9bd303e5-44b1-424d-93e6-7340d24cfb48",
      "metadata": {
        "id": "9bd303e5-44b1-424d-93e6-7340d24cfb48"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "548eae05-4292-48a0-8147-1b4d1fb0433b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "548eae05-4292-48a0-8147-1b4d1fb0433b",
        "outputId": "ce4a7ed6-45f4-4fdc-d4f3-63ee8ba9e7be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
            "\n",
            "<< FORMATTING >>\n",
            "Return a markdown code snippet with a JSON object formatted to look like:\n",
            "```json\n",
            "{{{{\n",
            "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
            "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
            "}}}}\n",
            "```\n",
            "\n",
            "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
            "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
            "\n",
            "<< CANDIDATE PROMPTS >>\n",
            "{destinations}\n",
            "\n",
            "<< INPUT >>\n",
            "{{input}}\n",
            "\n",
            "<< OUTPUT (must include ```json at the start of the response) >>\n",
            "<< OUTPUT (must end with ```) >>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1152ed30-7c5e-46ec-bd9f-8fa2ff42950e",
      "metadata": {
        "id": "1152ed30-7c5e-46ec-bd9f-8fa2ff42950e"
      },
      "source": [
        "### Routing Destinations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "635cbf1e-52ce-4d26-a25f-ddc81fa21340",
      "metadata": {
        "id": "635cbf1e-52ce-4d26-a25f-ddc81fa21340"
      },
      "outputs": [],
      "source": [
        "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
        "destinations_str = \"\\n\".join(destinations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7ac5f3a0-32e7-45a5-8564-b433d42eeeb2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ac5f3a0-32e7-45a5-8564-b433d42eeeb2",
        "outputId": "1c9388ca-2291-4d20-84f6-d4bb173f8cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "advanced physics: Answers advanced physics questions\n",
            "beginner physics: Answers basic beginner physics questions\n"
          ]
        }
      ],
      "source": [
        "print(destinations_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c9c0879-3d03-4b2b-b98b-1476a809ed25",
      "metadata": {
        "id": "4c9c0879-3d03-4b2b-b98b-1476a809ed25"
      },
      "source": [
        "### Router Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7dbfd595-c65a-49e6-91f6-026528f58e3f",
      "metadata": {
        "id": "7dbfd595-c65a-49e6-91f6-026528f58e3f"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "fefd428a-059e-41ba-b49e-b0016b72541b",
      "metadata": {
        "id": "fefd428a-059e-41ba-b49e-b0016b72541b"
      },
      "outputs": [],
      "source": [
        "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
        "    destinations=destinations_str\n",
        ")\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,\n",
        "    input_variables=[\"input\"],\n",
        "    output_parser=RouterOutputParser(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "cf19d2c3-0bbb-4a0d-8d69-ac177e814afa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf19d2c3-0bbb-4a0d-8d69-ac177e814afa",
        "outputId": "ea13beaf-a319-46a8-96d3-b3920c384e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
            "\n",
            "<< FORMATTING >>\n",
            "Return a markdown code snippet with a JSON object formatted to look like:\n",
            "```json\n",
            "{{\n",
            "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
            "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
            "}}\n",
            "```\n",
            "\n",
            "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
            "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
            "\n",
            "<< CANDIDATE PROMPTS >>\n",
            "advanced physics: Answers advanced physics questions\n",
            "beginner physics: Answers basic beginner physics questions\n",
            "\n",
            "<< INPUT >>\n",
            "{input}\n",
            "\n",
            "<< OUTPUT (must include ```json at the start of the response) >>\n",
            "<< OUTPUT (must end with ```) >>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(router_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd4ba041-a4fe-425d-a6e7-0d357dae6ef6",
      "metadata": {
        "id": "fd4ba041-a4fe-425d-a6e7-0d357dae6ef6"
      },
      "source": [
        "### Routing Chain Call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d1a82b26-438a-4882-bcdd-aa7548f4f961",
      "metadata": {
        "id": "d1a82b26-438a-4882-bcdd-aa7548f4f961"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "4100748e-75a5-4e40-998d-a3a959d9a58f",
      "metadata": {
        "id": "4100748e-75a5-4e40-998d-a3a959d9a58f"
      },
      "outputs": [],
      "source": [
        "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "1e5600e9-f60f-466c-8321-ec2f32e0cbf1",
      "metadata": {
        "id": "1e5600e9-f60f-466c-8321-ec2f32e0cbf1"
      },
      "outputs": [],
      "source": [
        "chain = MultiPromptChain(router_chain=router_chain,\n",
        "                         destination_chains=destination_chains,\n",
        "                         default_chain=default_chain, verbose=True\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1a77635b-b475-4bdf-bb35-d0ca5983911d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a77635b-b475-4bdf-bb35-d0ca5983911d",
        "outputId": "33145333-3c1a-4e8b-e64f-9dd722d46e89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "beginner physics: {'input': 'How do magnets work?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'How do magnets work?',\n",
              " 'text': \"Great question! Let's break it down in simple terms.\\n\\n### What Are Magnets?\\n\\nMagnets are objects that can attract (pull) or repel (push away) certain materials, like iron. You might have seen them in action when they stick to your fridge or when they hold papers together.\\n\\n### What Makes a Magnet?\\n\\n1. **Atoms and Electrons**: Everything around us is made up of tiny particles called atoms. Atoms have smaller particles inside them, called electrons. These electrons move around the atom, and this movement creates tiny magnetic fields.\\n\\n2. **Magnetic Domains**: In most materials, the magnetic fields of the atoms point in all different directions, and they cancel each other out. But in magnets, many of these tiny magnetic fields line up in the same direction. When enough of them align, the material becomes a magnet.\\n\\n### How Do Magnets Work?\\n\\n1. **Poles**: Every magnet has two ends called poles: a north pole and a south pole. The north pole of one magnet will attract the south pole of another magnet, and vice versa. However, if you try to bring two north poles or two south poles together, they will push away from each other. This is called repulsion.\\n\\n2. **Magnetic Field**: Magnets create an invisible area around them called a magnetic field. This field is what allows them to attract or repel other magnetic objects. You can think of the magnetic field like an invisible force field that extends out into the space around the magnet.\\n\\n### Why Do Some Materials Get Attracted?\\n\\nOnly certain materials, like iron, nickel, and cobalt, are attracted to magnets. These materials have a special structure that allows their atoms to line up and create a magnetic field when exposed to a magnet.\\n\\n### Summary\\n\\n- **Magnets attract and repel certain materials** based on their magnetic poles.\\n- **Atoms and their electrons** create tiny magnetic fields, and in magnets, these fields align to create a stronger magnetic field.\\n- **The magnetic field** is what allows magnets to interact with other magnetic materials.\\n\\nSo, in short, magnets work because of the special arrangement of atoms within them, allowing them to create and exert forces on certain materials around them! If you have more questions about magnets or anything else, feel free to ask!\"}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "chain.invoke(\"How do magnets work?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full Code\n",
        "\n",
        "### **Explanation of What the Code is Doing**\n",
        "\n",
        "1. **Templates for Task-Specific Responses**:\n",
        "   - Two templates (`beginner_template` and `expert_template`) are defined for answering physics questions tailored to different audiences:\n",
        "     - Beginner: Simplified, no prior knowledge required.\n",
        "     - Advanced: Detailed and assumes expertise.\n",
        "\n",
        "2. **Destination Chains**:\n",
        "   - Each prompt template is turned into a task-specific chain using `LLMChain`.\n",
        "   - These chains are stored in a dictionary (`destination_chains`) and keyed by their respective task names (`beginner physics`, `advanced physics`).\n",
        "\n",
        "3. **Default Chain**:\n",
        "   - A fallback chain handles inputs that don’t match any specific task. This uses a generic prompt.\n",
        "\n",
        "4. **Router Template**:\n",
        "   - The `MULTI_PROMPT_ROUTER_TEMPLATE` provides the structure for how the LLM decides the appropriate chain for an input.\n",
        "   - It lists available task descriptions and dynamically evaluates which task the input belongs to.\n",
        "\n",
        "5. **Router Chain**:\n",
        "   - Uses the router prompt and LLM to classify inputs and map them to a specific destination chain (e.g., \"advanced physics\").\n",
        "   - Outputs the task name corresponding to the most relevant chain.\n",
        "\n",
        "6. **MultiPromptChain**:\n",
        "   - Combines the router chain, destination chains, and default chain.\n",
        "   - It routes inputs dynamically to the correct chain and executes the associated task.\n",
        "\n",
        "7. **Invocation**:\n",
        "   - The `invoke` method is called with a question: `\"How do magnets work?\"`\n",
        "   - The router determines if the question is for a beginner or advanced audience and forwards it to the appropriate chain.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Concepts and Lessons**\n",
        "1. **Dynamic Task Routing**:\n",
        "   - The router chain ensures inputs are processed by the correct chain dynamically.\n",
        "2. **Separation of Logic**:\n",
        "   - Task-specific chains are modular and reusable.\n",
        "3. **Scalability**:\n",
        "   - New tasks or chains can be easily added by extending the `prompt_infos` list.\n",
        "4. **Fallback Mechanism**:\n",
        "   - The default chain ensures robustness when no specific task matches the input.\n"
      ],
      "metadata": {
        "id": "4JLWsapeO-xC"
      },
      "id": "4JLWsapeO-xC"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
        "\n",
        "# Define a template for beginners' questions\n",
        "beginner_template = '''You are a physics teacher who is really\n",
        "focused on beginners and explaining complex topics in simple to understand terms.\n",
        "You assume no prior knowledge. Here is the question\\n{input}'''\n",
        "\n",
        "# Define a template for advanced questions\n",
        "expert_template = '''You are a world expert physics professor who explains physics topics\n",
        "to advanced audience members. You can assume anyone you answer has a\n",
        "PhD level understanding of Physics. Here is the question\\n{input}'''\n",
        "\n",
        "# List of prompt configurations for different levels of physics questions\n",
        "prompt_infos = [\n",
        "    {\n",
        "        'name': 'advanced physics',  # Identifier for advanced questions\n",
        "        'description': 'Answers advanced physics questions',  # Task description\n",
        "        'prompt_template': expert_template  # Associated prompt template\n",
        "    },\n",
        "    {\n",
        "        'name': 'beginner physics',  # Identifier for beginner questions\n",
        "        'description': 'Answers basic beginner physics questions',  # Task description\n",
        "        'prompt_template': beginner_template  # Associated prompt template\n",
        "    },\n",
        "]\n",
        "\n",
        "# Step 1: Initialize the Language Model (LLM)\n",
        "# The ChatOpenAI instance specifies the model and behavior (temperature controls creativity)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "\n",
        "# Step 2: Create chains for each prompt configuration\n",
        "# Initialize an empty dictionary to store chains for each task\n",
        "destination_chains = {}\n",
        "\n",
        "# Loop through the prompt configurations and create a chain for each\n",
        "for p_info in prompt_infos:\n",
        "    name = p_info[\"name\"]  # Retrieve the task name (e.g., \"advanced physics\")\n",
        "    prompt_template = p_info[\"prompt_template\"]  # Retrieve the corresponding prompt template\n",
        "    prompt = ChatPromptTemplate.from_template(template=prompt_template)  # Create a ChatPromptTemplate\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)  # Create an LLMChain using the prompt and LLM\n",
        "    destination_chains[name] = chain  # Store the chain in the dictionary with the task name as the key\n",
        "\n",
        "# Step 3: Define a default prompt and chain\n",
        "# This is used if no specific task is matched during routing\n",
        "default_prompt = ChatPromptTemplate.from_template(\"{input}\")  # Basic template for fallback\n",
        "default_chain = LLMChain(llm=llm, prompt=default_prompt)  # Create the fallback chain\n",
        "\n",
        "# Step 4: Print the Multi-Prompt Router Template\n",
        "# This template is used to dynamically decide which chain to use based on input\n",
        "print(MULTI_PROMPT_ROUTER_TEMPLATE)\n",
        "\n",
        "# Generate a string listing all available task destinations with descriptions\n",
        "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
        "destinations_str = \"\\n\".join(destinations)  # Combine all destinations into a formatted string\n",
        "print(destinations_str)  # Print the formatted string for debugging or review\n",
        "\n",
        "# Import additional utilities for the router chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
        "\n",
        "# Step 5: Create a router prompt\n",
        "# This prompt is used by the LLM to decide which chain should handle the input\n",
        "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
        "    destinations=destinations_str  # Insert the destination descriptions into the router template\n",
        ")\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,  # Use the formatted router template\n",
        "    input_variables=[\"input\"],  # Input to be classified\n",
        "    output_parser=RouterOutputParser(),  # Parse the LLM's classification result\n",
        ")\n",
        "\n",
        "# Print the router template for debugging\n",
        "print(router_template)\n",
        "\n",
        "# Step 6: Create the router chain\n",
        "# This chain uses the router prompt and the LLM to classify inputs and decide which chain to invoke\n",
        "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
        "\n",
        "# Step 7: Create the MultiPromptChain\n",
        "# Combines the router chain, destination chains, and default chain into a single workflow\n",
        "chain = MultiPromptChain(\n",
        "    router_chain=router_chain,  # Router chain for task classification\n",
        "    destination_chains=destination_chains,  # Task-specific chains\n",
        "    default_chain=default_chain,  # Fallback chain\n",
        "    verbose=True  # Enable detailed logging of the workflow\n",
        ")\n",
        "\n",
        "# Step 8: Invoke the MultiPromptChain with an input\n",
        "# Dynamically routes the question to the appropriate chain based on its content\n",
        "chain.invoke(\"How do magnets work?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPdUurz9L8D8",
        "outputId": "d4295432-763f-4319-b4b7-395aa1888ece"
      },
      "id": "MPdUurz9L8D8",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
            "\n",
            "<< FORMATTING >>\n",
            "Return a markdown code snippet with a JSON object formatted to look like:\n",
            "```json\n",
            "{{{{\n",
            "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
            "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
            "}}}}\n",
            "```\n",
            "\n",
            "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
            "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
            "\n",
            "<< CANDIDATE PROMPTS >>\n",
            "{destinations}\n",
            "\n",
            "<< INPUT >>\n",
            "{{input}}\n",
            "\n",
            "<< OUTPUT (must include ```json at the start of the response) >>\n",
            "<< OUTPUT (must end with ```) >>\n",
            "\n",
            "advanced physics: Answers advanced physics questions\n",
            "beginner physics: Answers basic beginner physics questions\n",
            "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
            "\n",
            "<< FORMATTING >>\n",
            "Return a markdown code snippet with a JSON object formatted to look like:\n",
            "```json\n",
            "{{\n",
            "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
            "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
            "}}\n",
            "```\n",
            "\n",
            "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
            "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
            "\n",
            "<< CANDIDATE PROMPTS >>\n",
            "advanced physics: Answers advanced physics questions\n",
            "beginner physics: Answers basic beginner physics questions\n",
            "\n",
            "<< INPUT >>\n",
            "{input}\n",
            "\n",
            "<< OUTPUT (must include ```json at the start of the response) >>\n",
            "<< OUTPUT (must end with ```) >>\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "beginner physics: {'input': 'How do magnets work?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'How do magnets work?',\n",
              " 'text': 'Great question! Let’s break it down step by step.\\n\\n**1. What are Magnets?**\\nMagnets are objects that can attract or repel certain materials, mainly iron, nickel, and cobalt. They have two ends called poles: a north pole and a south pole.\\n\\n**2. The Basics of Magnetism:**\\nAt the core of every magnet is something called \"magnetic fields.\" You can think of a magnetic field as an invisible force field that surrounds the magnet and extends out into the space around it. This field is what causes magnets to attract or repel other magnets or magnetic materials.\\n\\n**3. How Do Magnets Attract or Repel?**\\n- **Attraction:** When you bring the north pole of one magnet close to the south pole of another magnet, they pull towards each other. This is because opposite poles attract.\\n- **Repulsion:** If you bring two north poles or two south poles close together, they push away from each other. This is because like poles repel.\\n\\n**4. Why Do Magnets Have Poles?**\\nThe poles are a result of how the tiny particles inside the magnet, called atoms, are arranged. In most materials, the magnetic effects of these atoms cancel each other out. But in magnets, many of the atoms are aligned in the same direction, which creates a strong magnetic field.\\n\\n**5. Magnetic Domains:**\\nYou can imagine that in a magnet, there are tiny regions called \"magnetic domains.\" Each domain acts like a small magnet with a north and south pole. In a magnet, these domains are all lined up in the same direction, which makes the whole object magnetic.\\n\\n**6. Types of Magnets:**\\nThere are different types of magnets:\\n- **Permanent Magnets:** These are the magnets you might have on your fridge. They keep their magnetism over time.\\n- **Temporary Magnets:** These are materials that can become magnets when in a magnetic field but lose their magnetism when the field is removed.\\n- **Electromagnets:** These are magnets made by running electricity through a wire. When the electricity is on, they act like magnets, and when it\\'s off, they don\\'t.\\n\\n**7. Everyday Uses of Magnets:**\\nMagnets are everywhere in our daily lives! They are used in things like:\\n- Fridge magnets (to hold things on your refrigerator)\\n- Speakers (to create sound)\\n- Magnetic locks (for doors)\\n- MRI machines in hospitals (to take pictures of the inside of your body)\\n\\n**Conclusion:**\\nIn summary, magnets work because of the magnetic fields created by the arrangement of atoms inside them. They can attract or repel other magnets and certain materials, and they come in different types with various uses in our daily lives. Understanding magnets is about recognizing the invisible forces that make them work!'}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7ed272-808e-4974-ad21-6af0ba31fb98",
      "metadata": {
        "id": "1c7ed272-808e-4974-ad21-6af0ba31fb98",
        "outputId": "f940016e-5ab2-4fa3-aef7-198a82daf076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "advanced physics: {'input': 'How do Feynman Diagrams work?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Feynman diagrams are graphical representations used in particle physics to visualize and calculate the interactions between elementary particles. They were developed by the physicist Richard Feynman as a powerful tool for understanding and calculating the behavior of subatomic particles based on quantum field theory.\\n\\nAt their core, Feynman diagrams depict the possible ways in which particles can interact and exchange energy and momentum. They provide a pictorial representation of the mathematical expressions that describe these interactions.\\n\\nIn a Feynman diagram, particles are represented by lines, with arrows indicating their direction of motion. The lines can be straight or wavy, representing different types of particles. For example, straight lines can represent fermions (such as electrons or quarks), while wavy lines can represent force-carrying bosons (such as photons or gluons).\\n\\nThe vertices where the lines meet in a Feynman diagram represent interactions between particles. Each vertex is associated with a mathematical expression that describes the probability amplitude of that particular interaction occurring. These amplitudes are calculated using Feynman rules, which assign mathematical terms to each component of the diagram.\\n\\nTo calculate the probability of a specific process occurring, one must consider all possible Feynman diagrams that contribute to that process. This involves summing up the probability amplitudes associated with each diagram and taking their square to obtain the probability.\\n\\nFeynman diagrams also account for the conservation laws of energy, momentum, and electric charge. The lines in the diagram represent the flow of these quantities, and their conservation is ensured at each vertex. This allows physicists to analyze and predict the behavior of particles during interactions.\\n\\nFurthermore, Feynman diagrams enable physicists to visualize the exchange of virtual particles between interacting particles. These virtual particles, which are not directly observable, mediate the fundamental forces in nature. For example, in the electromagnetic interaction between two electrons, a Feynman diagram would depict the exchange of virtual photons.\\n\\nOverall, Feynman diagrams provide a powerful and intuitive way to understand and calculate the behavior of particles in quantum field theory. They allow physicists to analyze complex interactions and make predictions about the outcomes of particle interactions, contributing significantly to our understanding of the fundamental laws of nature.'"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"How do Feynman Diagrams work?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}