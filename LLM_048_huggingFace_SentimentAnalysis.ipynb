{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOk+BByylOY/UtejItXjZAt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/LLMs/blob/main/LLM_048_huggingFace_SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install python-dotenv\n",
        "# !pip install transformers\n",
        "# !pip install huggingface_hub"
      ],
      "metadata": {
        "id": "G4dClqE9kmbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJWGNiI8ipCg",
        "outputId": "7b61ca0b-6133-48e6-84dd-588c50a01cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.999873161315918}]\n",
            "[{'label': 'POSITIVE', 'score': 0.9998546838760376}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.9937392473220825}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.9991015195846558}]\n",
            "[{'label': 'POSITIVE', 'score': 0.9790390133857727}]\n",
            "[{'label': 'POSITIVE', 'score': 0.967018723487854}]\n",
            "[{'label': 'POSITIVE', 'score': 0.9966733455657959}]\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from huggingface_hub import login\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv(\"/content/HUGGINGFACE_HUB_TOKEN.env\")\n",
        "\n",
        "# Login using the token\n",
        "login(token=os.environ[\"HUGGINGFACE_HUB_TOKEN\"])\n",
        "\n",
        "# Create your pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\",\n",
        "                      model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "result = classifier(\"I'm really enjoying Hugging Face with a token!\")\n",
        "print(result)\n",
        "\n",
        "# Run it on some text\n",
        "result = classifier(\"I'm really enjoying learning Hugging Face!\")\n",
        "print(result)\n",
        "result = classifier(\"I hate jogging!\")\n",
        "print(result)\n",
        "result = classifier(\"I dont' care either way\")\n",
        "print(result)\n",
        "result = classifier(\"meh\")\n",
        "print(result)\n",
        "result = classifier(\"whatever you say.\")\n",
        "print(result)\n",
        "result = classifier(\"you see awfully sure of yourself\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü§î Why Is the Model So Confident?\n",
        "\n",
        "You're seeing results like:\n",
        "```python\n",
        "[{'label': 'NEGATIVE', 'score': 0.999}]\n",
        "[{'label': 'POSITIVE', 'score': 0.996}]\n",
        "```\n",
        "\n",
        "Even for **neutral or sarcastic text** like:\n",
        "- \"meh\"\n",
        "- \"whatever you say\"\n",
        "- \"you seem awfully sure of yourself\"\n",
        "\n",
        "This seems... overly confident, right? Here's why üëá\n",
        "\n",
        "---\n",
        "\n",
        "## üß† What's Actually Happening\n",
        "\n",
        "### 1. **The Model Was Trained for Binary Classification**\n",
        "The model you're using:\n",
        "```python\n",
        "\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "```\n",
        "‚Ä¶was trained on the **Stanford Sentiment Treebank v2 (SST-2)** dataset.\n",
        "\n",
        "**SST-2 only includes:**\n",
        "- `POSITIVE`\n",
        "- `NEGATIVE`\n",
        "\n",
        "There‚Äôs **no \"neutral\" class**, no sarcasm, no subtlety, no \"mixed feelings.\"  \n",
        "So the model **must choose** between just two buckets‚Äîeven when the text is ambiguous or unopinionated.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Softmax Always Picks a Winner**\n",
        "The model outputs **raw scores** (called *logits*) for each label.\n",
        "\n",
        "Then it applies the **softmax function**, which converts logits into **probabilities that always sum to 1.0**.\n",
        "\n",
        "> Even if the model is unsure, it **still picks the \"most likely\" class** with a high confidence value‚Äîespecially in a 2-class scenario.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Pretraining Bias + Overfitting**\n",
        "LLMs like BERT or DistilBERT are pretrained on huge corpora (Wikipedia, books, etc.) and then **fine-tuned** on small datasets like SST-2.\n",
        "\n",
        "Fine-tuning on a limited dataset with polarized opinions can cause:\n",
        "- Overconfidence on short or vague sentences\n",
        "- Misclassification of sarcasm or nuance\n",
        "- Poor generalization to real-world tones (like \"meh\" or \"whatever\")\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Try This Yourself\n",
        "\n",
        "Let‚Äôs inspect the **raw logits** instead of the processed output:\n",
        "\n",
        "This will show you how it always leans toward a class even when unsure.\n",
        "\n"
      ],
      "metadata": {
        "id": "SL-1ibrzi3_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "text = \"meh\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "print(\"Logits:\", logits)\n",
        "print(\"Probabilities:\", probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "0e3cf4bf4e8645228884739f420012e0",
            "b8ab3354a02f47b2b1e46180460f7d7d",
            "6f8d1531aa6c40779860f9a1989ba193",
            "abb38bdcae97422fb75f93a91fcec942",
            "d9a5afe31aea4ae5b559612a9d9ff894",
            "8595c1c4509e45a6b32da762180fc441",
            "a257f790d93f44d383efab7994c69aea",
            "7bae44c9eb794b59b1fb8527398b3987",
            "9298d23999fa469684e239238d0e1c97",
            "d1021e377d1d4d79af935509ccd4ecd4",
            "c349b4f39db448bb9158624ce8f70720",
            "7af16979999642448fa9780d8b43c764",
            "a2dde35dd9bd460c8e22ea67d907a158",
            "4b6eb77337e54b27a23c8cf0f0da395b",
            "55c57b4c3d9740d29a2f491978f72e8d",
            "36f4868f83d94c7fa037b087627633b9",
            "a6ccef702ad643f08d7cc899fa2da0b6",
            "43a32542a97c494aa5806afa476073ec",
            "ab932fb096aa408398d5c45ab4f75d7a",
            "4d01bc8377c24496907cfac3420356d6",
            "8866484693e542ed9b4b90eeaa55305e",
            "dd7b72016e5049f68fac0e2ed0be84fa",
            "aa00f1998d3a43d7b6ce400934bb1400",
            "8253371a38b0483c99123b7fe745654f",
            "f465356641474b70aeada6f32cefb329",
            "4ce051e02dde4793949cd964b227914e",
            "90e409c004754ca1af895c2b8badaac0",
            "f69949de88eb46409b4e13cf168e49bc",
            "63592384897c4332b531a5e568b3ac8c",
            "b04a5b82504e4e64926aed78f728b7e5",
            "d8006dcd33cb41e8ade02bd72ef1a52d",
            "994538ed636f4874b21bc22ce061662f",
            "23116b94cf3b4d3bb327bb3d80273d50",
            "b59e38dcc3c94178b87c5a42221a902b",
            "aa0f908d1d0045f7a9d6798990b837d9",
            "3143748a54d94a299abc135430c3c9f8",
            "577a5a788ade49b49deb9e05276a3c59",
            "104deebed849492faa096c64d06e071e",
            "d778ec025eae442d8f80dff32d88c476",
            "a2c6fd2ba4a647adb8c63f59ea9fa254",
            "18065d6da0774cc6b5a93ef70a11fa48",
            "af87614ed06044c4830966d781b115fc",
            "12b42c48974e4f0dadcc0dcb2d722f2b",
            "220abd7e21de4c819d87d1395f8c350c"
          ]
        },
        "id": "NcXvll7mi4dK",
        "outputId": "188a8e94-08fd-498e-ded4-cffaaab25964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e3cf4bf4e8645228884739f420012e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7af16979999642448fa9780d8b43c764"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa00f1998d3a43d7b6ce400934bb1400"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b59e38dcc3c94178b87c5a42221a902b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: tensor([[-1.8109,  2.0331]])\n",
            "Probabilities: tensor([[0.0210, 0.9790]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ What You Can Do About It\n",
        "\n",
        "- **Use a multi-class sentiment model** with a neutral category  \n",
        "  ‚Üí e.g., `cardiffnlp/twitter-roberta-base-sentiment`  \n",
        "  (has Positive, Neutral, Negative)\n",
        "\n",
        "- **Try zero-shot classification** if you want more nuanced control:\n",
        "```python\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "result = classifier(\n",
        "    \"meh\",\n",
        "    candidate_labels=[\"positive\", \"negative\", \"neutral\", \"sarcastic\"]\n",
        ")\n",
        "print(result)\n",
        "```\n",
        "\n",
        "- **Train your own model** on more subtle or domain-specific sentiment examples."
      ],
      "metadata": {
        "id": "lxEpgw9djWVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your current notebook file (adjust if different)\n",
        "notebook_path = \"/content/drive/My Drive/LLM/LLM_048_huggingFace_SentimentAnalysis.ipynb\"\n",
        "\n",
        "\n",
        "# Load the notebook JSON\n",
        "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "    nb = json.load(f)\n",
        "\n",
        "# Remove the widget metadata if it exists\n",
        "if 'widgets' in nb.get('metadata', {}):\n",
        "    del nb['metadata']['widgets']\n",
        "\n",
        "# Save the cleaned notebook\n",
        "with open(notebook_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(nb, f, indent=2)\n",
        "\n",
        "print(\"Notebook metadata cleaned. Try saving to GitHub again.\")\n"
      ],
      "metadata": {
        "id": "UILjP50ojZBe",
        "outputId": "2730d659-e7b6-4b13-fc11-a3a1f51ea03b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Notebook metadata cleaned. Try saving to GitHub again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V7XcFvhMlzQq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}