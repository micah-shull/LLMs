{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/LLMs/blob/main/LLM_040_sequential_chain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Sequential Chains: Key Concepts\n",
        "\n",
        "### **1. Runnable Composition**\n",
        "- **Pipelines are modular**: The `|` operator allows chaining together `Runnable` components in a clean, readable way.\n",
        "- **Flexibility**: Each step is self-contained, making it easy to swap out components (e.g., use a different LLM or a new prompt).\n",
        "\n",
        "**Key Takeaway**: LangChain's `Runnable` paradigm emphasizes modularity and reusability, allowing you to build workflows that are easy to maintain and extend.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Input Handling with `RunnableMap` and `RunnablePassthrough`**\n",
        "- **`RunnableMap` and `RunnablePassthrough`** handle structured inputs like `{\"name\", \"purpose\"}` without modification.\n",
        "- These ensure that your inputs flow into the pipeline correctly, particularly when dealing with multiple variables.\n",
        "\n",
        "**Key Takeaway**: LangChain enables seamless handling of structured inputs, making pipelines adaptable to real-world use cases where multiple data points (like user inputs) need to be processed.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Multi-Step Processing**\n",
        "- The chain demonstrates a **multi-step workflow**:\n",
        "  1. Generate a professional email using a prompt.\n",
        "  2. Pass the email draft as input to a summarization prompt.\n",
        "  3. Process both prompts using the LLM.\n",
        "  4. Parse the final result into a clean string.\n",
        "- Each step builds on the output of the previous one, illustrating LangChain's **data flow management**.\n",
        "\n",
        "**Key Takeaway**: LangChain allows chaining multiple tasks (generation, summarization, etc.) into a single, logical flow.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Prompt Engineering**\n",
        "- The **prompt templates** are essential for guiding the LLM's behavior:\n",
        "  - The first prompt provides specific instructions for generating a professional email.\n",
        "  - The second prompt ensures a concise summary of the email.\n",
        "  \n",
        "**Key Takeaway**: Thoughtful prompt design is critical for getting the desired output from LLMs. LangChain makes prompts reusable and parameterized for dynamic input.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Integration with Models**\n",
        "- The code integrates a specific LLM (`ChatOpenAI`) seamlessly into the workflow.\n",
        "- This demonstrates how LangChain acts as a bridge between prompts, structured inputs, and powerful LLMs.\n",
        "\n",
        "**Key Takeaway**: LangChain abstracts the complexity of integrating models, focusing on functionality rather than model-specific details.\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Output Parsing**\n",
        "- The `StrOutputParser` ensures that the final result is a clean, usable string, even when intermediate steps might return complex or verbose outputs.\n",
        "\n",
        "**Key Takeaway**: LangChain provides utilities to control and format the final output, which is crucial for downstream applications.\n",
        "\n",
        "---\n",
        "\n",
        "### **7. Real-World Applicability**\n",
        "- The pipeline solves a practical problem: generating and summarizing professional emails.\n",
        "- It highlights how LangChain can be applied to real-world use cases, combining LLMs with structured workflows.\n",
        "\n",
        "**Key Takeaway**: LangChain simplifies building task-specific AI applications by abstracting common workflows into reusable components.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zQg1M3aaxtzE"
      },
      "id": "zQg1M3aaxtzE"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain\n",
        "# !pip install openai\n",
        "# !pip install python-dotenv\n",
        "# !pip install langchain-openai"
      ],
      "metadata": {
        "id": "7p8yMuGIsuVY"
      },
      "id": "7p8yMuGIsuVY",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "import json\n",
        "import langchain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "# Load environment variables from .env file\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "# Set the environment variable globally for libraries like LangChain\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "# Print the API key to confirm it's loaded correctly\n",
        "print(\"API Key loaded from .env:\",os.environ[\"OPENAI_API_KEY\"][0:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfNwmL50szJL",
        "outputId": "3ac1e38f-fc55-47e5-9ddb-8c90b38f6f69"
      },
      "id": "KfNwmL50szJL",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key loaded from .env: sk-proj-e1GUWruINPRnrozmiakkRM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Employee Review\n",
        "\n",
        "### **Key Concepts**\n",
        "\n",
        "1. **SequentialChain**:\n",
        "   - Manages multiple chains in a logical sequence where each chain's output feeds into the next as input.\n",
        "   - Ensures intermediate outputs (`review_summary`, `weaknesses`) are preserved for inspection or downstream use.\n",
        "\n",
        "2. **LLMChain**:\n",
        "   - Combines a prompt template and an LLM to perform specific tasks.\n",
        "   - Each chain has an input (like `review` or `weaknesses`) and a defined output (e.g., `review_summary`).\n",
        "\n",
        "3. **Prompt Engineering**:\n",
        "   - Thoughtfully designed prompts ensure each step focuses on a clear and actionable goal:\n",
        "     - Step 1: Summarize performance.\n",
        "     - Step 2: Extract weaknesses.\n",
        "     - Step 3: Propose solutions.\n",
        "\n",
        "4. **Reusable Outputs**:\n",
        "   - By specifying `output_key` for each chain, intermediate results are accessible for further use.\n",
        "\n",
        "5. **Scalability**:\n",
        "   - This modular design allows for easy addition of new steps or integration with external tools.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why This Workflow is Valuable**\n",
        "\n",
        "- **Automates Performance Review Analysis**:\n",
        "   - Reduces manual effort in summarizing reviews, identifying weaknesses, and designing improvement plans.\n",
        "\n",
        "- **Customizable**:\n",
        "   - Prompts can be adjusted to align with organizational goals or performance criteria.\n",
        "\n",
        "- **Transparent**:\n",
        "   - Intermediate outputs (`review_summary`, `weaknesses`) provide clear visibility into each step of the process.\n",
        "\n"
      ],
      "metadata": {
        "id": "uUkf-tIP6v-9"
      },
      "id": "uUkf-tIP6v-9"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "2a6c1d04-1fe0-4386-8b3a-4535cbfaff43",
      "metadata": {
        "id": "2a6c1d04-1fe0-4386-8b3a-4535cbfaff43"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize the LLM (Language Learning Model) with the desired model and configuration\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)  # GPT-4 model with moderate creativity\n",
        "\n",
        "# Step 1: Define the first prompt template to summarize the performance review\n",
        "template1 = \"Give a summary of this employee's performance review:\\n{review}\"\n",
        "prompt1 = ChatPromptTemplate.from_template(template1)\n",
        "\n",
        "# Step 1: Create the first chain to generate a performance review summary\n",
        "chain_1 = LLMChain(\n",
        "    llm=llm,  # Use the LLM to process the prompt\n",
        "    prompt=prompt1,  # Prompt for summarizing the review\n",
        "    output_key=\"review_summary\"  # Key for storing the summary output\n",
        ")\n",
        "\n",
        "# Step 2: Define the second prompt template to extract key weaknesses\n",
        "template2 = \"Identify key employee weaknesses in this review summary:\\n{review_summary}\"\n",
        "prompt2 = ChatPromptTemplate.from_template(template2)\n",
        "\n",
        "# Step 2: Create the second chain to extract employee weaknesses\n",
        "chain_2 = LLMChain(\n",
        "    llm=llm,  # Use the same LLM for this task\n",
        "    prompt=prompt2,  # Prompt to identify weaknesses\n",
        "    output_key=\"weaknesses\"  # Key for storing the weaknesses output\n",
        ")\n",
        "\n",
        "# Step 3: Define the third prompt template to create a personalized improvement plan\n",
        "template3 = \"Create a personalized plan to help address and fix these weaknesses:\\n{weaknesses}\"\n",
        "prompt3 = ChatPromptTemplate.from_template(template3)\n",
        "\n",
        "# Step 3: Create the third chain to generate a personalized improvement plan\n",
        "chain_3 = LLMChain(\n",
        "    llm=llm,  # Use the same LLM for consistency\n",
        "    prompt=prompt3,  # Prompt for creating an improvement plan\n",
        "    output_key=\"final_plan\"  # Key for storing the final plan output\n",
        ")\n",
        "\n",
        "# Combine all the chains into a SequentialChain\n",
        "seq_chain = SequentialChain(\n",
        "    chains=[chain_1, chain_2, chain_3],  # Execute the chains sequentially\n",
        "    input_variables=['review'],  # Input required for the first chain\n",
        "    output_variables=['review_summary', 'weaknesses', 'final_plan'],  # Outputs from all chains\n",
        "    verbose=True  # Enable verbose mode to see detailed logs of each step\n",
        ")\n",
        "\n",
        "# The SequentialChain:\n",
        "# 1. Takes 'review' as input.\n",
        "# 2. Generates 'review_summary' from Chain 1.\n",
        "# 3. Uses 'review_summary' to generate 'weaknesses' in Chain 2.\n",
        "# 4. Uses 'weaknesses' to create 'final_plan' in Chain 3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "0e6013f5-40c9-401b-9d45-98b52de1bb3f",
      "metadata": {
        "id": "0e6013f5-40c9-401b-9d45-98b52de1bb3f"
      },
      "outputs": [],
      "source": [
        "employee_review = '''\n",
        "Employee Information:\n",
        "Name: Joe Schmo\n",
        "Position: Software Engineer\n",
        "Date of Review: July 14, 2023\n",
        "\n",
        "Strengths:\n",
        "Joe is a highly skilled software engineer with a deep understanding of programming languages, algorithms, and software development best practices. His technical expertise shines through in his ability to efficiently solve complex problems and deliver high-quality code.\n",
        "\n",
        "One of Joe's greatest strengths is his collaborative nature. He actively engages with cross-functional teams, contributing valuable insights and seeking input from others. His open-mindedness and willingness to learn from colleagues make him a true team player.\n",
        "\n",
        "Joe consistently demonstrates initiative and self-motivation. He takes the lead in seeking out new projects and challenges, and his proactive attitude has led to significant improvements in existing processes and systems. His dedication to self-improvement and growth is commendable.\n",
        "\n",
        "Another notable strength is Joe's adaptability. He has shown great flexibility in handling changing project requirements and learning new technologies. This adaptability allows him to seamlessly transition between different projects and tasks, making him a valuable asset to the team.\n",
        "\n",
        "Joe's problem-solving skills are exceptional. He approaches issues with a logical mindset and consistently finds effective solutions, often thinking outside the box. His ability to break down complex problems into manageable parts is key to his success in resolving issues efficiently.\n",
        "\n",
        "Weaknesses:\n",
        "While Joe possesses numerous strengths, there are a few areas where he could benefit from improvement. One such area is time management. Occasionally, Joe struggles with effectively managing his time, resulting in missed deadlines or the need for additional support to complete tasks on time. Developing better prioritization and time management techniques would greatly enhance his efficiency.\n",
        "\n",
        "Another area for improvement is Joe's written communication skills. While he communicates well verbally, there have been instances where his written documentation lacked clarity, leading to confusion among team members. Focusing on enhancing his written communication abilities will help him effectively convey ideas and instructions.\n",
        "\n",
        "Additionally, Joe tends to take on too many responsibilities and hesitates to delegate tasks to others. This can result in an excessive workload and potential burnout. Encouraging him to delegate tasks appropriately will not only alleviate his own workload but also foster a more balanced and productive team environment.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "406813b0-b79d-4056-8dbc-923e1986df41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "406813b0-b79d-4056-8dbc-923e1986df41",
        "outputId": "1a7efa53-895b-498d-c101-e015eda41f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "results = seq_chain.invoke(employee_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "be395801-2e84-4686-9203-3857f8b5934b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be395801-2e84-4686-9203-3857f8b5934b",
        "outputId": "7eaf6085-1fac-4c5e-8463-7daf845ab61a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review', 'review_summary', 'weaknesses', 'final_plan'])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "results.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results['review_summary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85soHqk18FGU",
        "outputId": "38215cb8-d5a1-4e1d-d2f3-29d13e2f683b"
      },
      "id": "85soHqk18FGU",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Performance Review Summary for Joe Schmo**\n",
            "\n",
            "**Position:** Software Engineer  \n",
            "**Date of Review:** July 14, 2023\n",
            "\n",
            "**Strengths:**\n",
            "Joe Schmo is recognized as a highly skilled software engineer with a strong command of programming languages, algorithms, and best practices in software development. His technical prowess enables him to effectively tackle complex problems and produce high-quality code. Joe excels in collaboration, actively engaging with cross-functional teams and valuing input from others, which highlights his team-oriented mindset.\n",
            "\n",
            "He demonstrates remarkable initiative and self-motivation by seeking out new projects and challenges, leading to significant enhancements in processes and systems. Joe's adaptability is another asset; he effectively manages changing project requirements and quickly learns new technologies, allowing him to transition smoothly between various tasks.\n",
            "\n",
            "Joe's exceptional problem-solving skills are evident in his logical approach to issues, where he consistently identifies effective solutions and simplifies complex problems into manageable parts.\n",
            "\n",
            "**Weaknesses:**\n",
            "Despite his numerous strengths, Joe has areas that require attention. Time management is a challenge for him, as he occasionally struggles to meet deadlines or complete tasks efficiently without additional support. Improving his prioritization and time management techniques would enhance his overall performance.\n",
            "\n",
            "Additionally, while Joe communicates well verbally, his written communication has been noted as lacking clarity, leading to misunderstandings among team members. Focusing on this area will help him convey ideas and instructions more effectively.\n",
            "\n",
            "Lastly, Joe tends to take on too many responsibilities and is hesitant to delegate tasks, which can lead to an overwhelming workload and risk of burnout. Encouraging him to delegate more appropriately could foster a balanced and productive team environment.\n",
            "\n",
            "Overall, Joe Schmo is a valuable asset to the team with strong technical skills and a collaborative spirit, but improvements in time management, written communication, and delegation would further enhance his effectiveness.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2edc6866-769b-47ee-921d-ae40eb9891eb",
      "metadata": {
        "id": "2edc6866-769b-47ee-921d-ae40eb9891eb",
        "outputId": "8efa354d-0d50-43f4-bca5-242f6cac33eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To address and fix these weaknesses, the following personalized plan can be implemented for Joe:\n",
            "\n",
            "1. Time management:\n",
            "\n",
            "- Set clear goals and priorities: Joe should start each day by identifying the most important tasks that need to be accomplished and prioritize them accordingly. This will help him stay focused and ensure that he completes critical tasks on time.\n",
            "- Break tasks into smaller, manageable chunks: Large projects can be overwhelming and lead to procrastination. Joe should break them down into smaller, more manageable tasks, setting specific deadlines for each subtask. This will help him track progress and stay on schedule.\n",
            "- Use time management tools: Joe can utilize various time management tools, such as calendars, task management apps, or project management software, to help him stay organized and prioritize tasks effectively.\n",
            "\n",
            "2. Written communication skills:\n",
            "\n",
            "- Seek feedback and guidance: Joe should actively seek feedback from his colleagues or supervisors on his written communication skills. This feedback can help identify specific areas for improvement and provide guidance on how to enhance his written communication abilities.\n",
            "- Take writing courses or workshops: Joe can enroll in writing courses or workshops to improve his written communication skills. These courses can provide him with practical tips and techniques for conveying information effectively and ensure that his written documentation, emails, and reports are clear and concise.\n",
            "- Practice writing regularly: Joe should make an effort to practice his writing skills regularly. This can include writing memos, reports, or even maintaining a personal blog. Regular practice will help him become more comfortable and proficient in conveying his ideas through written communication.\n",
            "\n",
            "3. Delegation of tasks:\n",
            "\n",
            "- Identify tasks suitable for delegation: Joe should assess his workload and identify tasks that can be delegated to others without compromising quality or efficiency. This will help him free up time for more critical tasks and develop trust in his colleagues' abilities.\n",
            "- Communicate expectations clearly: When delegating tasks, Joe should clearly communicate his expectations, including deadlines, desired outcomes, and any necessary guidelines or resources. This will ensure that delegated tasks are completed efficiently and effectively.\n",
            "- Provide support and feedback: Joe should offer support to colleagues to whom he delegates tasks. This can include providing resources, answering questions, or offering guidance when needed. Additionally, he should provide constructive feedback on completed tasks to help improve the overall delegation process.\n",
            "\n",
            "Regular self-assessments and discussions with supervisors or mentors can help track progress and identify any further areas of improvement. Implementing this personalized plan will enable Joe to address his weaknesses and enhance his overall performance as a software engineer.\n"
          ]
        }
      ],
      "source": [
        "print(results['final_plan'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Client Feedback"
      ],
      "metadata": {
        "id": "sfRULi52Ae7D"
      },
      "id": "sfRULi52Ae7D"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "15760213-e3a3-443a-9fe7-17d14c438ac5",
      "metadata": {
        "id": "15760213-e3a3-443a-9fe7-17d14c438ac5"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize the LLM (Language Learning Model) with the desired model and configuration\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)  # GPT-4 model with moderate creativity\n",
        "\n",
        "# Step 1: Define the first prompt template to summarize client feedback\n",
        "template1 = \"Summarize the following client feedback into key points:\\n{feedback}\"\n",
        "prompt1 = ChatPromptTemplate.from_template(template1)\n",
        "\n",
        "# Step 1: Create the first chain to generate a feedback summary\n",
        "chain_1 = LLMChain(\n",
        "    llm=llm,  # Use the LLM to process the prompt\n",
        "    prompt=prompt1,  # Prompt for summarizing the feedback\n",
        "    output_key=\"feedback_summary\"  # Key for storing the summary output\n",
        ")\n",
        "\n",
        "# Step 2: Define the second prompt template to identify client pain points\n",
        "template2 = \"Based on the feedback summary, identify the client's main pain points:\\n{feedback_summary}\"\n",
        "prompt2 = ChatPromptTemplate.from_template(template2)\n",
        "\n",
        "# Step 2: Create the second chain to extract client pain points\n",
        "chain_2 = LLMChain(\n",
        "    llm=llm,  # Use the same LLM for this task\n",
        "    prompt=prompt2,  # Prompt to identify pain points\n",
        "    output_key=\"pain_points\"  # Key for storing the pain points output\n",
        ")\n",
        "\n",
        "# Step 3: Define the third prompt template to create actionable recommendations\n",
        "template3 = (\n",
        "    \"Create actionable recommendations to address the following client pain points:\\n{pain_points}\"\n",
        ")\n",
        "prompt3 = ChatPromptTemplate.from_template(template3)\n",
        "\n",
        "# Step 3: Create the third chain to generate actionable recommendations\n",
        "chain_3 = LLMChain(\n",
        "    llm=llm,  # Use the same LLM for consistency\n",
        "    prompt=prompt3,  # Prompt for creating actionable recommendations\n",
        "    output_key=\"recommendations\"  # Key for storing the recommendations output\n",
        ")\n",
        "\n",
        "# Combine all the chains into a SequentialChain\n",
        "seq_chain = SequentialChain(\n",
        "    chains=[chain_1, chain_2, chain_3],  # Execute the chains sequentially\n",
        "    input_variables=['feedback'],  # Input required for the first chain\n",
        "    output_variables=['feedback_summary', 'pain_points', 'recommendations'],  # Outputs from all chains\n",
        "    verbose=True  # Enable verbose mode to see detailed logs of each step\n",
        ")\n",
        "\n",
        "# Example Input: Client Feedback\n",
        "client_feedback = \"\"\"\n",
        "The product is useful, but the onboarding process was very confusing.\n",
        "I also found the customer support to be unresponsive during critical times.\n",
        "Overall, it gets the job done, but I expected better communication and clearer instructions.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = seq_chain.invoke(client_feedback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KduhOJrAK1V",
        "outputId": "47919706-b755-41b4-c5bd-9d55a38ce87f"
      },
      "id": "2KduhOJrAK1V",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Results\n",
        "print(\"Feedback Summary:\\n\", output['feedback_summary'])\n",
        "print(\"\\nClient Pain Points:\\n\", output['pain_points'])\n",
        "print(\"\\nActionable Recommendations:\\n\", output['recommendations'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLSgKWQ9_995",
        "outputId": "c1964fd1-72b9-4fe8-cfbf-a6d3551c1c1d"
      },
      "id": "WLSgKWQ9_995",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedback Summary:\n",
            " Key Points from Client Feedback:\n",
            "\n",
            "1. The product is useful and effective.\n",
            "2. The onboarding process is confusing.\n",
            "3. Customer support is unresponsive during critical times.\n",
            "4. Expectation for better communication and clearer instructions.\n",
            "\n",
            "Client Pain Points:\n",
            " Based on the feedback summary, the client's main pain points are:\n",
            "\n",
            "1. **Confusing Onboarding Process**: The client finds the onboarding process difficult to navigate, which may hinder their ability to effectively use the product.\n",
            "\n",
            "2. **Unresponsive Customer Support**: The client experiences issues with customer support being unresponsive during critical times, which can lead to frustration and hinder problem resolution.\n",
            "\n",
            "3. **Need for Better Communication**: There is an expectation for improved communication and clearer instructions, indicating that the client feels the current level of communication does not meet their needs.\n",
            "\n",
            "Actionable Recommendations:\n",
            " To address the identified pain points for the client, here are actionable recommendations:\n",
            "\n",
            "### 1. Improve the Onboarding Process\n",
            "- **Revamp Onboarding Materials**: Create simplified and visually appealing onboarding guides, including step-by-step tutorials, infographics, and video walkthroughs to make the process easier to understand.\n",
            "  \n",
            "- **Personalized Onboarding Sessions**: Offer one-on-one onboarding sessions with a dedicated customer success representative for new clients. This can help address specific questions and tailor the onboarding experience to their needs.\n",
            "\n",
            "- **Interactive Onboarding Platform**: Implement an interactive onboarding tool within the product that guides users through the features and functionalities, providing prompts and tips as they navigate.\n",
            "\n",
            "- **Feedback Loop**: Establish a system to collect feedback from new users after onboarding to continuously improve the process based on their experiences and suggestions.\n",
            "\n",
            "### 2. Enhance Customer Support Responsiveness\n",
            "- **Implement a Ticketing System**: Use a ticketing system that categorizes and prioritizes inquiries to ensure that critical issues are addressed promptly. Set clear response time expectations based on urgency.\n",
            "\n",
            "- **Expand Support Hours**: Consider extending customer support hours or offering 24/7 support, especially during peak usage times, to ensure clients can get assistance when they need it most.\n",
            "\n",
            "- **Dedicated Support Channels**: Introduce dedicated channels (e.g., chat support, phone support) for urgent issues, ensuring clients can reach the right support staff quickly.\n",
            "\n",
            "- **Regular Training for Support Staff**: Conduct ongoing training for customer support representatives to ensure they are knowledgeable about the product and can provide timely and accurate assistance.\n",
            "\n",
            "### 3. Foster Better Communication\n",
            "- **Regular Updates**: Schedule regular updates to clients (e.g., weekly or bi-weekly newsletters) that outline new features, tips for using the product, and any known issues being addressed.\n",
            "\n",
            "- **Create a Knowledge Base**: Develop a comprehensive online knowledge base or FAQ section that clients can easily access for self-help resources, tutorials, and troubleshooting guides.\n",
            "\n",
            "- **Client Feedback Surveys**: Conduct periodic surveys to gauge client satisfaction with the communication they receive and solicit suggestions for improvement. Follow up on the feedback to demonstrate commitment to enhancing communication.\n",
            "\n",
            "- **Set Clear Expectations**: Communicate clearly about timelines for support responses and any changes to the product or services. Transparency goes a long way in building trust and managing client expectations.\n",
            "\n",
            "### Implementation Plan\n",
            "- **Timeline**: Establish a timeline for implementing these recommendations, prioritizing those that will have the most immediate impact, such as customer support enhancements.\n",
            "  \n",
            "- **Assign Responsibilities**: Designate team members to oversee each recommendation and ensure accountability for progress.\n",
            "\n",
            "- **Monitor and Adjust**: Regularly assess the effectiveness of the implemented changes through client feedback and performance metrics, making adjustments as necessary to continuously improve the client experience.\n",
            "\n",
            "By addressing these pain points with concrete actions, the client can expect a more streamlined onboarding experience, improved support responsiveness, and clearer communication, ultimately leading to greater satisfaction and product utilization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Email Writing Function:**\n",
        "\n",
        "This function demonstrates how to use **LangChain's RunnablePipeline** to create a multi-step workflow for generating and summarizing a professional email. It integrates an LLM (OpenAI GPT-40-mini) to:\n",
        "\n",
        "1. **Generate a professional email draft** based on the recipient's name and the email's purpose.\n",
        "2. **Summarize the email** into a concise one-sentence summary, which could serve as a subject line or a quick preview.\n",
        "\n",
        "The workflow ensures both outputs—the full email and the summary—are returned for further use.\n",
        "\n",
        "---\n",
        "\n",
        "### **What This Function Does:**\n",
        "\n",
        "1. **Input Handling**:\n",
        "   - Accepts structured input (`name` and `purpose`) and processes it through a pipeline.\n",
        "\n",
        "2. **Email Drafting**:\n",
        "   - Uses a prompt to instruct the LLM to generate a formal email.\n",
        "\n",
        "3. **Summarization**:\n",
        "   - Processes the email draft through another prompt to produce a summary.\n",
        "---\n",
        "\n",
        "### **Key Lessons:**\n",
        "\n",
        "1. **Modularity**:\n",
        "   - The pipeline is built with reusable components (`RunnableMap`, `RunnablePassthrough`, `RunnableLambda`), making it easy to expand or adjust for other tasks.\n",
        "\n",
        "2. **Chaining Outputs**:\n",
        "   - Outputs from one step feed into the next, demonstrating how LangChain facilitates multi-step workflows.\n",
        "\n",
        "3. **Content Extraction**:\n",
        "   - Handling LLM outputs like `AIMessage` and converting them into plain strings is essential for compatibility in complex pipelines.\n",
        "\n",
        "4. **Parallel Processing**:\n",
        "   - `RunnableMap` enables splitting outputs (e.g., email draft and summary) for simultaneous or independent processing.\n",
        "\n",
        "5. **Prompt Engineering**:\n",
        "   - Thoughtful prompts guide the LLM's behavior, demonstrating how different tasks (drafting and summarization) can be performed in sequence.\n",
        "\n",
        "---\n",
        "\n",
        "### **Use Cases and Applications:**\n",
        "\n",
        "- **Email Automation**:\n",
        "   - Draft professional emails and generate subject lines or summaries for preview or categorization.\n",
        "\n",
        "- **Multi-Step Workflows**:\n",
        "   - Useful for any task requiring generation, refinement, or summarization of content.\n",
        "\n",
        "- **Scalability**:\n",
        "   - The modular structure supports integration with additional tools (e.g., email-sending APIs, CRMs).\n",
        "\n",
        "This function showcases how LangChain empowers developers to build structured, multi-step workflows that leverage LLMs efficiently and flexibly."
      ],
      "metadata": {
        "id": "X6t7HLC-5wfQ"
      },
      "id": "X6t7HLC-5wfQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema.runnable import RunnableMap\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "\n",
        "# Step 1: Define the LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "\n",
        "# Step 2: Define prompt templates for each task\n",
        "# Task 1: Create an email draft\n",
        "email_prompt = PromptTemplate(\n",
        "    input_variables=[\"name\", \"purpose\"],\n",
        "    template=(\n",
        "        \"Write a professional email addressed to {name} \"\n",
        "        \"with the purpose of {purpose}. Use a formal tone.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Task 2: Summarize the email\n",
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"email_draft\"],\n",
        "    template=(\n",
        "        \"Summarize the following email in one sentence:\\n\\n{email_draft}\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Step 3: Define a lambda to extract `AIMessage` content\n",
        "extract_content = RunnableLambda(lambda x: x.content if hasattr(x, 'content') else x)\n",
        "\n",
        "# Step 4: Define the pipeline\n",
        "sequential_chain = (\n",
        "    {\n",
        "        \"name\": RunnablePassthrough(),\n",
        "        \"purpose\": RunnablePassthrough()\n",
        "    }  # Pass inputs directly\n",
        "    | email_prompt  # Generate the email prompt\n",
        "    | llm  # Generate the email\n",
        "    | extract_content  # Extract content from AIMessage\n",
        "    | RunnableMap(  # Map outputs for both email and summary\n",
        "        {\n",
        "            \"email_draft\": RunnablePassthrough(),  # Pass through the email draft\n",
        "            \"summary\": summary_prompt | llm | extract_content  # Summarize and extract content\n",
        "        }\n",
        "    )\n",
        ")\n",
        "\n",
        "# Step 5: Run the chain with input\n",
        "inputs = {\"name\": \"Dr. Smith\", \"purpose\": \"scheduling a follow-up meeting\"}\n",
        "output = sequential_chain.invoke(inputs)\n",
        "\n",
        "# Print results\n",
        "print(\"Generated Email Draft:\\n\", output[\"email_draft\"])\n",
        "print(\"\\nGenerated Summary:\\n\", output[\"summary\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpfvK-i25TUV",
        "outputId": "18916608-fdc8-4478-e8c9-c0e4e039e8c8"
      },
      "id": "FpfvK-i25TUV",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Email Draft:\n",
            " Subject: Request for Follow-up Meeting \n",
            "\n",
            "Dear Dr. Smith,\n",
            "\n",
            "I trust you are in good health. I am writing to express my interest in scheduling a follow-up meeting with you in the coming weeks.\n",
            "\n",
            "Our previous meeting was enlightening and allowed us to touch base on several crucial points of our ongoing project. However, I believe that there are additional items that require our attention and in-depth discussion. These items are integral to the successful completion of our project.\n",
            "\n",
            "Given the importance of these matters, I propose that we convene a follow-up meeting at a time that best suits your schedule. I am flexible and can adjust my availability accordingly.\n",
            "\n",
            "Should you agree, kindly let me know your preferred date and time so that I may organize the necessary documents and prepare for our meeting.\n",
            "\n",
            "Thank you in advance for your consideration. I look forward to our continued collaboration.\n",
            "\n",
            "Best Regards,\n",
            "\n",
            "[Your Name] \n",
            "\n",
            "[Your Position]\n",
            "\n",
            "[Your Contact Information]\n",
            "\n",
            "Generated Summary:\n",
            " The sender of the email is requesting a follow-up meeting with Dr. Smith to discuss additional important items related to their ongoing project and is offering to adjust to Dr. Smith's schedule for the meeting.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}