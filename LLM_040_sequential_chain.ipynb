{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/LLMs/blob/main/LLM_040_sequential_chain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Sequential Chains: Key Concepts\n",
        "\n",
        "### **1. Runnable Composition**\n",
        "- **Pipelines are modular**: The `|` operator allows chaining together `Runnable` components in a clean, readable way.\n",
        "- **Flexibility**: Each step is self-contained, making it easy to swap out components (e.g., use a different LLM or a new prompt).\n",
        "\n",
        "**Key Takeaway**: LangChain's `Runnable` paradigm emphasizes modularity and reusability, allowing you to build workflows that are easy to maintain and extend.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Input Handling with `RunnableMap` and `RunnablePassthrough`**\n",
        "- **`RunnableMap` and `RunnablePassthrough`** handle structured inputs like `{\"name\", \"purpose\"}` without modification.\n",
        "- These ensure that your inputs flow into the pipeline correctly, particularly when dealing with multiple variables.\n",
        "\n",
        "**Key Takeaway**: LangChain enables seamless handling of structured inputs, making pipelines adaptable to real-world use cases where multiple data points (like user inputs) need to be processed.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Multi-Step Processing**\n",
        "- The chain demonstrates a **multi-step workflow**:\n",
        "  1. Generate a professional email using a prompt.\n",
        "  2. Pass the email draft as input to a summarization prompt.\n",
        "  3. Process both prompts using the LLM.\n",
        "  4. Parse the final result into a clean string.\n",
        "- Each step builds on the output of the previous one, illustrating LangChain's **data flow management**.\n",
        "\n",
        "**Key Takeaway**: LangChain allows chaining multiple tasks (generation, summarization, etc.) into a single, logical flow.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Prompt Engineering**\n",
        "- The **prompt templates** are essential for guiding the LLM's behavior:\n",
        "  - The first prompt provides specific instructions for generating a professional email.\n",
        "  - The second prompt ensures a concise summary of the email.\n",
        "  \n",
        "**Key Takeaway**: Thoughtful prompt design is critical for getting the desired output from LLMs. LangChain makes prompts reusable and parameterized for dynamic input.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Integration with Models**\n",
        "- The code integrates a specific LLM (`ChatOpenAI`) seamlessly into the workflow.\n",
        "- This demonstrates how LangChain acts as a bridge between prompts, structured inputs, and powerful LLMs.\n",
        "\n",
        "**Key Takeaway**: LangChain abstracts the complexity of integrating models, focusing on functionality rather than model-specific details.\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Output Parsing**\n",
        "- The `StrOutputParser` ensures that the final result is a clean, usable string, even when intermediate steps might return complex or verbose outputs.\n",
        "\n",
        "**Key Takeaway**: LangChain provides utilities to control and format the final output, which is crucial for downstream applications.\n",
        "\n",
        "---\n",
        "\n",
        "### **7. Real-World Applicability**\n",
        "- The pipeline solves a practical problem: generating and summarizing professional emails.\n",
        "- It highlights how LangChain can be applied to real-world use cases, combining LLMs with structured workflows.\n",
        "\n",
        "**Key Takeaway**: LangChain simplifies building task-specific AI applications by abstracting common workflows into reusable components.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zQg1M3aaxtzE"
      },
      "id": "zQg1M3aaxtzE"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain\n",
        "# !pip install openai\n",
        "# !pip install python-dotenv\n",
        "# !pip install langchain-openai"
      ],
      "metadata": {
        "id": "7p8yMuGIsuVY"
      },
      "id": "7p8yMuGIsuVY",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "import json\n",
        "import langchain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "# Load environment variables from .env file\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "# Set the environment variable globally for libraries like LangChain\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "# Print the API key to confirm it's loaded correctly\n",
        "print(\"API Key loaded from .env:\",os.environ[\"OPENAI_API_KEY\"][0:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfNwmL50szJL",
        "outputId": "3ac1e38f-fc55-47e5-9ddb-8c90b38f6f69"
      },
      "id": "KfNwmL50szJL",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key loaded from .env: sk-proj-e1GUWruINPRnrozmiakkRM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQNfSg-CuYwu"
      },
      "id": "YQNfSg-CuYwu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "23oS2tqquYub"
      },
      "id": "23oS2tqquYub",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cZ9KB0iwuYib"
      },
      "id": "cZ9KB0iwuYib",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "dda2db90-b54b-422e-baff-2bd96faeaaeb",
      "metadata": {
        "id": "dda2db90-b54b-422e-baff-2bd96faeaaeb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Employee Review\n",
        "\n",
        "### **Key Concepts**\n",
        "\n",
        "1. **SequentialChain**:\n",
        "   - Manages multiple chains in a logical sequence where each chain's output feeds into the next as input.\n",
        "   - Ensures intermediate outputs (`review_summary`, `weaknesses`) are preserved for inspection or downstream use.\n",
        "\n",
        "2. **LLMChain**:\n",
        "   - Combines a prompt template and an LLM to perform specific tasks.\n",
        "   - Each chain has an input (like `review` or `weaknesses`) and a defined output (e.g., `review_summary`).\n",
        "\n",
        "3. **Prompt Engineering**:\n",
        "   - Thoughtfully designed prompts ensure each step focuses on a clear and actionable goal:\n",
        "     - Step 1: Summarize performance.\n",
        "     - Step 2: Extract weaknesses.\n",
        "     - Step 3: Propose solutions.\n",
        "\n",
        "4. **Reusable Outputs**:\n",
        "   - By specifying `output_key` for each chain, intermediate results are accessible for further use.\n",
        "\n",
        "5. **Scalability**:\n",
        "   - This modular design allows for easy addition of new steps or integration with external tools.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why This Workflow is Valuable**\n",
        "\n",
        "- **Automates Performance Review Analysis**:\n",
        "   - Reduces manual effort in summarizing reviews, identifying weaknesses, and designing improvement plans.\n",
        "\n",
        "- **Customizable**:\n",
        "   - Prompts can be adjusted to align with organizational goals or performance criteria.\n",
        "\n",
        "- **Transparent**:\n",
        "   - Intermediate outputs (`review_summary`, `weaknesses`) provide clear visibility into each step of the process.\n",
        "\n"
      ],
      "metadata": {
        "id": "uUkf-tIP6v-9"
      },
      "id": "uUkf-tIP6v-9"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2a6c1d04-1fe0-4386-8b3a-4535cbfaff43",
      "metadata": {
        "id": "2a6c1d04-1fe0-4386-8b3a-4535cbfaff43"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize the LLM (Language Learning Model) with the desired model and configuration\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)  # GPT-4 model with moderate creativity\n",
        "\n",
        "# Step 1: Define the first prompt template to summarize the performance review\n",
        "template1 = \"Give a summary of this employee's performance review:\\n{review}\"\n",
        "prompt1 = ChatPromptTemplate.from_template(template1)\n",
        "\n",
        "# Step 1: Create the first chain to generate a performance review summary\n",
        "chain_1 = LLMChain(\n",
        "    llm=llm,  # Use the LLM to process the prompt\n",
        "    prompt=prompt1,  # Prompt for summarizing the review\n",
        "    output_key=\"review_summary\"  # Key for storing the summary output\n",
        ")\n",
        "\n",
        "# Step 2: Define the second prompt template to extract key weaknesses\n",
        "template2 = \"Identify key employee weaknesses in this review summary:\\n{review_summary}\"\n",
        "prompt2 = ChatPromptTemplate.from_template(template2)\n",
        "\n",
        "# Step 2: Create the second chain to extract employee weaknesses\n",
        "chain_2 = LLMChain(\n",
        "    llm=llm,  # Use the same LLM for this task\n",
        "    prompt=prompt2,  # Prompt to identify weaknesses\n",
        "    output_key=\"weaknesses\"  # Key for storing the weaknesses output\n",
        ")\n",
        "\n",
        "# Step 3: Define the third prompt template to create a personalized improvement plan\n",
        "template3 = \"Create a personalized plan to help address and fix these weaknesses:\\n{weaknesses}\"\n",
        "prompt3 = ChatPromptTemplate.from_template(template3)\n",
        "\n",
        "# Step 3: Create the third chain to generate a personalized improvement plan\n",
        "chain_3 = LLMChain(\n",
        "    llm=llm,  # Use the same LLM for consistency\n",
        "    prompt=prompt3,  # Prompt for creating an improvement plan\n",
        "    output_key=\"final_plan\"  # Key for storing the final plan output\n",
        ")\n",
        "\n",
        "# Combine all the chains into a SequentialChain\n",
        "seq_chain = SequentialChain(\n",
        "    chains=[chain_1, chain_2, chain_3],  # Execute the chains sequentially\n",
        "    input_variables=['review'],  # Input required for the first chain\n",
        "    output_variables=['review_summary', 'weaknesses', 'final_plan'],  # Outputs from all chains\n",
        "    verbose=True  # Enable verbose mode to see detailed logs of each step\n",
        ")\n",
        "\n",
        "# The SequentialChain:\n",
        "# 1. Takes 'review' as input.\n",
        "# 2. Generates 'review_summary' from Chain 1.\n",
        "# 3. Uses 'review_summary' to generate 'weaknesses' in Chain 2.\n",
        "# 4. Uses 'weaknesses' to create 'final_plan' in Chain 3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0e6013f5-40c9-401b-9d45-98b52de1bb3f",
      "metadata": {
        "id": "0e6013f5-40c9-401b-9d45-98b52de1bb3f"
      },
      "outputs": [],
      "source": [
        "employee_review = '''\n",
        "Employee Information:\n",
        "Name: Joe Schmo\n",
        "Position: Software Engineer\n",
        "Date of Review: July 14, 2023\n",
        "\n",
        "Strengths:\n",
        "Joe is a highly skilled software engineer with a deep understanding of programming languages, algorithms, and software development best practices. His technical expertise shines through in his ability to efficiently solve complex problems and deliver high-quality code.\n",
        "\n",
        "One of Joe's greatest strengths is his collaborative nature. He actively engages with cross-functional teams, contributing valuable insights and seeking input from others. His open-mindedness and willingness to learn from colleagues make him a true team player.\n",
        "\n",
        "Joe consistently demonstrates initiative and self-motivation. He takes the lead in seeking out new projects and challenges, and his proactive attitude has led to significant improvements in existing processes and systems. His dedication to self-improvement and growth is commendable.\n",
        "\n",
        "Another notable strength is Joe's adaptability. He has shown great flexibility in handling changing project requirements and learning new technologies. This adaptability allows him to seamlessly transition between different projects and tasks, making him a valuable asset to the team.\n",
        "\n",
        "Joe's problem-solving skills are exceptional. He approaches issues with a logical mindset and consistently finds effective solutions, often thinking outside the box. His ability to break down complex problems into manageable parts is key to his success in resolving issues efficiently.\n",
        "\n",
        "Weaknesses:\n",
        "While Joe possesses numerous strengths, there are a few areas where he could benefit from improvement. One such area is time management. Occasionally, Joe struggles with effectively managing his time, resulting in missed deadlines or the need for additional support to complete tasks on time. Developing better prioritization and time management techniques would greatly enhance his efficiency.\n",
        "\n",
        "Another area for improvement is Joe's written communication skills. While he communicates well verbally, there have been instances where his written documentation lacked clarity, leading to confusion among team members. Focusing on enhancing his written communication abilities will help him effectively convey ideas and instructions.\n",
        "\n",
        "Additionally, Joe tends to take on too many responsibilities and hesitates to delegate tasks to others. This can result in an excessive workload and potential burnout. Encouraging him to delegate tasks appropriately will not only alleviate his own workload but also foster a more balanced and productive team environment.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "406813b0-b79d-4056-8dbc-923e1986df41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "406813b0-b79d-4056-8dbc-923e1986df41",
        "outputId": "02b4e8b7-d9a2-4365-e6b6-2443da0825cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-ba61d33de059>:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  results = seq_chain(employee_review)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "results = seq_chain(employee_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "be395801-2e84-4686-9203-3857f8b5934b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be395801-2e84-4686-9203-3857f8b5934b",
        "outputId": "aea73b88-5ce1-43c0-a62a-a49ed83b4436"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review', 'review_summary', 'weaknesses', 'final_plan'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "results.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results['review_summary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85soHqk18FGU",
        "outputId": "5f3ed9f8-e697-4364-b606-69e60e870a1f"
      },
      "id": "85soHqk18FGU",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Performance Review Summary for Joe Schmo**\n",
            "\n",
            "**Employee Information:**\n",
            "- **Name:** Joe Schmo\n",
            "- **Position:** Software Engineer\n",
            "- **Date of Review:** July 14, 2023\n",
            "\n",
            "**Strengths:**\n",
            "Joe Schmo is recognized as a highly skilled software engineer with strong proficiency in programming languages, algorithms, and best practices in software development. His technical capabilities allow him to effectively solve complex problems and produce high-quality code.\n",
            "\n",
            "Key strengths include:\n",
            "- **Collaboration:** Joe actively engages with cross-functional teams, sharing insights and valuing input from others, showcasing his team-oriented mindset.\n",
            "- **Initiative and Self-Motivation:** He proactively seeks out new projects and challenges, leading to significant enhancements in processes and systems.\n",
            "- **Adaptability:** Joe demonstrates flexibility in managing changing project requirements and quickly learns new technologies, making him a valuable team member.\n",
            "- **Problem-Solving Skills:** He employs a logical approach to issues and consistently generates effective solutions, breaking down complex problems into manageable components.\n",
            "\n",
            "**Weaknesses:**\n",
            "Despite his strengths, there are areas where Joe could improve:\n",
            "- **Time Management:** Joe occasionally struggles with managing his time effectively, which can lead to missed deadlines. Developing better prioritization techniques would enhance his efficiency.\n",
            "- **Written Communication:** While he communicates well verbally, his written documentation sometimes lacks clarity, causing confusion among team members. Improving this skill will help convey ideas more effectively.\n",
            "- **Delegation:** Joe tends to take on too many responsibilities and is hesitant to delegate tasks, which can lead to an overwhelming workload. Encouraging him to delegate appropriately could help balance his workload and foster a more productive team environment.\n",
            "\n",
            "Overall, Joe's performance reflects a strong technical foundation and a collaborative spirit, with opportunities for growth in time management, written communication, and delegation skills.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2edc6866-769b-47ee-921d-ae40eb9891eb",
      "metadata": {
        "id": "2edc6866-769b-47ee-921d-ae40eb9891eb",
        "outputId": "8efa354d-0d50-43f4-bca5-242f6cac33eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To address and fix these weaknesses, the following personalized plan can be implemented for Joe:\n",
            "\n",
            "1. Time management:\n",
            "\n",
            "- Set clear goals and priorities: Joe should start each day by identifying the most important tasks that need to be accomplished and prioritize them accordingly. This will help him stay focused and ensure that he completes critical tasks on time.\n",
            "- Break tasks into smaller, manageable chunks: Large projects can be overwhelming and lead to procrastination. Joe should break them down into smaller, more manageable tasks, setting specific deadlines for each subtask. This will help him track progress and stay on schedule.\n",
            "- Use time management tools: Joe can utilize various time management tools, such as calendars, task management apps, or project management software, to help him stay organized and prioritize tasks effectively.\n",
            "\n",
            "2. Written communication skills:\n",
            "\n",
            "- Seek feedback and guidance: Joe should actively seek feedback from his colleagues or supervisors on his written communication skills. This feedback can help identify specific areas for improvement and provide guidance on how to enhance his written communication abilities.\n",
            "- Take writing courses or workshops: Joe can enroll in writing courses or workshops to improve his written communication skills. These courses can provide him with practical tips and techniques for conveying information effectively and ensure that his written documentation, emails, and reports are clear and concise.\n",
            "- Practice writing regularly: Joe should make an effort to practice his writing skills regularly. This can include writing memos, reports, or even maintaining a personal blog. Regular practice will help him become more comfortable and proficient in conveying his ideas through written communication.\n",
            "\n",
            "3. Delegation of tasks:\n",
            "\n",
            "- Identify tasks suitable for delegation: Joe should assess his workload and identify tasks that can be delegated to others without compromising quality or efficiency. This will help him free up time for more critical tasks and develop trust in his colleagues' abilities.\n",
            "- Communicate expectations clearly: When delegating tasks, Joe should clearly communicate his expectations, including deadlines, desired outcomes, and any necessary guidelines or resources. This will ensure that delegated tasks are completed efficiently and effectively.\n",
            "- Provide support and feedback: Joe should offer support to colleagues to whom he delegates tasks. This can include providing resources, answering questions, or offering guidance when needed. Additionally, he should provide constructive feedback on completed tasks to help improve the overall delegation process.\n",
            "\n",
            "Regular self-assessments and discussions with supervisors or mentors can help track progress and identify any further areas of improvement. Implementing this personalized plan will enable Joe to address his weaknesses and enhance his overall performance as a software engineer.\n"
          ]
        }
      ],
      "source": [
        "print(results['final_plan'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Client Feedback"
      ],
      "metadata": {
        "id": "sfRULi52Ae7D"
      },
      "id": "sfRULi52Ae7D"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "15760213-e3a3-443a-9fe7-17d14c438ac5",
      "metadata": {
        "id": "15760213-e3a3-443a-9fe7-17d14c438ac5"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize the LLM (Language Learning Model) with the desired model and configuration\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)  # GPT-4 model with moderate creativity\n",
        "\n",
        "# Step 1: Define the first prompt template to summarize client feedback\n",
        "template1 = \"Summarize the following client feedback into key points:\\n{feedback}\"\n",
        "prompt1 = ChatPromptTemplate.from_template(template1)\n",
        "\n",
        "# Step 1: Create the first chain to generate a feedback summary\n",
        "chain_1 = LLMChain(\n",
        "    llm=llm,  # Use the LLM to process the prompt\n",
        "    prompt=prompt1,  # Prompt for summarizing the feedback\n",
        "    output_key=\"feedback_summary\"  # Key for storing the summary output\n",
        ")\n",
        "\n",
        "# Step 2: Define the second prompt template to identify client pain points\n",
        "template2 = \"Based on the feedback summary, identify the client's main pain points:\\n{feedback_summary}\"\n",
        "prompt2 = ChatPromptTemplate.from_template(template2)\n",
        "\n",
        "# Step 2: Create the second chain to extract client pain points\n",
        "chain_2 = LLMChain(\n",
        "    llm=llm,  # Use the same LLM for this task\n",
        "    prompt=prompt2,  # Prompt to identify pain points\n",
        "    output_key=\"pain_points\"  # Key for storing the pain points output\n",
        ")\n",
        "\n",
        "# Step 3: Define the third prompt template to create actionable recommendations\n",
        "template3 = (\n",
        "    \"Create actionable recommendations to address the following client pain points:\\n{pain_points}\"\n",
        ")\n",
        "prompt3 = ChatPromptTemplate.from_template(template3)\n",
        "\n",
        "# Step 3: Create the third chain to generate actionable recommendations\n",
        "chain_3 = LLMChain(\n",
        "    llm=llm,  # Use the same LLM for consistency\n",
        "    prompt=prompt3,  # Prompt for creating actionable recommendations\n",
        "    output_key=\"recommendations\"  # Key for storing the recommendations output\n",
        ")\n",
        "\n",
        "# Combine all the chains into a SequentialChain\n",
        "seq_chain = SequentialChain(\n",
        "    chains=[chain_1, chain_2, chain_3],  # Execute the chains sequentially\n",
        "    input_variables=['feedback'],  # Input required for the first chain\n",
        "    output_variables=['feedback_summary', 'pain_points', 'recommendations'],  # Outputs from all chains\n",
        "    verbose=True  # Enable verbose mode to see detailed logs of each step\n",
        ")\n",
        "\n",
        "# Example Input: Client Feedback\n",
        "client_feedback = \"\"\"\n",
        "The product is useful, but the onboarding process was very confusing.\n",
        "I also found the customer support to be unresponsive during critical times.\n",
        "Overall, it gets the job done, but I expected better communication and clearer instructions.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = seq_chain(client_feedback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KduhOJrAK1V",
        "outputId": "543d88d5-e048-471b-c39b-96b4c83e55fb"
      },
      "id": "2KduhOJrAK1V",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Results\n",
        "print(\"Feedback Summary:\\n\", output['feedback_summary'])\n",
        "print(\"\\nClient Pain Points:\\n\", output['pain_points'])\n",
        "print(\"\\nActionable Recommendations:\\n\", output['recommendations'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLSgKWQ9_995",
        "outputId": "de91060a-861b-4698-b057-3db4203408de"
      },
      "id": "WLSgKWQ9_995",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedback Summary:\n",
            " Key Points from Client Feedback:\n",
            "\n",
            "1. Product is useful and effective.\n",
            "2. Onboarding process was confusing.\n",
            "3. Customer support was unresponsive during critical times.\n",
            "4. Expected better communication and clearer instructions.\n",
            "\n",
            "Client Pain Points:\n",
            " Based on the feedback summary, the client's main pain points are:\n",
            "\n",
            "1. **Confusing Onboarding Process**: The client found the onboarding process to be unclear, which may hinder their ability to fully utilize the product effectively.\n",
            "\n",
            "2. **Unresponsive Customer Support**: The client experienced issues with customer support being unresponsive during critical times, which likely exacerbated their confusion and frustration.\n",
            "\n",
            "3. **Lack of Clear Communication and Instructions**: The client expected better communication and clearer instructions, indicating a need for more comprehensive guidance and support throughout their experience with the product. \n",
            "\n",
            "These pain points highlight areas where the client feels improvements are necessary for a better overall experience.\n",
            "\n",
            "Actionable Recommendations:\n",
            " To address the client pain points effectively, here are actionable recommendations for each identified issue:\n",
            "\n",
            "### 1. Confusing Onboarding Process\n",
            "\n",
            "**Actionable Recommendations:**\n",
            "- **Revamp Onboarding Materials**: Create a streamlined onboarding guide that includes step-by-step instructions, visual aids (e.g., screenshots or video tutorials), and FAQs to clarify the process.\n",
            "- **Interactive Onboarding Sessions**: Offer live webinars or interactive onboarding sessions where users can ask questions in real-time and receive immediate assistance.\n",
            "- **Personalized Onboarding**: Assign a dedicated onboarding specialist to each new client for the first few weeks. This specialist can provide tailored support based on the client's specific needs and usage scenarios.\n",
            "- **Feedback Loop**: Implement a feedback mechanism (like a short survey) at the end of the onboarding process to gather insights and continuously improve the onboarding experience.\n",
            "\n",
            "### 2. Unresponsive Customer Support\n",
            "\n",
            "**Actionable Recommendations:**\n",
            "- **Enhance Support Channels**: Ensure multiple support channels are available (e.g., phone, email, live chat, and social media) and promote them prominently on the website and within the product.\n",
            "- **Implement a Support Ticketing System**: Adopt a ticketing system that allows clients to submit issues and track the status of their inquiries. This transparency can help clients feel more informed about their support requests.\n",
            "- **Set Response Time Standards**: Establish and communicate clear response time standards for different support channels (e.g., 24-hour response for emails, immediate assistance via live chat) to manage client expectations.\n",
            "- **Regular Training for Support Staff**: Provide regular training for customer support representatives to ensure they are knowledgeable about the product and equipped to handle inquiries efficiently.\n",
            "\n",
            "### 3. Lack of Clear Communication and Instructions\n",
            "\n",
            "**Actionable Recommendations:**\n",
            "- **Create a Resource Hub**: Develop a centralized online resource hub containing comprehensive documentation, video tutorials, and user guides that clients can easily access at any time.\n",
            "- **Regular Updates and Check-ins**: Schedule periodic check-ins (via email or calls) with clients to provide updates on new features, gather feedback, and remind them of available resources.\n",
            "- **Standardize Communication Templates**: Develop standardized communication templates for common scenarios (e.g., onboarding, troubleshooting, feature updates) to ensure clarity and consistency in messaging.\n",
            "- **Client Advisory Board**: Establish a client advisory board to provide feedback on communication practices and product usability. This can help identify areas for improvement and foster a sense of collaboration.\n",
            "\n",
            "### Implementation Strategy\n",
            "\n",
            "1. **Timeline**: Set a clear timeline for implementing these recommendations, with milestones for each phase (e.g., onboarding revamp, support enhancements, resource creation).\n",
            "2. **Assign Responsibilities**: Designate team members or departments responsible for each recommendation to ensure accountability and progress tracking.\n",
            "3. **Monitor and Evaluate**: After implementation, continuously monitor client feedback and support metrics to evaluate the effectiveness of these changes and make adjustments as necessary.\n",
            "4. **Celebrate Successes**: Share success stories and improvements with the team and clients to reinforce the value of these changes and encourage ongoing engagement.\n",
            "\n",
            "By addressing these pain points through specific, actionable steps, the client can significantly enhance their experience and satisfaction with the product.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Email Writing Function:**\n",
        "\n",
        "This function demonstrates how to use **LangChain's RunnablePipeline** to create a multi-step workflow for generating and summarizing a professional email. It integrates an LLM (OpenAI GPT-40-mini) to:\n",
        "\n",
        "1. **Generate a professional email draft** based on the recipient's name and the email's purpose.\n",
        "2. **Summarize the email** into a concise one-sentence summary, which could serve as a subject line or a quick preview.\n",
        "\n",
        "The workflow ensures both outputs—the full email and the summary—are returned for further use.\n",
        "\n",
        "---\n",
        "\n",
        "### **What This Function Does:**\n",
        "\n",
        "1. **Input Handling**:\n",
        "   - Accepts structured input (`name` and `purpose`) and processes it through a pipeline.\n",
        "\n",
        "2. **Email Drafting**:\n",
        "   - Uses a prompt to instruct the LLM to generate a formal email.\n",
        "\n",
        "3. **Summarization**:\n",
        "   - Processes the email draft through another prompt to produce a summary.\n",
        "---\n",
        "\n",
        "### **Key Lessons:**\n",
        "\n",
        "1. **Modularity**:\n",
        "   - The pipeline is built with reusable components (`RunnableMap`, `RunnablePassthrough`, `RunnableLambda`), making it easy to expand or adjust for other tasks.\n",
        "\n",
        "2. **Chaining Outputs**:\n",
        "   - Outputs from one step feed into the next, demonstrating how LangChain facilitates multi-step workflows.\n",
        "\n",
        "3. **Content Extraction**:\n",
        "   - Handling LLM outputs like `AIMessage` and converting them into plain strings is essential for compatibility in complex pipelines.\n",
        "\n",
        "4. **Parallel Processing**:\n",
        "   - `RunnableMap` enables splitting outputs (e.g., email draft and summary) for simultaneous or independent processing.\n",
        "\n",
        "5. **Prompt Engineering**:\n",
        "   - Thoughtful prompts guide the LLM's behavior, demonstrating how different tasks (drafting and summarization) can be performed in sequence.\n",
        "\n",
        "---\n",
        "\n",
        "### **Use Cases and Applications:**\n",
        "\n",
        "- **Email Automation**:\n",
        "   - Draft professional emails and generate subject lines or summaries for preview or categorization.\n",
        "\n",
        "- **Multi-Step Workflows**:\n",
        "   - Useful for any task requiring generation, refinement, or summarization of content.\n",
        "\n",
        "- **Scalability**:\n",
        "   - The modular structure supports integration with additional tools (e.g., email-sending APIs, CRMs).\n",
        "\n",
        "This function showcases how LangChain empowers developers to build structured, multi-step workflows that leverage LLMs efficiently and flexibly."
      ],
      "metadata": {
        "id": "X6t7HLC-5wfQ"
      },
      "id": "X6t7HLC-5wfQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema.runnable import RunnableMap\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "\n",
        "# Step 1: Define the LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "\n",
        "# Step 2: Define prompt templates for each task\n",
        "# Task 1: Create an email draft\n",
        "email_prompt = PromptTemplate(\n",
        "    input_variables=[\"name\", \"purpose\"],\n",
        "    template=(\n",
        "        \"Write a professional email addressed to {name} \"\n",
        "        \"with the purpose of {purpose}. Use a formal tone.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Task 2: Summarize the email\n",
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"email_draft\"],\n",
        "    template=(\n",
        "        \"Summarize the following email in one sentence:\\n\\n{email_draft}\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Step 3: Define a lambda to extract `AIMessage` content\n",
        "extract_content = RunnableLambda(lambda x: x.content if hasattr(x, 'content') else x)\n",
        "\n",
        "# Step 4: Define the pipeline\n",
        "sequential_chain = (\n",
        "    {\n",
        "        \"name\": RunnablePassthrough(),\n",
        "        \"purpose\": RunnablePassthrough()\n",
        "    }  # Pass inputs directly\n",
        "    | email_prompt  # Generate the email prompt\n",
        "    | llm  # Generate the email\n",
        "    | extract_content  # Extract content from AIMessage\n",
        "    | RunnableMap(  # Map outputs for both email and summary\n",
        "        {\n",
        "            \"email_draft\": RunnablePassthrough(),  # Pass through the email draft\n",
        "            \"summary\": summary_prompt | llm | extract_content  # Summarize and extract content\n",
        "        }\n",
        "    )\n",
        ")\n",
        "\n",
        "# Step 5: Run the chain with input\n",
        "inputs = {\"name\": \"Dr. Smith\", \"purpose\": \"scheduling a follow-up meeting\"}\n",
        "output = sequential_chain.invoke(inputs)\n",
        "\n",
        "# Print results\n",
        "print(\"Generated Email Draft:\\n\", output[\"email_draft\"])\n",
        "print(\"\\nGenerated Summary:\\n\", output[\"summary\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpfvK-i25TUV",
        "outputId": "18916608-fdc8-4478-e8c9-c0e4e039e8c8"
      },
      "id": "FpfvK-i25TUV",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Email Draft:\n",
            " Subject: Request for Follow-up Meeting \n",
            "\n",
            "Dear Dr. Smith,\n",
            "\n",
            "I trust you are in good health. I am writing to express my interest in scheduling a follow-up meeting with you in the coming weeks.\n",
            "\n",
            "Our previous meeting was enlightening and allowed us to touch base on several crucial points of our ongoing project. However, I believe that there are additional items that require our attention and in-depth discussion. These items are integral to the successful completion of our project.\n",
            "\n",
            "Given the importance of these matters, I propose that we convene a follow-up meeting at a time that best suits your schedule. I am flexible and can adjust my availability accordingly.\n",
            "\n",
            "Should you agree, kindly let me know your preferred date and time so that I may organize the necessary documents and prepare for our meeting.\n",
            "\n",
            "Thank you in advance for your consideration. I look forward to our continued collaboration.\n",
            "\n",
            "Best Regards,\n",
            "\n",
            "[Your Name] \n",
            "\n",
            "[Your Position]\n",
            "\n",
            "[Your Contact Information]\n",
            "\n",
            "Generated Summary:\n",
            " The sender of the email is requesting a follow-up meeting with Dr. Smith to discuss additional important items related to their ongoing project and is offering to adjust to Dr. Smith's schedule for the meeting.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}