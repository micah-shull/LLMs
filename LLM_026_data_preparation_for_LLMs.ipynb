{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPTQnFLlfUuRPCtaJks5sCx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/LLMs/blob/main/LLM_026_data_preparation_for_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Key Steps in Data Preparation for LLMs\n",
        "\n",
        "1. **Text Cleaning and Preprocessing**\n",
        "   - Standardize the text (e.g., remove special characters, fix formatting).\n",
        "   - Handle language-specific requirements, like stemming or lemmatization, if needed.\n",
        "\n",
        "2. **Tokenization**\n",
        "   - Tokenize text data into subwords, words, or characters, depending on the model’s requirements.\n",
        "   - Add padding and truncation as needed to create consistent input sizes.\n",
        "\n",
        "3. **Formatting for LLM-Specific Inputs**\n",
        "   - Structure the data into the required input format (e.g., sequences, key-value pairs).\n",
        "   - Add special tokens (e.g., `[CLS]`, `[SEP]`, or `<|endoftext|>` tokens) as required by the model.\n",
        "\n",
        "4. **Creating Attention Masks**\n",
        "   - Generate attention masks that help the model distinguish real tokens from padding tokens, essential for handling variable-length input.\n",
        "\n",
        "5. **Converting Labels to the Correct Format**\n",
        "   - Ensure labels are in the correct numerical or categorical format for classification, regression, or other tasks.\n",
        "\n",
        "6. **Batching and Preparing for Training**\n",
        "   - Organize the data into batches compatible with your LLM for efficient processing during training.\n",
        "\n"
      ],
      "metadata": {
        "id": "Bi9OvaXmO5U8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation for LLMs\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Import and Inspect IMDb Data**\n",
        "\n",
        "   - **Objective**: Load the IMDb data from Hugging Face and understand its structure.\n",
        "   - **Key Concepts**: Dataset format (splits, columns), and overall data layout.\n",
        "   - **Actions**: Load the data, inspect samples, and note features like text, labels, and any additional metadata.\n",
        "\n",
        "#### **2. Deconstruct the Data into Components**\n",
        "\n",
        "   - **Objective**: Break down the data into its raw components, such as:\n",
        "     - Text content (raw reviews).\n",
        "     - Labels (sentiment labels).\n",
        "   - **Key Concepts**: Understand the individual pieces of information (e.g., input text, labels) required to format data for training.\n",
        "\n",
        "#### **3. Text Cleaning and Preprocessing**\n",
        "\n",
        "   - **Objective**: Go over basic text preprocessing steps, even though the IMDb dataset is relatively clean.\n",
        "   - **Key Concepts**: Standardizing text (lowercasing, removing special characters if necessary), optional stemming or lemmatization.\n",
        "   - **Actions**: Apply text cleaning functions, understand why each step is (or isn’t) needed.\n",
        "\n",
        "#### **4. Tokenization**\n",
        "\n",
        "   - **Objective**: Re-tokenize the text to understand how it’s prepared for an LLM.\n",
        "   - **Key Concepts**:\n",
        "     - Tokenizer functions like `encode`, `decode`, `tokenize`.\n",
        "     - Padding, truncation, and token length consistency.\n",
        "   - **Actions**: Tokenize individual examples, explore padding/truncation options, and understand how tokenizers work with special tokens for transformers.\n",
        "\n",
        "#### **5. Formatting Inputs for the Model**\n",
        "\n",
        "   - **Objective**: Reassemble the tokenized data to create the full model input format.\n",
        "   - **Key Concepts**:\n",
        "     - Adding special tokens like `[CLS]` and `[SEP]` (or equivalents for different models).\n",
        "     - Structuring data for batch processing.\n",
        "   - **Actions**: Use the tokenizer’s methods to add special tokens and reformat inputs into consistent-length sequences.\n",
        "\n",
        "#### **6. Generating Attention Masks**\n",
        "\n",
        "   - **Objective**: Create attention masks to handle padding effectively.\n",
        "   - **Key Concepts**: Purpose and format of attention masks, where `1` represents real tokens and `0` represents padding.\n",
        "   - **Actions**: Generate attention masks based on tokenized sequences.\n",
        "\n",
        "#### **7. Label Processing**\n",
        "\n",
        "   - **Objective**: Ensure that labels are in the correct numerical format for binary classification.\n",
        "   - **Key Concepts**: Converting categorical labels to integers or tensors, ensuring compatibility with LLM training requirements.\n",
        "   - **Actions**: Map labels like “pos” and “neg” to numerical values, and prepare them in tensor format for PyTorch models.\n",
        "\n",
        "#### **8. Putting It All Together**\n",
        "\n",
        "   - **Objective**: Reassemble the cleaned, tokenized, and formatted inputs into a final dataset compatible with an LLM.\n",
        "   - **Key Concepts**: Wrapping everything into a `Dataset` object (like the custom `IMDbDataset` class we previously discussed) to use for training.\n",
        "   - **Actions**: Combine text, tokenized inputs, attention masks, and labels into a structured dataset ready for training.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary\n",
        "\n",
        "This approach will give you hands-on experience with each stage of data preparation by deconstructing and reassembling the IMDb dataset. Along the way, you’ll gain insights into the steps required to format data for an LLM, preparing you for when you want to work with your own raw datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "KLxRv-VxPZSO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BIzY5ANmOF8m"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers datasets\n",
        "# !pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('/content/huggingface_api_key.env')\n",
        "api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
        "os.environ[\"HF_TOKEN\"] = api_key\n",
        "\n",
        "# Load the Amazon Reviews dataset\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Inspect the structure of the dataset\n",
        "print(\"Dataset structure:\", dataset)\n",
        "\n",
        "# Print a few examples from the training set\n",
        "print(\"\\nSample IMDb data:\")\n",
        "for i in range(3):\n",
        "    print(f\"Review {i+1}:\")\n",
        "    print(\"Text:\", dataset[\"train\"][i][\"text\"])\n",
        "    print(\"Label:\", \"Positive\" if dataset[\"train\"][i][\"label\"] == 1 else \"Negative\")\n",
        "    print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CATjN8jWPiGi",
        "outputId": "d2c13a04-679e-41e1-ecff-a8ecdc43959d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset structure: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    unsupervised: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n",
            "\n",
            "Sample IMDb data:\n",
            "Review 1:\n",
            "Text: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
            "Label: Negative\n",
            "==================================================\n",
            "Review 2:\n",
            "Text: \"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.\n",
            "Label: Negative\n",
            "==================================================\n",
            "Review 3:\n",
            "Text: If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\n",
            "Label: Negative\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HuggingFace Data Structure\n",
        "\n",
        "The structure of the data at this point is a **`DatasetDict`** containing multiple **`Dataset`** objects for different splits (e.g., `train`, `test`, and `unsupervised`). Here’s a deeper look at this structure and its implications:\n",
        "\n",
        "### 1. **DatasetDict Overview**\n",
        "\n",
        "- **`DatasetDict`**: This is a specialized dictionary provided by the Hugging Face `datasets` library. It acts as a container for different data splits (`train`, `test`, etc.), making it easy to access and work with each split individually.\n",
        "- **Each Key**: The keys (`train`, `test`, `unsupervised`) represent the different splits of the dataset.\n",
        "- **Value (Dataset)**: Each value is a `Dataset` object containing the actual data and metadata (features, rows) for that split.\n",
        "\n",
        "### 2. **Dataset Object Structure**\n",
        "\n",
        "Each `Dataset` object (e.g., `dataset[\"train\"]`) has the following structure:\n",
        "\n",
        "- **Features**: A list of fields (or columns) in the dataset. For IMDb, these are:\n",
        "  - `text`: Contains the raw movie review text.\n",
        "  - `label`: An integer representing the sentiment label (1 for positive, 0 for negative).\n",
        "- **Num_rows**: Shows the number of rows (or samples) in the split. Here:\n",
        "  - `train` and `test` each contain 25,000 rows.\n",
        "  - `unsupervised` contains 50,000 rows, although it isn’t labeled for sentiment.\n",
        "\n",
        "Each row in the `Dataset` is a **dictionary** with the keys `text` and `label`, where:\n",
        "- **text**: Stores the movie review.\n",
        "- **label**: Stores the integer sentiment label.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Practical Example of Accessing the Data\n",
        "\n",
        "Each row is a dictionary, so accessing an individual sample might look like this:\n",
        "\n",
        "```python\n",
        "sample = dataset[\"train\"][0]\n",
        "print(sample)  # Output: {'text': '...', 'label': 1}\n",
        "```\n",
        "\n",
        "### 4. Implications for Model Training\n",
        "\n",
        "The **structure of the data does not need to stay as a `DatasetDict`** for model training. However, this structure is convenient for:\n",
        "- **Data Management**: Separating `train` and `test` splits.\n",
        "- **Accessing Rows**: Accessing samples by index and working with them in dictionaries simplifies handling individual text-label pairs.\n",
        "\n",
        "When preparing data for the model, you’ll need to further process each row:\n",
        "- **Tokenize** the text.\n",
        "- **Convert labels** to tensors or compatible formats.\n",
        "- **Reassemble** the data into a structure compatible with your training framework (e.g., PyTorch `Dataset` or a Hugging Face `Trainer` dataset).\n",
        "\n",
        "### Summary\n",
        "\n",
        "- The initial structure is a **`DatasetDict` of `Dataset` objects**.\n",
        "- Each sample is a **dictionary** with `text` and `label` fields.\n",
        "- For training, we will transform each sample (text and label) to meet model requirements, but the initial structure is ideal for exploration and preprocessing.\n",
        "\n",
        "Let me know if you’d like to move on to **Step 2: Deconstructing the Data into Components** or if you have questions about this structure!"
      ],
      "metadata": {
        "id": "fJ2TXylfSFdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract labels and documents from the IMDb dataset\n",
        "documents = dataset[\"train\"][\"text\"]\n",
        "labels = [\"pos\" if label == 1 else \"neg\" for label in dataset[\"train\"][\"label\"]]\n",
        "\n",
        "# Calculate and print value counts for labels\n",
        "label_counts = pd.Series(labels).value_counts()\n",
        "\n",
        "# Calculate review lengths\n",
        "review_lengths = [len(review.split()) for review in documents]\n",
        "\n",
        "# Create a 1x2 grid for the plots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Label Distribution\n",
        "axes[0].bar(label_counts.index, label_counts.values, color=['skyblue', 'salmon'])\n",
        "axes[0].set_title(\"IMDb Reviews Sentiment Distribution\")\n",
        "axes[0].set_xlabel(\"Sentiment\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "axes[0].set_xticks(range(len(label_counts.index)))\n",
        "axes[0].set_xticklabels([\"Positive\", \"Negative\"])\n",
        "\n",
        "# Plot 2: Review Length Distribution\n",
        "axes[1].hist(review_lengths, bins=30, color='gold', alpha=0.7)\n",
        "axes[1].set_title(\"Distribution of Review Lengths in IMDb Reviews\")\n",
        "axes[1].set_xlabel(\"Number of Words\")\n",
        "axes[1].set_ylabel(\"Frequency\")\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display basic statistics\n",
        "print(\"Review Length Statistics:\")\n",
        "print(\"Mean Length:\", sum(review_lengths) / len(review_lengths))\n",
        "print(\"Max Length:\", max(review_lengths))\n",
        "print(\"Min Length:\", min(review_lengths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "BP069lG7QhVu",
        "outputId": "9e8d8fcc-cc0f-4760-da20-9ba8d74426ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review Length Statistics:\n",
            "Mean Length: 233.7872\n",
            "Max Length: 2470\n",
            "Min Length: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split into Samples & Labels\n",
        "In this setup, the data structures we’re working with are simple lists, not dictionaries. Here’s how they break down:\n",
        "\n",
        "#### Sample the Data\n",
        "1. **Single Split Sampling**: Since we’re focusing on training data preparation, we simplified the code to sample only from `train_texts` and `train_labels`.\n",
        "2. **Simplified Labels**: We’re using the raw labels (`0` or `1`) directly instead of converting them to strings (“pos” or “neg”) since this matches the original label format.\n",
        "\n",
        "This code will provide a random 5% sample of the training data, reducing memory usage and making it easier to work within a notebook environment.\n",
        "\n",
        "\n",
        "\n",
        "### Key Data Structures\n",
        "\n",
        "1. **`sampled_texts`**: This is a **list of strings**.\n",
        "   - Each element in `sampled_texts` is a string representing a movie review.\n",
        "   - Example structure: `[\"I loved this movie!\", \"It was boring...\", ...]`\n",
        "\n",
        "2. **`sampled_labels`**: This is a **list of integers**.\n",
        "   - Each element in `sampled_labels` is an integer representing the sentiment label for the corresponding review in `sampled_texts`.\n",
        "   - Labels are `1` for positive and `0` for negative sentiment.\n",
        "   - Example structure: `[1, 0, 1, 1, 0, ...]`\n",
        "\n",
        "### Relationship Between `sampled_texts` and `sampled_labels`\n",
        "\n",
        "- **Index-Based Pairing**: Each review in `sampled_texts` corresponds to a label in `sampled_labels` by index. For instance:\n",
        "   - `sampled_texts[0]` has its label in `sampled_labels[0]`.\n",
        "   - `sampled_texts[1]` has its label in `sampled_labels[1]`, and so on.\n",
        "\n",
        "### Why Lists Are Useful Here\n",
        "\n",
        "- **Simplicity**: Lists allow us to quickly inspect and manipulate the text and labels, making them ideal for exploration and data preparation.\n",
        "- **Flexibility**: Later on, we can easily combine these lists into a structured format (e.g., a PyTorch `Dataset` object) for training."
      ],
      "metadata": {
        "id": "yCF30-AdSZJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Set the sample fraction (e.g., 5%) for a smaller subset of the data\n",
        "sample_fraction = 0.05\n",
        "\n",
        "# Extract text reviews and labels from the training set\n",
        "train_texts = dataset[\"train\"][\"text\"]\n",
        "train_labels = dataset[\"train\"][\"label\"]\n",
        "train_sample_size = int(len(train_texts) * sample_fraction)\n",
        "\n",
        "# Randomly sample reviews and labels from the training set\n",
        "random.seed(42)\n",
        "sample_indices = random.sample(range(len(train_texts)), train_sample_size)\n",
        "sampled_texts = [train_texts[i] for i in sample_indices]\n",
        "sampled_labels = [train_labels[i] for i in sample_indices]\n",
        "\n",
        "# Print the first few examples of the sampled data to confirm the extraction\n",
        "print(\"Sample Text Reviews:\")\n",
        "for i in range(3):\n",
        "    print(f\"Review {i+1}: {sampled_texts[i]}\")\n",
        "\n",
        "print(\"\\nSample Labels:\")\n",
        "print(\"Labels:\", sampled_labels[:3])  # Display the first few labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpHqUZ1fQlmG",
        "outputId": "2087b767-7a4d-41f1-de35-439830879da2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Text Reviews:\n",
            "Review 1: Arguably this is a very good \"sequel\", better than the first live action film 101 Dalmatians. It has good dogs, good actors, good jokes and all right slapstick! <br /><br />Cruella DeVil, who has had some rather major therapy, is now a lover of dogs and very kind to them. Many, including Chloe Simon, owner of one of the dogs that Cruella once tried to kill, do not believe this. Others, like Kevin Shepherd (owner of 2nd Chance Dog Shelter) believe that she has changed. <br /><br />Meanwhile, Dipstick, with his mate, have given birth to three cute dalmatian puppies! Little Dipper, Domino and Oddball...<br /><br />Starring Eric Idle as Waddlesworth (the hilarious macaw), Glenn Close as Cruella herself and Gerard Depardieu as Le Pelt (another baddie, the name should give a clue), this is a good family film with excitement and lots more!! One downfall of this film is that is has a lot of painful slapstick, but not quite as excessive as the last film. This is also funnier than the last film.<br /><br />Enjoy \"102 Dalmatians\"! :-)\n",
            "Review 2: It's a good thing I didn't watch this while i was pregnant.I definitely would have cried my eyes out and/or vomit. It was Kind of gruesome mainly disturbing. I personally thought the baby was adorable in its own twisted little way.However as a mom I cringed when Beth stabbed herself in the stomach and when Virgina aborted the child during her 3rd trimester with rusty utensils no less.Also,as an animal lover i almost cried when she scratched the cat to a bloody pulp.However,As creepy and sinister as the baby was I was rooting for it to live.And as twisted as the movie was I am extremely intrigued to see the sequel...... ......... ....... ......... ......... ....... ...... .....\n",
            "Review 3: This has to be the worst movie I have seen. Madsen fans don't be drawn into this like I was. He is only in it for a maximum of five minutes. This movie is so bad that the only reason why you would watch it is if all the rest of the movies on earth as well as t.v. had been destroyed.\n",
            "\n",
            "Sample Labels:\n",
            "Labels: [1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Cleaning and Preprocessing\n",
        "\n",
        "In this step, we’ll:\n",
        "1. **Standardize the Text**: This includes lowercasing and removing any unnecessary characters to simplify the data.\n",
        "2. **Optional Cleaning**: For some applications, you might also consider removing stop words or stemming/lemmatizing words, though it’s usually less critical with large language models since they are often robust to these variations.\n",
        "\n",
        "Since the IMDb dataset is relatively clean, we’ll focus on basic standardization.\n",
        "\n",
        "---\n",
        "\n",
        "### Text Cleaning and Preprocessing\n",
        "\n",
        "Here’s a simple function to preprocess the text by lowercasing and removing any special characters that might not add value to the analysis. This function will apply to each review in `sampled_texts`.\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of the Cleaning Function\n",
        "\n",
        "- **Lowercasing**: Lowercasing the text reduces variations in words (e.g., \"Great\" and \"great\" are treated the same).\n",
        "- **Removing Special Characters**: The regular expression `[^a-zA-Z0-9\\s.,!?']+` keeps only letters, numbers, spaces, and basic punctuation marks (like periods and commas) while removing other special characters. This can reduce noise in the data.\n",
        "\n",
        "### Key Lessons\n",
        "\n",
        "1. **Basic Standardization**: Lowercasing and removing special characters can help reduce variability in the text, making tokenization and model processing more consistent.\n",
        "2. **Flexible Preprocessing**: The cleaning function is adaptable, so you can add or remove steps based on the specific requirements of your dataset or model.\n",
        "\n",
        "Once you’ve inspected the cleaned text and are satisfied, let’s move on to **Step 4: Tokenization**. Let me know if you have questions about this step or if you’re ready to proceed!"
      ],
      "metadata": {
        "id": "IPori607VXhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Remove special characters (keeping only letters, numbers, and basic punctuation)\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s.,!?']+\", \"\", text)\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to each text review\n",
        "cleaned_texts = [clean_text(review) for review in sampled_texts]\n",
        "\n",
        "# Print a few examples to confirm the cleaning\n",
        "print(\"Cleaned Sample Text Reviews:\")\n",
        "for i in range(3):\n",
        "    print(f\"Review {i+1}: {cleaned_texts[i]}\")"
      ],
      "metadata": {
        "id": "tk-jFuFUVbCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What is Lemmatization ??\n",
        "\n",
        "**Lemmatization** is a common text preprocessing step that reduces words to their base or dictionary form, known as the “lemma.” This can be helpful for standardizing words that have similar meanings but different forms (e.g., \"running,\" \"runs,\" and \"run\" all reduce to \"run\"). Although it’s not always essential for LLMs (which often handle these variations well), learning lemmatization is valuable for general NLP preprocessing.\n",
        "\n",
        "Let’s go over how to implement it using **NLTK** (a popular NLP library) and **spaCy** (another common library for NLP tasks).\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Lemmatization with NLTK\n",
        "\n",
        "First, install NLTK if it’s not already installed:\n",
        "\n",
        "```bash\n",
        "pip install nltk\n",
        "```\n",
        "\n",
        "Then, here’s how to use NLTK for lemmatization:\n",
        "\n",
        "```python\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')  # Download WordNet data for lemmatization\n",
        "nltk.download('omw-1.4')  # Download additional resources\n",
        "\n",
        "# Initialize the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Example lemmatization function using NLTK\n",
        "def lemmatize_text(text):\n",
        "    words = text.split()  # Split text into words\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Apply lemmatization to each text review\n",
        "lemmatized_texts = [lemmatize_text(review) for review in cleaned_texts]\n",
        "\n",
        "# Print a few examples to see the effects of lemmatization\n",
        "print(\"Lemmatized Sample Text Reviews:\")\n",
        "for i in range(3):\n",
        "    print(f\"Review {i+1}: {lemmatized_texts[i]}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Lemmatization with spaCy\n",
        "\n",
        "If you prefer, you can use spaCy, which provides more advanced linguistic processing. Install spaCy and download its English model:\n",
        "\n",
        "```bash\n",
        "pip install spacy\n",
        "python -m spacy download en_core_web_sm\n",
        "```\n",
        "\n",
        "Then, here’s how to use spaCy for lemmatization:\n",
        "\n",
        "```python\n",
        "import spacy\n",
        "\n",
        "# Load the English model in spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example lemmatization function using spaCy\n",
        "def lemmatize_text_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    lemmatized_words = [token.lemma_ for token in doc]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Apply lemmatization to each text review\n",
        "lemmatized_texts_spacy = [lemmatize_text_spacy(review) for review in cleaned_texts]\n",
        "\n",
        "# Print a few examples to see the effects of lemmatization\n",
        "print(\"Lemmatized Sample Text Reviews (spaCy):\")\n",
        "for i in range(3):\n",
        "    print(f\"Review {i+1}: {lemmatized_texts_spacy[i]}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Key Differences Between NLTK and spaCy\n",
        "\n",
        "- **NLTK**: Provides simple word-level lemmatization without considering the context of the word in a sentence. It’s lightweight and effective for simpler tasks.\n",
        "- **spaCy**: Performs lemmatization with context, using language models to better determine the correct lemma based on sentence structure.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Should You Lemmatize Before Tokenization?**\n",
        "   - **Typically Not Required for LLMs**: For large language models like BERT or GPT-based models, lemmatization isn’t usually necessary. These models are trained on vast amounts of data, so they inherently learn the relationships between words, including variations in tense, pluralization, and other forms.\n",
        "   - **When It Might Help**: Lemmatization can be helpful if you’re working with a simple, smaller model or with tasks where reducing vocabulary size is essential (e.g., if you want to limit the number of unique words to improve training speed).\n",
        "\n",
        "### 2. **Impact on Model Performance**\n",
        "   - **Reduced Vocabulary**: Lemmatization can reduce the vocabulary size by mapping different forms of a word (e.g., \"running,\" \"runs,\" \"run\") to a single base form. This can be beneficial if vocabulary reduction is critical.\n",
        "   - **Potential Loss of Nuance**: For sentiment analysis and other nuanced tasks, lemmatization might remove information that the model could otherwise use. For example, \"running\" and \"ran\" might imply different contexts in reviews, and reducing them both to \"run\" could remove subtle but useful distinctions.\n",
        "   - **Performance on Pre-Trained Models**: Pre-trained LLMs are trained on unaltered text, so applying lemmatization may misalign the data with the patterns learned during pre-training, which could reduce performance.\n",
        "\n",
        "### 3. **Standard Protocol**\n",
        "   - **Skip Lemmatization for Large LLMs**: The standard approach with large, pre-trained language models (like those in Hugging Face’s Transformers library) is to skip lemmatization. These models are already well-equipped to understand word relationships and meanings, so additional lemmatization usually isn’t beneficial.\n",
        "   - **Consider Lemmatization for Smaller, Custom Models**: For simpler models or custom neural networks where reducing vocabulary is necessary to save memory or processing power, lemmatization might be worth considering.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary Recommendation\n",
        "\n",
        "For this lesson, I recommend **skipping lemmatization** before tokenization. This will align our dataset with the training data typically used for LLMs, ensuring consistency and potentially better performance. Tokenization alone will handle most of the standardization, so we’ll proceed with raw, unaltered text from here.\n",
        "\n",
        "Exactly! For simpler models like **Logistic Regression (LogReg)**, **Naive Bayes**, or even **Support Vector Machines (SVM)**, lemmatization (and sometimes stemming) can be quite helpful. Here’s why it makes a difference with these types of models:\n",
        "\n",
        "### Why Lemmatization Helps with Simple Models\n",
        "\n",
        "1. **Reduced Vocabulary Size**:\n",
        "   - Simpler models don’t have the capacity to handle large, complex vocabularies as effectively as large language models (LLMs).\n",
        "   - Lemmatization helps by reducing the number of unique words, which can improve the model’s efficiency and reduce memory usage.\n",
        "\n",
        "2. **Improved Signal-to-Noise Ratio**:\n",
        "   - By mapping words like \"running,\" \"runs,\" and \"run\" to a common base form, lemmatization helps these models focus on the core meaning of each word, rather than getting distracted by variations.\n",
        "   - This is particularly helpful for bag-of-words or term frequency-inverse document frequency (TF-IDF) approaches, where each word is treated as a distinct feature.\n",
        "\n",
        "3. **Better Generalization**:\n",
        "   - Lemmatization can improve generalization by grouping words with the same meaning into a single feature, which helps the model capture patterns more effectively.\n",
        "   - For example, in sentiment analysis, grouping all forms of “happy” together strengthens the signal associated with positive sentiment.\n",
        "\n",
        "### Example Scenario: Logistic Regression for Sentiment Analysis\n",
        "\n",
        "When using Logistic Regression for sentiment analysis:\n",
        "- **Preprocessing Steps** often include **lemmatization** or **stemming** to reduce vocabulary, alongside **tokenization**, **lowercasing**, and **removing stop words**.\n",
        "- **Vectorization Techniques** like **TF-IDF** or **count vectors** benefit from a smaller, more consistent vocabulary, which makes lemmatization useful.\n",
        "\n",
        "### Key Takeaway\n",
        "\n",
        "Lemmatization is generally beneficial for simpler models that rely on straightforward text features, as it helps reduce vocabulary size and improves feature consistency. For large, complex models like LLMs, however, lemmatization is typically unnecessary, as these models can understand and handle word variations on their own.\n"
      ],
      "metadata": {
        "id": "uf-jxFkIWBmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What is Tokenization??\n",
        "\n",
        "**Step 4: Tokenization**.\n",
        "\n",
        "Tokenization is essential for preparing text data for a language model. In this step, we’ll use Hugging Face’s tokenizer to:\n",
        "1. **Convert Text to Tokens**: Break down text into subwords or tokens that the model can process.\n",
        "2. **Add Special Tokens**: Add necessary tokens like `[CLS]` (start of input) and `[SEP]` (end of segment) to structure the input for transformer models.\n",
        "3. **Apply Padding and Truncation**: Ensure that all input sequences have consistent lengths by padding shorter ones and truncating longer ones.\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of Each Part\n",
        "\n",
        "1. **Tokenizer Loading**:\n",
        "   - We’re using `AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")` to load the tokenizer that matches our model, which ensures compatibility with the model’s vocabulary and token requirements.\n",
        "   \n",
        "2. **Tokenization Parameters**:\n",
        "   - **`padding=True`**: Pads sequences to the length of the longest sequence in the batch.\n",
        "   - **`truncation=True`**: Truncates sequences that are longer than `max_length=128`.\n",
        "   - **`max_length=128`**: Sets a consistent maximum length for all sequences. This prevents excessively long reviews from slowing down training.\n",
        "   - **`return_tensors=\"pt\"`**: Converts the tokenized output into PyTorch tensors, which is the required format for most transformer models during training.\n",
        "\n",
        "3. **Inspecting the Output**:\n",
        "   - **`input_ids`**: These are the numerical representations of each token in the text. They represent the actual tokens that will be fed into the model.\n",
        "   - **`attention_mask`**: Indicates which tokens are real and which are padding (`1` for real tokens, `0` for padding). The model uses this mask to ignore padding tokens during processing.\n",
        "\n",
        "---\n",
        "\n",
        "### Key Lessons from Tokenization\n",
        "\n",
        "- **Alignment with Model Requirements**: Different models (e.g., BERT, GPT) have unique tokenization requirements. Hugging Face tokenizers make it easy to match these requirements.\n",
        "- **Consistency in Input Length**: Padding and truncation ensure that all inputs are the same length, which is important for batch processing in training.\n",
        "- **Special Tokens and Attention Masks**: These structures help the model interpret the beginning, end, and padding in each sequence, ensuring it processes data correctly.\n",
        "\n",
        "Absolutely, that’s a great idea! Large Language Models (LLMs) like BERT, GPT, and DistilBERT are indeed types of **neural networks**, specifically **transformer-based neural networks**. Here’s a high-level overview of how these data preparation steps connect with the structure and requirements of an LLM as a neural network.\n",
        "\n",
        "---\n",
        "\n",
        "### Neural Networks and LLMs: The Basics\n",
        "\n",
        "At a fundamental level, **neural networks** process numerical data, so transforming text into a numerical format is essential. **Transformers** (which are the architecture behind LLMs) are particularly good at handling sequences of data (like text) and learning the relationships between words or tokens.\n",
        "\n",
        "To optimize their performance, LLMs require input data in a consistent, structured format. Here’s how the tokenization, padding, and special tokens help achieve that:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Convert Text to Tokens**\n",
        "\n",
        "   - **Purpose**: The model needs to process words as numbers, so we use a tokenizer to break down text into smaller pieces, like **subwords** or **tokens**. Each token is assigned an ID that the model can interpret.\n",
        "   - **Relation to Neural Networks**: Tokenizing text allows the neural network to work with each word or subword as a unique feature in a sequence. It enables the model to recognize patterns in language by analyzing these tokens in context.\n",
        "   - **How It Helps LLMs**: Since transformers excel at sequence-based tasks, breaking down text into tokens gives them the flexibility to learn complex relationships and dependencies between words.\n",
        "\n",
        "### 2. **Add Special Tokens**\n",
        "\n",
        "   - **Purpose**: Special tokens help the model understand the structure of the input. For example:\n",
        "     - **[CLS]**: Marks the start of the sequence, used for tasks like classification.\n",
        "     - **[SEP]**: Separates distinct segments within the input, useful in question-answering or sentence-pair tasks.\n",
        "   - **Relation to Neural Networks**: Special tokens help transformers organize input sequences and focus on specific tasks, like identifying the beginning of a sentence or differentiating between question and answer segments.\n",
        "   - **How It Helps LLMs**: Special tokens provide structure, ensuring that the model knows where to start interpreting the sequence and, in some cases, where one part of the input ends and another begins. These markers allow LLMs to manage complex tasks like text classification or question-answering effectively.\n",
        "\n",
        "### 3. **Apply Padding and Truncation**\n",
        "\n",
        "   - **Purpose**: Padding and truncation standardize the length of input sequences. Shorter sequences are **padded** to reach a common length, while longer sequences are **truncated** to avoid exceeding a maximum length (like `max_length=128`).\n",
        "   - **Relation to Neural Networks**: Neural networks process data in **batches**—groups of inputs processed simultaneously for efficiency. To do this, each input in the batch must have the same length. Padding ensures that all inputs in a batch reach a consistent length, while truncation prevents overly long sequences from monopolizing memory.\n",
        "   - **How It Helps LLMs**: Padding keeps inputs aligned in a batch, while **attention masks** allow the model to ignore padding during processing. Truncation ensures that memory and computation are kept manageable, making it feasible to train or fine-tune LLMs on large datasets.\n",
        "\n",
        "### Summary of How These Steps Support LLMs as Neural Networks\n",
        "\n",
        "- **Consistency and Efficiency**: Tokenization, padding, and truncation make the input data uniform, which is essential for efficient batch processing in neural networks.\n",
        "- **Understanding Context**: Special tokens and tokenization allow LLMs to interpret language structure and relationships, enabling them to model context and meaning effectively.\n",
        "- **Memory and Processing Constraints**: Padding and truncation ensure that each batch of data is manageable for the model’s memory, balancing efficiency with performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "CDCcny2oZ9Sm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer Matching by Model Name\n",
        "\n",
        "Each language model is typically designed with a specific **tokenizer** in mind, and the model and tokenizer must match to ensure compatibility. Here’s how you can determine which tokenizer works with which model:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Tokenizer Matching by Model Name**\n",
        "\n",
        "The easiest and most reliable way to select the correct tokenizer is to use the **same model name** when loading both the model and the tokenizer. For instance, if you’re using the Hugging Face Transformers library:\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load the tokenizer and model with the same model name\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "```\n",
        "\n",
        "By specifying the model name (`\"distilbert-base-uncased\"` in this case) for both the tokenizer and model, you ensure that the tokenizer is compatible. Hugging Face will automatically load the correct tokenizer that aligns with the model’s architecture.\n",
        "\n",
        "### 2. **Why Tokenizer-Model Compatibility Matters**\n",
        "\n",
        "Each model architecture has unique requirements for:\n",
        "   - **Vocabulary Size**: Different models have different vocabularies and token ID mappings.\n",
        "   - **Token Types and Special Tokens**: Models like BERT use `[CLS]` and `[SEP]` tokens, while GPT-based models use `<|endoftext|>` as an end marker.\n",
        "   - **Tokenization Strategy**: Some models use subword tokenization (like BERT’s WordPiece), while others use byte-pair encoding (BPE, common for GPT and RoBERTa).\n",
        "\n",
        "Using a mismatched tokenizer can cause errors because the model may encounter unexpected token IDs, special tokens, or sequence formats.\n",
        "\n",
        "### 3. **AutoTokenizer Handles Compatibility**\n",
        "\n",
        "When using `AutoTokenizer` from Hugging Face, it automatically loads the appropriate tokenizer class based on the model type. Here’s how it works:\n",
        "   - For **BERT-based models**, `AutoTokenizer` loads a tokenizer that uses WordPiece tokenization with `[CLS]` and `[SEP]` tokens.\n",
        "   - For **GPT-based models**, it loads a tokenizer with BPE encoding and `<|endoftext|>` tokens.\n",
        "   - For **Roberta** or **DistilBERT**, it loads tokenizers using their respective special tokens and encoding methods.\n",
        "\n",
        "### 4. **Checking Model Documentation**\n",
        "\n",
        "If you’re unsure, you can check the model’s documentation on Hugging Face or the original paper. Most documentation will specify:\n",
        "   - The exact tokenizer method (e.g., WordPiece, BPE).\n",
        "   - Any special tokens that need to be added.\n",
        "   - Vocabulary details (size, specific tokens).\n",
        "\n",
        "### Summary\n",
        "\n",
        "- **Match by Name**: Using the same model name when loading both model and tokenizer is the easiest way to ensure compatibility.\n",
        "- **Use AutoTokenizer**: Hugging Face’s `AutoTokenizer` automatically selects the correct tokenizer for the model type.\n",
        "- **Check Documentation**: If in doubt, refer to the model’s documentation for exact tokenization requirements.\n",
        "\n"
      ],
      "metadata": {
        "id": "uemKLJOzhlAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the tokenizer for the model we're using (e.g., DistilBERT)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Tokenize the sampled text data with padding and truncation\n",
        "tokenized_texts = tokenizer(\n",
        "    sampled_texts,\n",
        "    padding=True,              # Pad shorter sequences\n",
        "    truncation=True,           # Truncate longer sequences\n",
        "    max_length=128,            # Maximum length for each sequence\n",
        "    return_tensors=\"pt\"        # Return as PyTorch tensors for model compatibility\n",
        ")\n",
        "\n",
        "# Print a few tokenized examples to inspect the results\n",
        "print(\"Tokenized Text Sample:\")\n",
        "for i in range(3):\n",
        "    print(f\"Review {i+1}: {sampled_texts[i]}\")\n",
        "    print(f\"Input IDs (tokens) for Review {i+1}: {tokenized_texts['input_ids'][i]}\")\n",
        "    print(f\"Attention Mask for Review {i+1}: {tokenized_texts['attention_mask'][i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpCqdKAbWCPZ",
        "outputId": "303a0337-08cf-4044-9bd7-44fb17dbb389"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Text Sample:\n",
            "Review 1: Arguably this is a very good \"sequel\", better than the first live action film 101 Dalmatians. It has good dogs, good actors, good jokes and all right slapstick! <br /><br />Cruella DeVil, who has had some rather major therapy, is now a lover of dogs and very kind to them. Many, including Chloe Simon, owner of one of the dogs that Cruella once tried to kill, do not believe this. Others, like Kevin Shepherd (owner of 2nd Chance Dog Shelter) believe that she has changed. <br /><br />Meanwhile, Dipstick, with his mate, have given birth to three cute dalmatian puppies! Little Dipper, Domino and Oddball...<br /><br />Starring Eric Idle as Waddlesworth (the hilarious macaw), Glenn Close as Cruella herself and Gerard Depardieu as Le Pelt (another baddie, the name should give a clue), this is a good family film with excitement and lots more!! One downfall of this film is that is has a lot of painful slapstick, but not quite as excessive as the last film. This is also funnier than the last film.<br /><br />Enjoy \"102 Dalmatians\"! :-)\n",
            "Input IDs (tokens) for Review 1: tensor([  101, 15835,  2023,  2003,  1037,  2200,  2204,  1000,  8297,  1000,\n",
            "         1010,  2488,  2084,  1996,  2034,  2444,  2895,  2143,  7886, 17488,\n",
            "        18900,  7066,  1012,  2009,  2038,  2204,  6077,  1010,  2204,  5889,\n",
            "         1010,  2204, 13198,  1998,  2035,  2157, 14308, 21354,   999,  1026,\n",
            "         7987,  1013,  1028,  1026,  7987,  1013,  1028, 10311,  2721,  6548,\n",
            "         1010,  2040,  2038,  2018,  2070,  2738,  2350,  7242,  1010,  2003,\n",
            "         2085,  1037,  7089,  1997,  6077,  1998,  2200,  2785,  2000,  2068,\n",
            "         1012,  2116,  1010,  2164,  9318,  4079,  1010,  3954,  1997,  2028,\n",
            "         1997,  1996,  6077,  2008, 10311,  2721,  2320,  2699,  2000,  3102,\n",
            "         1010,  2079,  2025,  2903,  2023,  1012,  2500,  1010,  2066,  4901,\n",
            "        11133,  1006,  3954,  1997,  3416,  3382,  3899,  7713,  1007,  2903,\n",
            "         2008,  2016,  2038,  2904,  1012,  1026,  7987,  1013,  1028,  1026,\n",
            "         7987,  1013,  1028,  5564,  1010, 16510, 21354,   102])\n",
            "Attention Mask for Review 1: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n",
            "Review 2: It's a good thing I didn't watch this while i was pregnant.I definitely would have cried my eyes out and/or vomit. It was Kind of gruesome mainly disturbing. I personally thought the baby was adorable in its own twisted little way.However as a mom I cringed when Beth stabbed herself in the stomach and when Virgina aborted the child during her 3rd trimester with rusty utensils no less.Also,as an animal lover i almost cried when she scratched the cat to a bloody pulp.However,As creepy and sinister as the baby was I was rooting for it to live.And as twisted as the movie was I am extremely intrigued to see the sequel...... ......... ....... ......... ......... ....... ...... .....\n",
            "Input IDs (tokens) for Review 2: tensor([  101,  2009,  1005,  1055,  1037,  2204,  2518,  1045,  2134,  1005,\n",
            "         1056,  3422,  2023,  2096,  1045,  2001,  6875,  1012,  1045,  5791,\n",
            "         2052,  2031,  6639,  2026,  2159,  2041,  1998,  1013,  2030, 23251,\n",
            "         1012,  2009,  2001,  2785,  1997, 24665, 15808,  8462,  3701, 14888,\n",
            "         1012,  1045,  7714,  2245,  1996,  3336,  2001, 23677,  1999,  2049,\n",
            "         2219,  6389,  2210,  2126,  1012,  2174,  2004,  1037,  3566,  1045,\n",
            "        23952,  2043,  7014, 13263,  2841,  1999,  1996,  4308,  1998,  2043,\n",
            "         6261,  2050, 11113, 15613,  1996,  2775,  2076,  2014,  3822, 12241,\n",
            "        20367,  2007, 13174, 21183,  6132, 12146,  2053,  2625,  1012,  2036,\n",
            "         1010,  2004,  2019,  4111,  7089,  1045,  2471,  6639,  2043,  2016,\n",
            "        15047,  1996,  4937,  2000,  1037,  6703, 16016,  1012,  2174,  1010,\n",
            "         2004, 17109,  1998, 16491,  2004,  1996,  3336,  2001,  1045,  2001,\n",
            "         7117,  2075,  2005,  2009,  2000,  2444,  1012,   102])\n",
            "Attention Mask for Review 2: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n",
            "Review 3: This has to be the worst movie I have seen. Madsen fans don't be drawn into this like I was. He is only in it for a maximum of five minutes. This movie is so bad that the only reason why you would watch it is if all the rest of the movies on earth as well as t.v. had been destroyed.\n",
            "Input IDs (tokens) for Review 3: tensor([ 101, 2023, 2038, 2000, 2022, 1996, 5409, 3185, 1045, 2031, 2464, 1012,\n",
            "        5506, 5054, 4599, 2123, 1005, 1056, 2022, 4567, 2046, 2023, 2066, 1045,\n",
            "        2001, 1012, 2002, 2003, 2069, 1999, 2009, 2005, 1037, 4555, 1997, 2274,\n",
            "        2781, 1012, 2023, 3185, 2003, 2061, 2919, 2008, 1996, 2069, 3114, 2339,\n",
            "        2017, 2052, 3422, 2009, 2003, 2065, 2035, 1996, 2717, 1997, 1996, 5691,\n",
            "        2006, 3011, 2004, 2092, 2004, 1056, 1012, 1058, 1012, 2018, 2042, 3908,\n",
            "        1012,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "Attention Mask for Review 3: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine Inputs\n",
        "\n",
        "Now that we have our **tokenized inputs**, **labels**, and **attention masks** separated, the next step is to combine them into a unified format for model training.\n",
        "\n",
        "Here’s what we’ll do next:\n",
        "\n",
        "1. **Combine the Inputs**: Package the tokenized inputs (input IDs, attention masks) and labels into a single dataset structure.\n",
        "2. **Create a Custom Dataset (Optional)**: Wrap everything in a custom dataset class, like `torch.utils.data.Dataset`, to make it compatible with PyTorch or Hugging Face’s Trainer API.\n",
        "\n",
        "### Step 5: Combining Inputs for Training\n",
        "\n",
        "Let’s structure the data so that each sample has its **input IDs**, **attention mask**, and **label** grouped together.\n",
        "\n",
        "---\n",
        "\n",
        "### Option 1: Using a Dictionary (Quick and Simple for Smaller Projects)\n",
        "\n",
        "If you’re working with a smaller project or just testing, you can combine the inputs in a dictionary format:\n",
        "\n",
        "```python\n",
        "# Convert labels to tensor format\n",
        "import torch\n",
        "\n",
        "# Prepare labels as tensors\n",
        "label_tensors = torch.tensor(sampled_labels)\n",
        "\n",
        "# Combine inputs in a dictionary\n",
        "train_data = {\n",
        "    \"input_ids\": tokenized_texts[\"input_ids\"],\n",
        "    \"attention_mask\": tokenized_texts[\"attention_mask\"],\n",
        "    \"labels\": label_tensors\n",
        "}\n",
        "\n",
        "# Check the structure\n",
        "print(\"Combined Data Sample:\")\n",
        "for key, value in train_data.items():\n",
        "    print(f\"{key}: {value[:3]}\")\n",
        "```\n",
        "\n",
        "This dictionary format groups the tokenized data with attention masks and labels, making it easy to pass the inputs to the model for small testing scenarios.\n",
        "\n",
        "---\n",
        "\n",
        "### Option 2: Creating a Custom Dataset (More Scalable)\n",
        "\n",
        "For more scalable training, especially when using `Trainer` in Hugging Face or a PyTorch DataLoader, creating a custom dataset class provides more flexibility.\n",
        "\n",
        "```python\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class IMDbDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: self.encodings[key][idx] for key in self.encodings}\n",
        "        item[\"labels\"] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create the dataset\n",
        "train_dataset = IMDbDataset(tokenized_texts, label_tensors)\n",
        "\n",
        "# Check the structure of a sample\n",
        "print(\"Custom Dataset Sample:\")\n",
        "print(train_dataset[0])  # Print the first item in the dataset\n",
        "```\n",
        "\n",
        "### Explanation of the Custom Dataset Class\n",
        "\n",
        "- **`__init__`**: Takes in `encodings` (tokenized inputs and masks) and `labels`, storing them as class attributes.\n",
        "- **`__getitem__`**: Accesses an individual sample by index, returning a dictionary of `input_ids`, `attention_mask`, and `labels`.\n",
        "- **`__len__`**: Returns the total number of samples, which is required for `Dataset` objects in PyTorch.\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- **Dictionary Format**: Quick and easy for small projects.\n",
        "- **Custom Dataset**: More flexible and essential for larger-scale training, especially with PyTorch’s `DataLoader` or Hugging Face’s `Trainer`.\n",
        "\n"
      ],
      "metadata": {
        "id": "UE33_vc1i6vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to tensor format\n",
        "import torch\n",
        "\n",
        "# Prepare labels as tensors\n",
        "label_tensors = torch.tensor(sampled_labels)\n",
        "\n",
        "# Combine inputs in a dictionary\n",
        "train_data = {\n",
        "    \"input_ids\": tokenized_texts[\"input_ids\"],\n",
        "    \"attention_mask\": tokenized_texts[\"attention_mask\"],\n",
        "    \"labels\": label_tensors\n",
        "}\n",
        "\n",
        "# Check the structure\n",
        "print(\"Combined Data Sample:\")\n",
        "for key, value in train_data.items():\n",
        "    print(f\"{key}: {value[:3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1yVfuSng6Xa",
        "outputId": "d11a6d3c-9bc4-467c-edc0-ad5322f66661"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Data Sample:\n",
            "input_ids: tensor([[  101, 15835,  2023,  2003,  1037,  2200,  2204,  1000,  8297,  1000,\n",
            "          1010,  2488,  2084,  1996,  2034,  2444,  2895,  2143,  7886, 17488,\n",
            "         18900,  7066,  1012,  2009,  2038,  2204,  6077,  1010,  2204,  5889,\n",
            "          1010,  2204, 13198,  1998,  2035,  2157, 14308, 21354,   999,  1026,\n",
            "          7987,  1013,  1028,  1026,  7987,  1013,  1028, 10311,  2721,  6548,\n",
            "          1010,  2040,  2038,  2018,  2070,  2738,  2350,  7242,  1010,  2003,\n",
            "          2085,  1037,  7089,  1997,  6077,  1998,  2200,  2785,  2000,  2068,\n",
            "          1012,  2116,  1010,  2164,  9318,  4079,  1010,  3954,  1997,  2028,\n",
            "          1997,  1996,  6077,  2008, 10311,  2721,  2320,  2699,  2000,  3102,\n",
            "          1010,  2079,  2025,  2903,  2023,  1012,  2500,  1010,  2066,  4901,\n",
            "         11133,  1006,  3954,  1997,  3416,  3382,  3899,  7713,  1007,  2903,\n",
            "          2008,  2016,  2038,  2904,  1012,  1026,  7987,  1013,  1028,  1026,\n",
            "          7987,  1013,  1028,  5564,  1010, 16510, 21354,   102],\n",
            "        [  101,  2009,  1005,  1055,  1037,  2204,  2518,  1045,  2134,  1005,\n",
            "          1056,  3422,  2023,  2096,  1045,  2001,  6875,  1012,  1045,  5791,\n",
            "          2052,  2031,  6639,  2026,  2159,  2041,  1998,  1013,  2030, 23251,\n",
            "          1012,  2009,  2001,  2785,  1997, 24665, 15808,  8462,  3701, 14888,\n",
            "          1012,  1045,  7714,  2245,  1996,  3336,  2001, 23677,  1999,  2049,\n",
            "          2219,  6389,  2210,  2126,  1012,  2174,  2004,  1037,  3566,  1045,\n",
            "         23952,  2043,  7014, 13263,  2841,  1999,  1996,  4308,  1998,  2043,\n",
            "          6261,  2050, 11113, 15613,  1996,  2775,  2076,  2014,  3822, 12241,\n",
            "         20367,  2007, 13174, 21183,  6132, 12146,  2053,  2625,  1012,  2036,\n",
            "          1010,  2004,  2019,  4111,  7089,  1045,  2471,  6639,  2043,  2016,\n",
            "         15047,  1996,  4937,  2000,  1037,  6703, 16016,  1012,  2174,  1010,\n",
            "          2004, 17109,  1998, 16491,  2004,  1996,  3336,  2001,  1045,  2001,\n",
            "          7117,  2075,  2005,  2009,  2000,  2444,  1012,   102],\n",
            "        [  101,  2023,  2038,  2000,  2022,  1996,  5409,  3185,  1045,  2031,\n",
            "          2464,  1012,  5506,  5054,  4599,  2123,  1005,  1056,  2022,  4567,\n",
            "          2046,  2023,  2066,  1045,  2001,  1012,  2002,  2003,  2069,  1999,\n",
            "          2009,  2005,  1037,  4555,  1997,  2274,  2781,  1012,  2023,  3185,\n",
            "          2003,  2061,  2919,  2008,  1996,  2069,  3114,  2339,  2017,  2052,\n",
            "          3422,  2009,  2003,  2065,  2035,  1996,  2717,  1997,  1996,  5691,\n",
            "          2006,  3011,  2004,  2092,  2004,  1056,  1012,  1058,  1012,  2018,\n",
            "          2042,  3908,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]])\n",
            "attention_mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "labels: tensor([1, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the simple dictionary approach, `train_data` will be a dictionary where each key corresponds to one type of data, and each value is a tensor containing all samples for that data type. Here’s a breakdown of what this dictionary will look like:\n",
        "\n",
        "### Structure of `train_data`\n",
        "\n",
        "```python\n",
        "train_data = {\n",
        "    \"input_ids\": tokenized_texts[\"input_ids\"],       # Token IDs for each sample\n",
        "    \"attention_mask\": tokenized_texts[\"attention_mask\"],  # Attention masks indicating real tokens vs padding\n",
        "    \"labels\": label_tensors                          # Labels for each sample (0 or 1 for sentiment)\n",
        "}\n",
        "```\n",
        "\n",
        "### Data Types and Shapes\n",
        "\n",
        "- **`\"input_ids\"`**: Tensor of token IDs with a shape of `(num_samples, max_length)`.\n",
        "  - Each row in `input_ids` is a sequence of token IDs representing a text review.\n",
        "  \n",
        "- **`\"attention_mask\"`**: Tensor with a shape of `(num_samples, max_length)`.\n",
        "  - Each row in `attention_mask` is a binary sequence (1s and 0s), where `1` represents real tokens, and `0` represents padding tokens.\n",
        "  \n",
        "- **`\"labels\"`**: Tensor with a shape of `(num_samples,)`.\n",
        "  - Each entry in `labels` is the sentiment label for the corresponding review, where `1` represents positive sentiment and `0` represents negative.\n",
        "\n",
        "### Example Output for `train_data`\n",
        "\n",
        "If you printed `train_data`, it would look something like this:\n",
        "\n",
        "```python\n",
        "{\n",
        "  \"input_ids\": tensor([[101, 2057, 2293, ...], [101, 2009, 2001, ...], ...]),\n",
        "  \"attention_mask\": tensor([[1, 1, 1, ...], [1, 1, 1, ...], ...]),\n",
        "  \"labels\": tensor([1, 0, 1, ...])\n",
        "}\n",
        "```\n",
        "\n",
        "Each entry (e.g., `input_ids`, `attention_mask`, `labels`) represents all samples in the dataset.\n",
        "\n",
        "### Using `train_data` for Training\n",
        "\n",
        "Now that we have `train_data` structured this way, it’s ready to be fed into a model for training. We can pass each element in `train_data` directly to a transformer model or training loop, making it very efficient for batch processing.\n",
        "\n",
        "Great questions! Let’s clarify these terms, as it can get a bit confusing with the different shapes involved. Here’s a breakdown of **`num_samples`**, **`max_length`**, and the meaning of each **sample** in the context of our dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "1. **`num_samples`**:\n",
        "   - This represents the **total number of reviews** in the dataset.\n",
        "   - In your `train_data` dictionary, `num_samples` is the number of entries in `sampled_texts`—so if you sampled 5% of a 25,000-sample training dataset, `num_samples` would be about 1,250.\n",
        "   - Each sample in this context is a **single text review** with its corresponding token IDs, attention mask, and label.\n",
        "\n",
        "2. **`max_length`**:\n",
        "   - This is the **maximum token length** for each review, defining how long each sequence can be. If a review has fewer tokens than `max_length`, we add **padding** to reach this length. If it’s longer, we **truncate** it to fit.\n",
        "   - For example, if `max_length=128`, every tokenized review will have 128 tokens, regardless of its original length, due to padding and truncation.\n",
        "   - **`attention_mask`** uses `max_length` to ensure each review sequence has a uniform length, marking real tokens with `1` and padding tokens with `0`.\n",
        "\n",
        "---\n",
        "\n",
        "### Tensor Shapes in `train_data`\n",
        "\n",
        "Let’s relate these definitions back to the shapes in `train_data`:\n",
        "\n",
        "- **`\"input_ids\"` Tensor**: Has a shape of `(num_samples, max_length)`.\n",
        "  - **Example Shape**: `(1250, 128)` if we sampled 1,250 reviews and set `max_length=128`.\n",
        "  - Each row in `input_ids` represents the tokenized form of a single review, with each entry in the row representing a token ID. So, every row is a **sample** (one review) padded or truncated to `max_length`.\n",
        "\n",
        "- **`\"attention_mask\"` Tensor**: Also has a shape of `(num_samples, max_length)`.\n",
        "  - **Example Shape**: `(1250, 128)` for 1,250 reviews with padding/truncation to 128 tokens.\n",
        "  - Each row here corresponds to a single review, with `1` for real tokens and `0` for padding tokens, enabling the model to focus only on real tokens.\n",
        "\n",
        "- **`\"labels\"` Tensor**: Has a shape of `(num_samples,)`.\n",
        "  - **Example Shape**: `(1250,)`, where each entry represents the sentiment label (0 or 1) for a single review.\n",
        "  - This is a one-dimensional tensor since each label is a single integer value representing the sentiment for each sample.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary: What Is a \"Sample\"?\n",
        "\n",
        "- **Each Sample = One Review**:\n",
        "  - Each sample in `train_data` is a single movie review and its associated data (tokens, mask, and label).\n",
        "  - A **dataset** (like `train_data`) contains multiple samples.\n",
        "\n",
        "In this structure:\n",
        "- **`num_samples`** is the number of reviews.\n",
        "- **`max_length`** is the fixed length of each review’s token sequence after padding and truncation.\n",
        "\n",
        "Each sample (a single review) isn’t considered a dataset on its own, but it forms part of the larger dataset, `train_data`, which contains all samples.\n"
      ],
      "metadata": {
        "id": "B0BJQnkSl380"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model\n",
        "\n",
        "Now, we’ll use Hugging Face’s `Trainer` API to set up and run the training process, which simplifies the process of training and evaluating transformer models. Since we already have `train_data` organized with input IDs, attention masks, and labels, we’re in a good position to get started with training.\n",
        "\n",
        "#### Steps in This Phase:\n",
        "1. **Define Training Arguments**: Set parameters like batch size, learning rate, and the number of training epochs.\n",
        "2. **Initialize the Trainer**: Set up the model and data with the Hugging Face `Trainer`.\n",
        "3. **Train the Model**: Run the training loop and periodically evaluate the model.\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of the Training Steps\n",
        "\n",
        "- **Training Arguments**: Control aspects of training like batch size, learning rate, and evaluation frequency.\n",
        "- **Trainer**: Simplifies the training process by managing data loading, batch processing, and logging automatically.\n",
        "- **Epoch-Based Evaluation**: Evaluating at each epoch helps monitor performance and ensures the model doesn’t overfit.\n",
        "\n"
      ],
      "metadata": {
        "id": "SxO6Izz0msvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Define Training Arguments\n",
        "\n",
        "We’ll start by setting the training arguments. Here’s some code to define these:"
      ],
      "metadata": {
        "id": "_ExeuxuanX4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",            # Output directory for model predictions and checkpoints\n",
        "    eval_strategy=\"epoch\",       # Evaluate at the end of each epoch\n",
        "    per_device_train_batch_size=8,     # Batch size for training\n",
        "    per_device_eval_batch_size=8,      # Batch size for evaluation\n",
        "    num_train_epochs=1,                # Number of training epochs\n",
        "    weight_decay=0.01,                 # Weight decay for regularization\n",
        "    logging_dir=\"./logs\",              # Directory for storing logs\n",
        "    logging_steps=10,                  # Log every 10 steps\n",
        "    report_to=\"none\"                    # Disables W&B logging\n",
        ")"
      ],
      "metadata": {
        "id": "5KMBYrg_jIpb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Initialize the Trainer\n",
        "\n",
        "Next, we initialize the `Trainer`, specifying the model, training arguments, and dataset. For simplicity, let’s also create a validation set from a portion of `train_data` to monitor the model’s performance."
      ],
      "metadata": {
        "id": "01sS5mqbnHxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"input_ids\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1mGcglYnrFq",
        "outputId": "ca2117c3-94cb-44b2-c985-0ce574039995"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1250, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_size = int(0.8 * len(train_data[\"input_ids\"]))\n",
        "val_size = len(train_data[\"input_ids\"]) - train_size\n",
        "\n",
        "# Separate training and validation data\n",
        "train_dataset = {\n",
        "    \"input_ids\": train_data[\"input_ids\"][:train_size],\n",
        "    \"attention_mask\": train_data[\"attention_mask\"][:train_size],\n",
        "    \"labels\": train_data[\"labels\"][:train_size],\n",
        "}\n",
        "val_dataset = {\n",
        "    \"input_ids\": train_data[\"input_ids\"][train_size:],\n",
        "    \"attention_mask\": train_data[\"attention_mask\"][train_size:],\n",
        "    \"labels\": train_data[\"labels\"][train_size:],\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RlqhlhZjIm2",
        "outputId": "3ba8e29d-2c82-4c2d-84c2-c10952b532f4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Train the Model\n",
        "\n",
        "This will start the training process, where the model learns from `train_dataset`, and `Trainer` will also evaluate on `val_dataset` at the end of each epoch (because of `evaluation_strategy=\"epoch\"`)."
      ],
      "metadata": {
        "id": "g2W015T2nB7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# End the timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the duration in minutes\n",
        "duration = (end_time - start_time) / 60\n",
        "print(f\"Tokenization completed in {duration:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "2CnGxAxyjIkO",
        "outputId": "38c2f02d-64e3-4bb7-b018-2540c67b27bf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-2efe6e5d5729>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# End the timer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2237\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This `KeyError` is likely due to the way we structured `train_dataset` and `val_dataset` as dictionaries rather than as PyTorch datasets or Hugging Face `Dataset` objects. The `Trainer` expects datasets to follow certain formats to retrieve samples by index.\n",
        "\n",
        "To resolve this, let’s modify `train_dataset` and `val_dataset` to work with `Trainer`. Since we’re using dictionaries to hold our data, we can either convert them into a `Dataset` object or switch to using a `DatasetDict` from Hugging Face’s `datasets` library.\n",
        "\n",
        "### Wrap Data in a Custom Dataset Class\n",
        "\n",
        "Here’s how to wrap `train_data` and `val_data` in a custom dataset class compatible with `Trainer`:\n",
        "\n",
        "```python\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class IMDbDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieves data by index as expected by Trainer\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Split labels as tensors for training and validation sets\n",
        "train_labels = label_tensors[:train_size]\n",
        "val_labels = label_tensors[train_size:]\n",
        "\n",
        "# Initialize datasets with the IMDbDataset class\n",
        "train_dataset = IMDbDataset(\n",
        "    encodings={\n",
        "        \"input_ids\": train_data[\"input_ids\"][:train_size],\n",
        "        \"attention_mask\": train_data[\"attention_mask\"][:train_size],\n",
        "    },\n",
        "    labels=train_labels\n",
        ")\n",
        "val_dataset = IMDbDataset(\n",
        "    encodings={\n",
        "        \"input_ids\": train_data[\"input_ids\"][train_size:],\n",
        "        \"attention_mask\": train_data[\"attention_mask\"][train_size:],\n",
        "    },\n",
        "    labels=val_labels\n",
        ")\n",
        "```\n",
        "\n",
        "### Explanation of Changes\n",
        "\n",
        "- **Custom Dataset Class**: `IMDbDataset` allows `Trainer` to index data as expected.\n",
        "- **`__getitem__` Method**: Retrieves each sample by index and packages it in a dictionary.\n",
        "- **Consistent Format**: Wrapping `train_data` and `val_data` in `IMDbDataset` allows `Trainer` to handle the data correctly.\n",
        "\n",
        "This should resolve the `KeyError`. Let me know if you encounter further issues or if you’re ready to proceed with model evaluation after training!\n",
        "\n",
        "The Hugging Face `Trainer` requires that the datasets (`train_dataset` and `eval_dataset`) be in a format that allows it to retrieve samples by index, which a simple dictionary doesn’t support. **Using a PyTorch `Dataset`** or a Hugging Face `Dataset` provides that indexing capability and enables `Trainer` to access each sample in the way it expects.\n",
        "\n",
        "### Why a Simple Dictionary Won't Work\n",
        "\n",
        "- **Indexing Requirement**: The `Trainer` retrieves individual samples by calling the dataset with an index (e.g., `dataset[0]`), which dictionaries don’t support.\n",
        "- **Batch Processing**: To create batches, `Trainer` needs to know how to retrieve sequences by their indices and stack them together. Dictionaries don’t provide this functionality, but `Dataset` classes do.\n",
        "\n",
        "### Solution Recap\n",
        "\n",
        "By wrapping our data in a custom PyTorch `Dataset` class, such as the `IMDbDataset` we defined, we give the `Trainer` the ability to access samples by index. This allows it to correctly retrieve, batch, and process data during training and evaluation.\n",
        "\n"
      ],
      "metadata": {
        "id": "I76g5UoJoflR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "train_size = int(0.8 * len(train_data[\"input_ids\"]))\n",
        "val_size = len(train_data[\"input_ids\"]) - train_size\n",
        "\n",
        "# Separate training and validation data\n",
        "train_dataset = {\n",
        "    \"input_ids\": train_data[\"input_ids\"][:train_size],\n",
        "    \"attention_mask\": train_data[\"attention_mask\"][:train_size],\n",
        "    \"labels\": train_data[\"labels\"][:train_size],\n",
        "}\n",
        "val_dataset = {\n",
        "    \"input_ids\": train_data[\"input_ids\"][train_size:],\n",
        "    \"attention_mask\": train_data[\"attention_mask\"][train_size:],\n",
        "    \"labels\": train_data[\"labels\"][train_size:],\n",
        "}\n",
        "\n",
        "# Print a sample from the dictionary-based dataset\n",
        "print(\"Sample from dictionary-based train_dataset:\")\n",
        "print({\n",
        "    \"input_ids\": train_dataset[\"input_ids\"][0],\n",
        "    \"attention_mask\": train_dataset[\"attention_mask\"][0],\n",
        "    \"labels\": train_dataset[\"labels\"][0]\n",
        "})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5cyxuK3pZnH",
        "outputId": "77736eeb-6e68-4b22-cb47-5a4866abf8df"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample from dictionary-based train_dataset:\n",
            "{'input_ids': tensor([  101, 15835,  2023,  2003,  1037,  2200,  2204,  1000,  8297,  1000,\n",
            "         1010,  2488,  2084,  1996,  2034,  2444,  2895,  2143,  7886, 17488,\n",
            "        18900,  7066,  1012,  2009,  2038,  2204,  6077,  1010,  2204,  5889,\n",
            "         1010,  2204, 13198,  1998,  2035,  2157, 14308, 21354,   999,  1026,\n",
            "         7987,  1013,  1028,  1026,  7987,  1013,  1028, 10311,  2721,  6548,\n",
            "         1010,  2040,  2038,  2018,  2070,  2738,  2350,  7242,  1010,  2003,\n",
            "         2085,  1037,  7089,  1997,  6077,  1998,  2200,  2785,  2000,  2068,\n",
            "         1012,  2116,  1010,  2164,  9318,  4079,  1010,  3954,  1997,  2028,\n",
            "         1997,  1996,  6077,  2008, 10311,  2721,  2320,  2699,  2000,  3102,\n",
            "         1010,  2079,  2025,  2903,  2023,  1012,  2500,  1010,  2066,  4901,\n",
            "        11133,  1006,  3954,  1997,  3416,  3382,  3899,  7713,  1007,  2903,\n",
            "         2008,  2016,  2038,  2904,  1012,  1026,  7987,  1013,  1028,  1026,\n",
            "         7987,  1013,  1028,  5564,  1010, 16510, 21354,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class IMDbDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieves data by index as expected by Trainer\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Split labels as tensors for training and validation sets\n",
        "train_labels = label_tensors[:train_size]\n",
        "val_labels = label_tensors[train_size:]\n",
        "\n",
        "# Initialize datasets with the IMDbDataset class\n",
        "train_dataset = IMDbDataset(\n",
        "    encodings={\n",
        "        \"input_ids\": train_data[\"input_ids\"][:train_size],\n",
        "        \"attention_mask\": train_data[\"attention_mask\"][:train_size],\n",
        "    },\n",
        "    labels=train_labels\n",
        ")\n",
        "val_dataset = IMDbDataset(\n",
        "    encodings={\n",
        "        \"input_ids\": train_data[\"input_ids\"][train_size:],\n",
        "        \"attention_mask\": train_data[\"attention_mask\"][train_size:],\n",
        "    },\n",
        "    labels=val_labels\n",
        ")\n",
        "\n",
        "# Print a sample from the train_dataset\n",
        "print(\"Sample from train_dataset:\")\n",
        "print(train_dataset[0])  # Print the first item in the dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiEbHUeboxlH",
        "outputId": "b6971fcd-c7e8-4b26-f0d2-a87540bc8139"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample from train_dataset:\n",
            "{'input_ids': tensor([  101, 15835,  2023,  2003,  1037,  2200,  2204,  1000,  8297,  1000,\n",
            "         1010,  2488,  2084,  1996,  2034,  2444,  2895,  2143,  7886, 17488,\n",
            "        18900,  7066,  1012,  2009,  2038,  2204,  6077,  1010,  2204,  5889,\n",
            "         1010,  2204, 13198,  1998,  2035,  2157, 14308, 21354,   999,  1026,\n",
            "         7987,  1013,  1028,  1026,  7987,  1013,  1028, 10311,  2721,  6548,\n",
            "         1010,  2040,  2038,  2018,  2070,  2738,  2350,  7242,  1010,  2003,\n",
            "         2085,  1037,  7089,  1997,  6077,  1998,  2200,  2785,  2000,  2068,\n",
            "         1012,  2116,  1010,  2164,  9318,  4079,  1010,  3954,  1997,  2028,\n",
            "         1997,  1996,  6077,  2008, 10311,  2721,  2320,  2699,  2000,  3102,\n",
            "         1010,  2079,  2025,  2903,  2023,  1012,  2500,  1010,  2066,  4901,\n",
            "        11133,  1006,  3954,  1997,  3416,  3382,  3899,  7713,  1007,  2903,\n",
            "         2008,  2016,  2038,  2904,  1012,  1026,  7987,  1013,  1028,  1026,\n",
            "         7987,  1013,  1028,  5564,  1010, 16510, 21354,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s compare the two formats and understand why the `Trainer` requires the dataset to be in the `Dataset` class format rather than a simple dictionary.\n",
        "\n",
        "### Dictionary Dataset Structure\n",
        "\n",
        "In the dictionary version (`train_dataset` and `val_dataset` as dictionaries), we’re just slicing arrays from `train_data`. Here’s what a sample from the **dictionary-based dataset** would look like if we print the first few values for each key:\n",
        "\n",
        "```python\n",
        "# Print a sample from the dictionary-based dataset\n",
        "print(\"Sample from dictionary-based train_dataset:\")\n",
        "print({\n",
        "    \"input_ids\": train_dataset[\"input_ids\"][0],\n",
        "    \"attention_mask\": train_dataset[\"attention_mask\"][0],\n",
        "    \"labels\": train_dataset[\"labels\"][0]\n",
        "})\n",
        "```\n",
        "\n",
        "### Expected Output of Dictionary-Based Sample\n",
        "\n",
        "The output will show each part of the data separately, but it doesn’t group them into individual samples, which is the main difference:\n",
        "\n",
        "```python\n",
        "Sample from dictionary-based train_dataset:\n",
        "{\n",
        "    'input_ids': tensor([101, 1045, 2293, ..., 102, 0, 0]),\n",
        "    'attention_mask': tensor([1, 1, 1, ..., 0, 0, 0]),\n",
        "    'labels': tensor(1)\n",
        "}\n",
        "```\n",
        "\n",
        "This format is similar in structure to the sample from the `IMDbDataset` class, but the dictionary itself doesn’t have a method to retrieve individual samples by index, nor does it group each sample as a dictionary. This structure stores each type of data separately as lists of tensors, rather than creating a \"sample-by-sample\" structure.\n",
        "\n",
        "---\n",
        "\n",
        "### Key Differences Between the Dictionary and the `IMDbDataset`\n",
        "\n",
        "1. **Index-Based Access**:\n",
        "   - With a dictionary, accessing individual samples requires slicing manually, e.g., `train_dataset[\"input_ids\"][0]`, which doesn’t group each sample’s elements together.\n",
        "   - With `IMDbDataset`, each sample (one review) is a cohesive dictionary, accessible by `train_dataset[0]`, which retrieves the `input_ids`, `attention_mask`, and `labels` for a single sample.\n",
        "\n",
        "2. **Compatibility with `Trainer`**:\n",
        "   - The `Trainer` requires each sample to be a dictionary containing all necessary inputs (`input_ids`, `attention_mask`, and `labels`), which it expects to access by index.\n",
        "   - Dictionaries don’t provide this structure, while the `IMDbDataset` class does.\n",
        "\n",
        "3. **Batch Processing**:\n",
        "   - When using `Trainer`, batch processing relies on each sample being an individual dictionary with its data grouped together. This is facilitated by the `Dataset` class, but not by a dictionary.\n",
        "\n",
        "### Summary\n",
        "\n",
        "The dictionary-based dataset doesn’t group individual samples and lacks index-based access, which makes it incompatible with `Trainer`. The `IMDbDataset` class format, on the other hand, groups each review as an individual sample with index access, aligning it with the `Trainer` requirements.\n",
        "\n"
      ],
      "metadata": {
        "id": "NjVm3EMQp8Mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# End the timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the duration in minutes\n",
        "duration = (end_time - start_time) / 60\n",
        "print(f\"Tokenization completed in {duration:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "nlvsbnCSjIhW",
        "outputId": "7104c60e-1eb5-493b-d638-d5fc8cf8c616"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 14:43, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.499200</td>\n",
              "      <td>0.374737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization completed in 14.87 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the Model on the Test Set\n",
        "\n",
        "First, we’ll use `trainer.evaluate()` to get evaluation metrics on the validation set (or test set if we split one out).\n",
        "\n",
        "This will give you basic metrics like accuracy and loss. However, for a more detailed report, let’s use `sklearn.metrics.classification_report` to get a full breakdown.\n",
        "\n",
        "### Generate a Classification Report\n",
        "\n",
        "To generate the classification report, we need the model’s predictions and the true labels for the validation/test set.\n",
        "---\n",
        "\n",
        "### Explanation of Each Part\n",
        "\n",
        "1. **`trainer.evaluate()`**: Provides basic evaluation metrics, like loss and accuracy, on the specified dataset.\n",
        "2. **`trainer.predict()`**: Runs inference on `val_dataset` to get raw predictions.\n",
        "3. **`np.argmax`**: Converts the raw logits (output scores) to class labels by taking the index of the highest score for each sample.\n",
        "4. **`classification_report`**: Generates precision, recall, and F1 scores for each class (positive and negative sentiment).\n",
        "\n",
        "The classification report will give you insights into the model’s performance across these metrics, helping you assess how well it handles each class individually.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ar4Aqs65qfXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"Evaluation Results:\", eval_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Iqpi5p9qqkk-",
        "outputId": "4f946d2d-1866-40ac-d7d7-d209255f0124"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:53]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.3747371733188629, 'eval_runtime': 54.5796, 'eval_samples_per_second': 4.58, 'eval_steps_per_second': 0.586, 'epoch': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Get predictions on the validation/test set\n",
        "predictions = trainer.predict(val_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=1)  # Convert logits to class labels\n",
        "\n",
        "# Generate the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(val_dataset[\"labels\"], preds, target_names=[\"Negative\", \"Positive\"]))"
      ],
      "metadata": {
        "id": "IvT6cGsVjIeh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}