{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO1F4WjZgGRFZNb/LzXMXHq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d3fd533c8de24d9f83a349cab733617f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_926fd48d700541b2975ebdf4af23199c",
              "IPY_MODEL_001d9b100d8846a89bfae26f66d33c75",
              "IPY_MODEL_dac89dbd3f084885897c3e768c0bb28b"
            ],
            "layout": "IPY_MODEL_134fbcf84a544140a893ebbfc17f4b9d"
          }
        },
        "926fd48d700541b2975ebdf4af23199c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25fbfbbe34b94c639caa50d42420ca16",
            "placeholder": "​",
            "style": "IPY_MODEL_008231acf2784f4e86267537f1b7c995",
            "value": "config.json: 100%"
          }
        },
        "001d9b100d8846a89bfae26f66d33c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aefa69de00084a909aad873653c0ff4e",
            "max": 1802,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d527da7b93c4ac3ab9ef6b49482a1e6",
            "value": 1802
          }
        },
        "dac89dbd3f084885897c3e768c0bb28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70eec555ca20479cb240952a08cc4287",
            "placeholder": "​",
            "style": "IPY_MODEL_167c57e4c45647efaca344a702f46631",
            "value": " 1.80k/1.80k [00:00&lt;00:00, 87.4kB/s]"
          }
        },
        "134fbcf84a544140a893ebbfc17f4b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25fbfbbe34b94c639caa50d42420ca16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008231acf2784f4e86267537f1b7c995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aefa69de00084a909aad873653c0ff4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d527da7b93c4ac3ab9ef6b49482a1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70eec555ca20479cb240952a08cc4287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "167c57e4c45647efaca344a702f46631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3227abd82da74353b3923c9cd3236645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a950e22fabcc46fb914f542576e23fd7",
              "IPY_MODEL_4ef24ac80b344927a6e765400c94afaa",
              "IPY_MODEL_23639c3514ac4d5a822916fc915bc262"
            ],
            "layout": "IPY_MODEL_7a13062d0c40433384ff9fba69947af0"
          }
        },
        "a950e22fabcc46fb914f542576e23fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4d54ded4204439bb1a57f40d64c7753",
            "placeholder": "​",
            "style": "IPY_MODEL_40441cdd89ea4d4ebdaf91ae92298de0",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "4ef24ac80b344927a6e765400c94afaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28955f664d14b818e91bb7272de3998",
            "max": 1222317369,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aad68ec3d0b24537925d59c2b62eaafd",
            "value": 1222317369
          }
        },
        "23639c3514ac4d5a822916fc915bc262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb419b1ecac945c791830a691e1f6f28",
            "placeholder": "​",
            "style": "IPY_MODEL_eba0e4c00a7a4822bd733bece9c81f13",
            "value": " 1.22G/1.22G [00:14&lt;00:00, 114MB/s]"
          }
        },
        "7a13062d0c40433384ff9fba69947af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4d54ded4204439bb1a57f40d64c7753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40441cdd89ea4d4ebdaf91ae92298de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f28955f664d14b818e91bb7272de3998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad68ec3d0b24537925d59c2b62eaafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb419b1ecac945c791830a691e1f6f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eba0e4c00a7a4822bd733bece9c81f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd23a1f498994b5c93d26708bad0d29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23dc52d699004000a1fa4efcd0878628",
              "IPY_MODEL_8d8c23a42dda4e878470d9388b5b0bb7",
              "IPY_MODEL_7222d046ecdf41be946971a888f91688"
            ],
            "layout": "IPY_MODEL_105f1f19b82b4e9a9885d0efab6dbfd9"
          }
        },
        "23dc52d699004000a1fa4efcd0878628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd8ad612f4eb4a1bbf22d993a1e1ae12",
            "placeholder": "​",
            "style": "IPY_MODEL_f52ed950934e4e98b87a0876cb1d308d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8d8c23a42dda4e878470d9388b5b0bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0aa97e1757a4426b3a2404e98d3755e",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ce27bf1ddb14d6e8652ca5cf998d005",
            "value": 26
          }
        },
        "7222d046ecdf41be946971a888f91688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15673a075414089b544c0fafd11dad5",
            "placeholder": "​",
            "style": "IPY_MODEL_c498d48e10af4513a4660f0781517ce4",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.23kB/s]"
          }
        },
        "105f1f19b82b4e9a9885d0efab6dbfd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8ad612f4eb4a1bbf22d993a1e1ae12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52ed950934e4e98b87a0876cb1d308d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0aa97e1757a4426b3a2404e98d3755e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ce27bf1ddb14d6e8652ca5cf998d005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c15673a075414089b544c0fafd11dad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c498d48e10af4513a4660f0781517ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "236a8e7a584b48a68c1310fd8814ecce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b17467e7f51c43029a192b7e8399fe0c",
              "IPY_MODEL_1996c48c7d7e43f2a1e9f07572403ddc",
              "IPY_MODEL_1c7e3cee7dd542d38ce934959801cdef"
            ],
            "layout": "IPY_MODEL_564c73a411bc4d9f9237d2a0e44638e5"
          }
        },
        "b17467e7f51c43029a192b7e8399fe0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d719d7a632ee4c2ca7f4f5f06fb9dda0",
            "placeholder": "​",
            "style": "IPY_MODEL_18e5e631d8674085be315734d4f972bc",
            "value": "vocab.json: 100%"
          }
        },
        "1996c48c7d7e43f2a1e9f07572403ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b75ffff66ce54d1c97d890d7ef61f34e",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8762614919d94ce1820f4fccfbc1a3e5",
            "value": 898822
          }
        },
        "1c7e3cee7dd542d38ce934959801cdef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8d9cf7712a4eb3bd42b5cddc8786d0",
            "placeholder": "​",
            "style": "IPY_MODEL_35c3a4fe4cc746ab9b695d5f421b22a8",
            "value": " 899k/899k [00:00&lt;00:00, 3.70MB/s]"
          }
        },
        "564c73a411bc4d9f9237d2a0e44638e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d719d7a632ee4c2ca7f4f5f06fb9dda0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e5e631d8674085be315734d4f972bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b75ffff66ce54d1c97d890d7ef61f34e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8762614919d94ce1820f4fccfbc1a3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d8d9cf7712a4eb3bd42b5cddc8786d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c3a4fe4cc746ab9b695d5f421b22a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e843be174d74d4eb4933b97ac817c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2078a4b46de2475abdc2d3d7e08a1bfe",
              "IPY_MODEL_a2869d41133d44ce8c861f8e3800e2d7",
              "IPY_MODEL_fc599ff8b6b1453d9fdad3af7082de08"
            ],
            "layout": "IPY_MODEL_38269e793aeb404ab7f15f615b41868c"
          }
        },
        "2078a4b46de2475abdc2d3d7e08a1bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbfa3d4144d64d05906a986bab820873",
            "placeholder": "​",
            "style": "IPY_MODEL_044af525d23c498986b3ea7d11bf13cc",
            "value": "merges.txt: 100%"
          }
        },
        "a2869d41133d44ce8c861f8e3800e2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fbc349ca67242f5a7d4823117a9f3d3",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2d531cd4e3346a4b9f8f8ce028de9fd",
            "value": 456318
          }
        },
        "fc599ff8b6b1453d9fdad3af7082de08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc3a8bb28df14623896d7df19ab52d0d",
            "placeholder": "​",
            "style": "IPY_MODEL_c6082cb049384908a7df3861778a63b8",
            "value": " 456k/456k [00:00&lt;00:00, 8.17MB/s]"
          }
        },
        "38269e793aeb404ab7f15f615b41868c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbfa3d4144d64d05906a986bab820873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044af525d23c498986b3ea7d11bf13cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fbc349ca67242f5a7d4823117a9f3d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d531cd4e3346a4b9f8f8ce028de9fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc3a8bb28df14623896d7df19ab52d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6082cb049384908a7df3861778a63b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/LLMs/blob/main/LLM_022_useragent_reuquests_PDF_summarzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. **What is a User-Agent?**\n",
        "\n",
        "A **User-Agent** is a string that your browser or application (like Python's `requests` library) sends to a web server to identify itself. It typically includes information like the browser type, operating system, and version. Servers can use this information to tailor responses (like sending different content to mobile vs. desktop browsers) or to block certain kinds of clients (e.g., bots).\n",
        "\n",
        "For example, when you visit a website with a browser like Chrome, your browser sends a User-Agent string like this:\n",
        "\n",
        "```\n",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36\n",
        "```\n",
        "\n",
        "In the case of Python's `requests` library, it uses a default User-Agent like this:\n",
        "\n",
        "```\n",
        "python-requests/2.26.0\n",
        "```\n",
        "\n",
        "Some websites might block requests that come from the default Python User-Agent, assuming it’s from an automated script. To bypass that, you can \"spoof\" your User-Agent to make it appear like a regular browser.\n",
        "\n",
        "**Example of setting a custom User-Agent in `requests`:**\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "url = 'https://example.com'\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36'}\n",
        "response = requests.get(url, headers=headers)\n",
        "```\n",
        "\n",
        "### 2. **What are `requests` and `response` in Python?**\n",
        "\n",
        "#### a) `requests` Library\n",
        "The `requests` library is used to send HTTP requests in Python. It allows you to interact with websites, APIs, or other online services by sending various types of requests (e.g., `GET`, `POST`, `PUT`, etc.) and receiving responses.\n",
        "\n",
        "- **`requests.get()`**: This sends a GET request to the server to fetch the resource (like a web page or file).\n",
        "- **`requests.post()`**: This sends a POST request, usually to submit data (like form data) to a server.\n",
        "\n",
        "#### b) `response` Object\n",
        "When you send a request (e.g., `requests.get()`), the server responds, and `requests` returns a **response object**. This response object contains various details about the server's response, such as:\n",
        "\n",
        "- **`response.status_code`**: This is the HTTP status code that tells you whether the request was successful. Common status codes are:\n",
        "  - `200`: Success (The request was successful).\n",
        "  - `404`: Not Found (The requested resource couldn't be found on the server).\n",
        "  - `500`: Internal Server Error (Something went wrong on the server).\n",
        "\n",
        "- **`response.content`**: This is the raw content of the response (often binary, like when downloading a file).\n",
        "\n",
        "- **`response.text`**: This is the content of the response in text format (usually HTML or JSON).\n",
        "\n",
        "- **`response.json()`**: If the response is in JSON format, you can use this method to parse it into a Python dictionary.\n",
        "\n",
        "### Example: Making a Request and Getting a Response\n",
        "```python\n",
        "import requests\n",
        "\n",
        "# Send a GET request to the server\n",
        "url = 'https://api.example.com/data'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Access the status code\n",
        "print(response.status_code)  # 200 means success\n",
        "\n",
        "# Access the content of the response\n",
        "print(response.text)  # Print the text (HTML, JSON, etc.) returned by the server\n",
        "\n",
        "# If it's a JSON response, convert it to a dictionary\n",
        "data = response.json()\n",
        "print(data)\n",
        "```\n",
        "\n",
        "### 3. **What is `response.status_code == 200`?**\n",
        "\n",
        "When you check `response.status_code == 200`, you are confirming whether the request was **successful**. The status code `200` is part of the HTTP standard and indicates that the request was successfully received, understood, and processed by the server.\n",
        "\n",
        "- **200 OK**: This status code means the server successfully processed the request and sent back the expected content.\n",
        "  \n",
        "You often check for `200` to ensure that the request was successful before proceeding to work with the response content:\n",
        "\n",
        "```python\n",
        "if response.status_code == 200:\n",
        "    print(\"Request was successful!\")\n",
        "else:\n",
        "    print(f\"Failed with status code: {response.status_code}\")\n",
        "```\n",
        "\n",
        "### Example Use Case:\n",
        "Let's say you're trying to download a PDF file from a website. You can send a `GET` request and check if the server returns a `200` status code before saving the file.\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "url = 'https://example.com/somefile.pdf'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Save the file locally\n",
        "    with open('downloaded_file.pdf', 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(\"File downloaded successfully!\")\n",
        "else:\n",
        "    print(f\"Failed to download file. Status code: {response.status_code}\")\n",
        "```\n",
        "\n",
        "### Summary:\n",
        "- **User-Agent**: A string identifying your client (like a browser or script) to the server.\n",
        "- **`requests`**: A Python library used to send HTTP requests to a web server.\n",
        "- **`response`**: The server's response to your request, containing the content, status code, headers, etc.\n",
        "- **`response.status_code == 200`**: A check to confirm the request was successful, as `200` is the standard status code for success.\n",
        "\n"
      ],
      "metadata": {
        "id": "uarglSK7Z6b8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the response object is essential for working with APIs! The `requests` library in Python makes it easy to interact with APIs, and the response object it returns is central to handling the data you get back from an API.\n",
        "\n",
        "### What is the Response Object?\n",
        "\n",
        "When you make a request using `requests.get()` or `requests.post()`, Python sends an HTTP request to the API’s endpoint. The response that comes back from the server contains several elements:\n",
        "\n",
        "- **Status Code** (`response.status_code`): Indicates whether the request was successful (like 200 for OK or 404 for Not Found).\n",
        "- **Headers** (`response.headers`): Contains metadata about the response, such as content type, date, and server information.\n",
        "- **Content** (`response.content`): The raw response data in bytes, which is useful for non-text responses like images or PDFs.\n",
        "- **Text** (`response.text`): The response data decoded as a string. Useful for reading HTML or plain text responses.\n",
        "- **JSON** (`response.json()`): If the server returns JSON data (a structured format commonly used in APIs), this method will parse it into a Python dictionary or list.\n",
        "\n",
        "### Loading the Response as JSON\n",
        "\n",
        "APIs often return data in JSON format, so it’s common to load the response as JSON using `response.json()`. This only works if the response is actually JSON. Attempting to call `response.json()` on non-JSON data (like a PDF) will cause an error.\n",
        "\n",
        "### Extracting Elements from the Response\n",
        "\n",
        "Once you’ve verified that the response contains JSON data, you can access elements of the parsed JSON as you would with any dictionary or list in Python.\n",
        "\n",
        "Here’s a basic example to illustrate:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "# Example of making an API request that returns JSON data\n",
        "url = 'https://jsonplaceholder.typicode.com/todos/1'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Load response as JSON\n",
        "    data = response.json()\n",
        "    \n",
        "    # Print the JSON data\n",
        "    print(\"Full JSON data:\", data)\n",
        "    \n",
        "    # Access individual items in the JSON (assuming it's a dictionary)\n",
        "    print(\"User ID:\", data['userId'])\n",
        "    print(\"ID:\", data['id'])\n",
        "    print(\"Title:\", data['title'])\n",
        "    print(\"Completed:\", data['completed'])\n",
        "else:\n",
        "    print(\"Failed to retrieve data\")\n",
        "```\n",
        "\n",
        "### Explanation of the Code:\n",
        "\n",
        "1. **Make the Request**: `response = requests.get(url)`\n",
        "2. **Check the Status Code**: `if response.status_code == 200`\n",
        "   - A status code of `200` means the request was successful.\n",
        "3. **Load JSON Data**: `data = response.json()`\n",
        "   - This converts the JSON data into a Python dictionary (or list).\n",
        "4. **Extract Values**: `data['userId']`, `data['title']`, etc.\n",
        "   - Access values in the dictionary using keys.\n",
        "\n",
        "In this example, the JSON response is something like:\n",
        "```json\n",
        "{\n",
        "  \"userId\": 1,\n",
        "  \"id\": 1,\n",
        "  \"title\": \"delectus aut autem\",\n",
        "  \"completed\": false\n",
        "}\n",
        "```\n",
        "\n",
        "### Key Points to Remember:\n",
        "\n",
        "- **Use `response.json()` only if the response is JSON**. If it’s not, you’ll get a `JSONDecodeError`.\n",
        "- **Use `response.content`** for non-text responses (like files) that you want to save directly.\n",
        "- **Check the `Content-Type` header** (`response.headers['Content-Type']`) to understand the type of data in the response. JSON responses typically have `Content-Type: application/json`.\n",
        "\n"
      ],
      "metadata": {
        "id": "IOX1Fegty4xG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# response.headers[list('Date', 'Content-Type', 'access-control-allow-methods', 'access-control-allow-origin')]\n",
        "\n",
        "import requests\n",
        "\n",
        "# Step 1: Download the file\n",
        "url = 'https://core.ac.uk/download/pdf/35115719.pdf'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Print out different parts of the response object\n",
        "    print(\"Status Code:\", response.status_code)  # Status code of the request\n",
        "    print(\"Headers:\", response.headers)  # Headers with metadata about the response\n",
        "    print(\"Content-Type:\", response.headers.get('Content-Type'))  # Specific header field for content type\n",
        "    print(\"Date:\", response.headers.get('Date'))  # Specific header field for date\n",
        "    print(\"Content (first 500 bytes):\", response.content[:500])  # First 500 bytes of content for a glimpse\n",
        "\n",
        "    # Try to parse as JSON to see if it’s JSON data (it won't be in this case)\n",
        "    try:\n",
        "        data = response.json()\n",
        "        print(\"JSON data:\", data)\n",
        "    except ValueError:\n",
        "        print(\"The response is not in JSON format.\")\n",
        "else:\n",
        "    print(\"Failed to download the file\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mze4Dg5Rr97X",
        "outputId": "4b0a4fde-7b57-4df6-b297-2dafd984d85a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Headers: {'Date': 'Thu, 07 Nov 2024 13:40:38 GMT', 'Content-Type': 'application/pdf', 'Content-Length': '561867', 'Connection': 'keep-alive', 'x-frame-options': 'SAMEORIGIN, SAMEORIGIN, SAMEORIGIN', 'access-control-allow-methods': 'POST, GET, OPTIONS', 'access-control-allow-origin': '*', 'access-control-allow-headers': 'Content-Type, Access-Control-Allow-Headers, Authorization, X-Frame-Options', 'Cache-Control': 'public', 'link': '<https://core.ac.uk/reader/35115719>; rel=\"canonical\"', 'last-modified': 'Mon, 15 Mar 2021 19:24:30 GMT', 'etag': '\"892cb-5bd9832e37780\"', 'vary': 'User-Agent, Accept-Encoding', 'CF-Cache-Status': 'BYPASS', 'Set-Cookie': '_ga=GA1.3.c3a37971-bb78-45fe-abec-520004f1123e; expires=Sat, 07-Nov-2026 13:40:38 GMT; Max-Age=63072000; path=/; domain=core.ac.uk', 'Accept-Ranges': 'bytes', 'Report-To': '{\"endpoints\":[{\"url\":\"https:\\\\/\\\\/a.nel.cloudflare.com\\\\/report\\\\/v4?s=bupxntrASWPNs%2BmFOdUJzunEc4zmINNOp%2FON7Ee6qVmmHW1zL6dtD5kPMkGjrnDQJPSgWMD%2BKKuM4KTkKOghRfHlCn7SP0JTKcJazjABvu7tDq4S56ypVRblXRdO\"}],\"group\":\"cf-nel\",\"max_age\":604800}', 'NEL': '{\"success_fraction\":0,\"report_to\":\"cf-nel\",\"max_age\":604800}', 'Server': 'cloudflare', 'CF-RAY': '8dedbc7a3fb35c90-ORD', 'alt-svc': 'h3=\":443\"; ma=86400', 'server-timing': 'cfL4;desc=\"?proto=TCP&rtt=11305&sent=4&recv=6&lost=0&retrans=0&sent_bytes=2838&recv_bytes=785&delivery_rate=259591&cwnd=250&unsent_bytes=0&cid=ae80412cc3d4e8d9&ts=468&x=0\"'}\n",
            "Content-Type: application/pdf\n",
            "Date: Thu, 07 Nov 2024 13:40:38 GMT\n",
            "Content (first 500 bytes): b'%PDF-1.6\\n%\\xf6\\xe4\\xfc\\xdf\\n1 0 obj\\n<<\\n/Metadata 2 0 R\\n/Pages 3 0 R\\n/Type /Catalog\\n>>\\nendobj\\n4 0 obj\\n<<\\n/CreationDate (D:20110502201921+02\\'00\\')\\n/Creator (Adobe InDesign CS5 \\\\(7.0.3\\\\))\\n/ModDate (D:20111128144517+01\\'00\\')\\n/Producer (Adobe PDF Library 9.9)\\n>>\\nendobj\\n2 0 obj\\n<<\\n/Length 3358\\n/Subtype /XML\\n/Type /Metadata\\n>>\\nstream\\r\\n<?xpacket begin=\"\\xef\\xbb\\xbf\" id=\"W5M0MpCehiHzreSzNTczkc9d\"?>\\n<x:xmpmeta xmlns:x=\"adobe:ns:meta/\" x:xmptk=\"Adobe XMP Core 5.2-c001 63.139439, 2010/09/27-13:37:26        \">\\n   <rdf:RDF xmlns:rdf'\n",
            "The response is not in JSON format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Access Response Content\n",
        "\n",
        "Let’s break down why we use different methods to access parts of the `response` object.\n",
        "\n",
        "### 1. Accessing `response.headers` with `.get()`\n",
        "\n",
        "`response.headers` is a dictionary-like object, where each header name is a key and its corresponding value is the content of that header. When you access a specific header like `\"Date\"` using `.get()`, you’re using a dictionary’s method to safely retrieve the value:\n",
        "\n",
        "```python\n",
        "response.headers.get('Date')\n",
        "```\n",
        "\n",
        "This is useful because:\n",
        "- **If the header exists**: `.get()` returns its value (like `'Wed, 07 Nov 2024 12:34:56 GMT'`).\n",
        "- **If the header does not exist**: `.get()` returns `None` instead of raising an error, allowing your code to avoid breaking if the header is missing.\n",
        "\n",
        "#### Example:\n",
        "Using `.get()` ensures that if `\"Date\"` isn’t in `response.headers`, it won’t throw a `KeyError`. Instead, it will simply return `None`, which you can handle gracefully.\n",
        "\n",
        "### 2. Accessing `response.content` with Indexing (`[:500]`)\n",
        "\n",
        "`response.content` is a **byte string** containing the raw content of the response (such as a PDF, image, or HTML document). Unlike `response.headers`, it’s not a dictionary but a single, long string of binary data. Here, we use **slicing** to print just a small part of it:\n",
        "\n",
        "```python\n",
        "response.content[:500]\n",
        "```\n",
        "\n",
        "This takes the **first 500 bytes** of the content and shows them, giving you a preview without overwhelming the console with potentially large data.\n",
        "\n",
        "#### Why Indexing?\n",
        "\n",
        "Since `response.content` is a byte string, you can treat it like a sequence of bytes (similar to a list of characters in a regular string). Slicing is a common way to limit what we print or display, especially when the content is large (e.g., files, images).\n",
        "\n",
        "### Summary\n",
        "\n",
        "- **`response.headers.get('Date')`**: Safe access for dictionary items; avoids errors if the key is missing.\n",
        "- **`response.content[:500]`**: Slice the first 500 bytes of a byte string for a preview without printing everything.\n",
        "\n"
      ],
      "metadata": {
        "id": "KhUdAhGF0YaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read PDF from URL\n",
        "\n",
        "1. **Download the PDF File**:\n",
        "   ```python\n",
        "   response = requests.get(url)\n",
        "   ```\n",
        "   This line sends an HTTP GET request to the specified URL, attempting to retrieve the file. Since this URL points to a PDF, `response.content` contains the raw binary data of the PDF file.\n",
        "\n",
        "2. **Check the Response Status**:\n",
        "   ```python\n",
        "   if response.status_code == 200:\n",
        "   ```\n",
        "   We’re confirming that the request was successful (status code `200`). If it wasn’t, we print an error message instead of proceeding, ensuring we only save the file if it was downloaded correctly.\n",
        "\n",
        "3. **Save the PDF to a Local File**:\n",
        "   ```python\n",
        "   with open('downloaded.pdf', 'wb') as f:\n",
        "       f.write(response.content)\n",
        "   ```\n",
        "   This step saves the binary data to a file:\n",
        "   - **`'downloaded.pdf'`**: Specifies the file’s name.\n",
        "   - **`'wb'` (write binary)**: Opens the file in binary mode for writing, which is required for non-text files like PDFs.\n",
        "   - **`f.write(response.content)`**: Writes the entire byte string of `response.content` to the file, storing the PDF locally.\n",
        "\n",
        "### How This Differs from the Previous Code\n",
        "\n",
        "- **No JSON Parsing Attempt**: This code doesn’t attempt to interpret the response as JSON because we know we’re handling a binary file.\n",
        "- **Directly Saving the File**: Since the goal is to download the file, we immediately save `response.content` to disk, making the code more efficient and focused on the task of saving.\n",
        "- **No Preview of Data**: We skip previewing the content because, with binary data, there’s no need to inspect it (it would appear as unreadable bytes).\n",
        "\n",
        "### Why This Approach is Effective for File Downloads\n",
        "\n",
        "When working with downloadable files (like PDFs, images, or zip files):\n",
        "- **Binary Mode**: Ensures the file’s integrity by preserving its raw byte structure.\n",
        "- **No JSON Parsing or String Manipulation**: Simplifies the code by treating the response as a file download rather than data for immediate inspection or manipulation.\n",
        "  \n"
      ],
      "metadata": {
        "id": "p-yPsL1ZaEa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTcMBkHX5qGG",
        "outputId": "9b0c3536-53b6-46fc-a34a-fb504df73b41"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfx in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: pdfminer.six==20201018 in /usr/local/lib/python3.10/dist-packages (from pdfx) (20201018)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfx) (4.0.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20201018->pdfx) (43.0.3)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20201018->pdfx) (2.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->pdfminer.six==20201018->pdfx) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->pdfminer.six==20201018->pdfx) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pdfx\n",
        "\n",
        "# Step 1: Download the PDF file\n",
        "url = 'https://core.ac.uk/download/pdf/35115719.pdf'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Step 2: Save the PDF to a local file\n",
        "    with open('downloaded.pdf', 'wb') as f:\n",
        "        f.write(response.content)\n",
        "else:\n",
        "    print(\"Failed to download the file\")\n"
      ],
      "metadata": {
        "id": "TpKlBXxMX2jO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process PDF\n",
        "\n",
        "This code processes a saved PDF file using the `pdfx` library. Let’s break down what it does and suggest some improvements:\n",
        "\n",
        "### Code Explanation\n",
        "\n",
        "1. **Load the PDF File with `pdfx`**:\n",
        "   ```python\n",
        "   pdf = pdfx.PDFx('downloaded.pdf')\n",
        "   ```\n",
        "   This line creates a `PDFx` object by loading the saved PDF file (`'downloaded.pdf'`). The `pdfx` library is designed for extracting metadata, text, and references (e.g., URLs) from PDF documents.\n",
        "\n",
        "2. **Extract Metadata**:\n",
        "   ```python\n",
        "   metadata = pdf.get_metadata()\n",
        "   print(metadata)\n",
        "   ```\n",
        "   The `get_metadata()` method retrieves metadata from the PDF, which may include:\n",
        "   - Title, author, and subject\n",
        "   - Creation date, modification date\n",
        "   - Producer (software that generated the PDF)\n",
        "   - Other embedded information specific to the PDF\n",
        "\n",
        "   Printing `metadata` shows this information in a dictionary format, making it accessible for further analysis or saving.\n",
        "\n",
        "\n",
        "### Summary Code\n",
        "\n",
        "- **File Existence Check**: Ensures `'downloaded.pdf'` is present before processing.\n",
        "- **Error Handling**: Uses a try-except block to catch any issues with loading or processing the PDF.\n",
        "- **Optional Saving of Metadata**: Saves metadata to a JSON file if you want to keep a record.\n",
        "- **Text Extraction Preview**: Provides a short preview of the PDF’s content for quick inspection.\n",
        "\n"
      ],
      "metadata": {
        "id": "PyV_Eg_GYG_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pdfx\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists('downloaded.pdf'):\n",
        "    try:\n",
        "        # Load the PDF file\n",
        "        pdf = pdfx.PDFx('downloaded.pdf')\n",
        "\n",
        "        # Extract and print metadata\n",
        "        metadata = pdf.get_metadata()\n",
        "        print(\"Metadata:\", metadata)\n",
        "\n",
        "        # Optionally save metadata to a JSON file\n",
        "        with open('metadata.json', 'w') as f:\n",
        "            json.dump(metadata, f, indent=4)\n",
        "        print(\"Metadata saved to 'metadata.json'\")\n",
        "\n",
        "        # Extract and print a preview of the PDF text\n",
        "        text = pdf.get_text()\n",
        "        print(\"Extracted Text (Preview):\", text[:500])  # First 500 characters\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred while processing the PDF:\", e)\n",
        "else:\n",
        "    print(\"File 'downloaded.pdf' does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpgxA5Jp1zx4",
        "outputId": "48451458-7619-4c0c-8ef0-8d9efd60c452"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata: {'CreationDate': \"D:20110502201921+02'00'\", 'Creator': 'Adobe InDesign CS5 (7.0.3)', 'ModDate': \"D:20111128144517+01'00'\", 'Producer': 'Adobe PDF Library 9.9', 'rdf': {}, 'xap': {'ModifyDate': '2011-11-28T14:45:17+01:00', 'CreateDate': '2011-05-02T20:19:21+02:00', 'MetadataDate': '2011-11-28T14:45:17+01:00', 'CreatorTool': 'Adobe InDesign CS5 (7.0.3)'}, 'dc': {'format': 'application/pdf'}, 'xapmm': {'DocumentID': 'uuid:c8b0c497-6ec1-4539-836e-754e73d73881', 'InstanceID': 'uuid:c937332f-d96b-49f0-9fe3-23c4c93d5bef'}, 'pdf': {'Producer': 'Adobe PDF Library 9.9'}, 'Pages': 5}\n",
            "Metadata saved to 'metadata.json'\n",
            "Extracted Text (Preview): CORE\n",
            "\n",
            "Provided by Open Marine Archive\n",
            "\n",
            "Metadata, citation and similar papers at core.ac.uk\n",
            "\n",
            "Journal of Coastal Research \n",
            "Journal of Coastal Research\n",
            "\n",
            "SI 64 \n",
            "SI 64\n",
            "\n",
            "pg - pg \n",
            "349 - 353\n",
            "\n",
            "ICS2011 (Proceedings) \n",
            "ICS2011 (Proceedings)\n",
            "\n",
            "Poland \n",
            "Poland\n",
            "\n",
            "ISSN 0749-0208 \n",
            "ISSN 0749-0208\n",
            "\n",
            " \n",
            "\n",
            "Characterisation  of  mangrove  forest  types  in  view  of  conservation  and \n",
            "management:  a  review  of  mangals  at  the  Cananéia  region,  São  Paulo \n",
            "State, Brazil \n",
            "\n",
            "M. Cunha-Lignon†‡∞ , C. Coelho Jr. ‡*, R. Alme\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF from Google Drive\n",
        "The steps for reading a file from a **URL** and from **Google Drive** differ because of how each service handles file hosting and access. Let me break it down:\n",
        "\n",
        "### 1. **Reading from a URL** (Standard Web Server)\n",
        "When you download a file from a typical URL, you're accessing a file hosted on a web server that directly serves files in response to HTTP requests. Here's how it works:\n",
        "\n",
        "- **Standard Web Server**: A web server like `example.com` or `core.ac.uk` serves files when requested through standard HTTP or HTTPS protocols.\n",
        "- **Direct File Links**: If the link points directly to a file (e.g., a `.pdf` or `.csv` file), you can use Python's `requests` library to directly fetch the content of the file and save it or process it.\n",
        "\n",
        "**Example**:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "# URL points directly to a file\n",
        "url = 'https://example.com/somefile.pdf'\n",
        "\n",
        "# Make the GET request to download the file\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    with open('file.pdf', 'wb') as f:\n",
        "        f.write(response.content)\n",
        "else:\n",
        "    print(f\"Failed to download the file: {response.status_code}\")\n",
        "```\n",
        "\n",
        "In this case, you're making a direct request to the server for a file, and the server responds by sending the file contents. There are no extra steps or layers involved.\n",
        "\n",
        "### 2. **Reading from Google Drive**\n",
        "Google Drive works a bit differently. When you share a file through Google Drive, the URL typically does **not** point directly to the file but instead to a **web page** where the file is displayed (such as a view or download page).\n",
        "\n",
        "Here's what happens with a Google Drive link:\n",
        "\n",
        "- **Google Drive Link (view page)**: When you access a file through a standard Google Drive link, you're not taken directly to the file itself. Instead, Google presents a web page with an embedded viewer for the file (like the one you get when clicking \"View\" on a shared Google Drive link).\n",
        "- **Direct Download Links**: Google provides a mechanism to generate direct download links that let you bypass the \"View\" page and download the file directly. This requires modifying the URL.\n",
        "\n",
        "#### How to Convert Google Drive URLs:\n",
        "When working with Google Drive links, the standard format is:\n",
        "\n",
        "```\n",
        "https://drive.google.com/file/d/{file_id}/view\n",
        "```\n",
        "\n",
        "To directly download the file, you need to convert this to:\n",
        "\n",
        "```\n",
        "https://drive.google.com/uc?export=download&id={file_id}\n",
        "```\n",
        "\n",
        "- The `{file_id}` is the unique identifier for your file, which you extract from the standard Google Drive link.\n",
        "\n",
        "**Example of Downloading a File from Google Drive**:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "# Original Google Drive URL (view page)\n",
        "url = 'https://drive.google.com/file/d/1ILsIxKRBmqPxGW6Py3pRPLiBWhWBEU3g/view'\n",
        "\n",
        "# Convert to direct download URL\n",
        "file_id = '1ILsIxKRBmqPxGW6Py3pRPLiBWhWBEU3g'\n",
        "download_url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "\n",
        "# Download the file\n",
        "response = requests.get(download_url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    with open('downloaded_file.pdf', 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(\"File downloaded successfully!\")\n",
        "else:\n",
        "    print(f\"Failed to download file. Status code: {response.status_code}\")\n",
        "```\n",
        "\n",
        "### Why the Difference?\n",
        "\n",
        "- **Standard URL**: When you download a file from a typical web server (like `example.com`), you're usually dealing with a direct link to the file. No extra steps are needed, and you can download the file directly with a `GET` request.\n",
        "  \n",
        "- **Google Drive**: Google Drive serves files differently. Google Drive links typically point to a view or preview page, not the file itself. You need to either modify the URL to create a direct download link or download the file manually from the interface.\n",
        "\n",
        "### Summary of the Differences:\n",
        "1. **File Hosting**:\n",
        "   - **URL**: Direct access to the file.\n",
        "   - **Google Drive**: Requires viewing through Google’s interface, or a modified link for direct download.\n",
        "\n",
        "2. **URL Format**:\n",
        "   - **URL**: Points directly to a downloadable file (e.g., `example.com/file.pdf`).\n",
        "   - **Google Drive**: Needs a special download link (`uc?export=download`).\n",
        "\n",
        "3. **Additional Step**:\n",
        "   - **Google Drive**: Requires extracting the file ID and converting the URL for direct download.\n",
        "\n",
        "### Use Case Example:\n",
        "\n",
        "- **Direct URL**:\n",
        "  - You can use a simple `requests.get()` to fetch the file.\n",
        "\n",
        "- **Google Drive**:\n",
        "  - You need to modify the URL to the direct download format or use an API (e.g., Google Drive API) for more complex operations.\n"
      ],
      "metadata": {
        "id": "fep07O1wYhzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PDF from Google Drive"
      ],
      "metadata": {
        "id": "obAsC06ai0c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pdfx\n",
        "\n",
        "# Step 1: Download the file from Google Drive\n",
        "url = 'https://drive.google.com/uc?export=download&id=1ILsIxKRBmqPxGW6Py3pRPLiBWhWBEU3g'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Print headers and other response info\n",
        "    print(\"Status Code:\", response.status_code)\n",
        "    print(\"Headers:\", response.headers)  # Print all headers\n",
        "    print(\"Content-Type:\", response.headers.get('Content-Type'))  # Specific header field\n",
        "    print(\"Date:\", response.headers.get('Date'))  # Specific header field\n",
        "\n",
        "    # Step 2: Save the PDF to a local file\n",
        "    with open('google_drive_downloaded.pdf', 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(\"File downloaded and saved as 'google_drive_downloaded.pdf'\")\n",
        "else:\n",
        "    print(\"Failed to download the file\")\n",
        "\n",
        "# Step 3: Process the saved PDF file\n",
        "try:\n",
        "    pdf = pdfx.PDFx('google_drive_downloaded.pdf')\n",
        "\n",
        "    # Extract and print a slice of the text\n",
        "    text = pdf.get_text()\n",
        "    print(\"Extracted Text (Preview):\", text[:500])  # Print the first 500 characters of the text\n",
        "\n",
        "    # Extract and print metadata for reference\n",
        "    metadata = pdf.get_metadata()\n",
        "    print(\"Metadata:\", metadata)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"An error occurred while processing the PDF:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLVuxPHE3V5v",
        "outputId": "89ac8bbd-fc51-4e38-eef4-19ab7d5c7c75"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Headers: {'Content-Type': 'application/octet-stream', 'Content-Security-Policy': \"sandbox, default-src 'none', frame-ancestors 'none'\", 'X-Content-Security-Policy': 'sandbox', 'Cross-Origin-Opener-Policy': 'same-origin', 'Cross-Origin-Embedder-Policy': 'require-corp', 'Cross-Origin-Resource-Policy': 'same-site', 'X-Content-Type-Options': 'nosniff', 'Content-Disposition': 'attachment; filename=\"Art Collector personality types_ finish.pdf\"', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'false', 'Access-Control-Allow-Headers': 'Accept, Accept-Language, Authorization, Cache-Control, Content-Disposition, Content-Encoding, Content-Language, Content-Length, Content-MD5, Content-Range, Content-Type, Date, developer-token, financial-institution-id, X-Goog-Sn-Metadata, X-Goog-Sn-PatientId, GData-Version, google-cloud-resource-prefix, linked-customer-id, login-customer-id, x-goog-request-params, Host, If-Match, If-Modified-Since, If-None-Match, If-Unmodified-Since, Origin, OriginToken, Pragma, Range, request-id, Slug, Transfer-Encoding, hotrod-board-name, hotrod-chrome-cpu-model, hotrod-chrome-processors, Want-Digest, X-Ad-Manager-Impersonation, x-chrome-connected, X-ClientDetails, X-Client-Pctx, X-Client-Version, x-debug-settings-metadata, X-Firebase-Locale, X-Goog-Firebase-Installations-Auth, X-Firebase-Client, X-Firebase-Client-Log-Type, X-Firebase-GMPID, X-Firebase-Auth-Token, X-Firebase-AppCheck, X-Firebase-Token, X-Goog-Drive-Client-Version, X-Goog-Drive-Resource-Keys, X-GData-Client, X-GData-Key, X-GoogApps-Allowed-Domains, X-Goog-AdX-Buyer-Impersonation, X-Goog-Api-Client, X-Goog-Visibilities, X-Goog-AuthUser, X-Google-EOM, x-goog-ext-124712974-jspb, x-goog-ext-467253834-jspb, x-goog-ext-353267353-bin, x-goog-ext-353267353-jspb, x-goog-ext-251363160-jspb, x-goog-ext-259736195-jspb, x-goog-ext-477772811-jspb, x-goog-ext-359275022-bin, x-goog-ext-328800237-jspb, x-goog-ext-202735639-bin, x-goog-ext-223435598-bin, X-Goog-PageId, X-Goog-Encode-Response-If-Executable, X-Goog-Correlation-Id, X-Goog-Request-Info, X-Goog-Request-Reason, X-Goog-Request-Time, X-Goog-Experiments, x-goog-iam-authority-selector, x-goog-iam-authorization-token, X-Goog-Spatula, X-Goog-Travel-Bgr, X-Goog-Travel-Settings, X-Goog-Upload-Command, X-Goog-Upload-Content-Disposition, X-Goog-Upload-Content-Length, X-Goog-Upload-Content-Type, X-Goog-Upload-File-Name, X-Goog-Upload-Header-Content-Encoding, X-Goog-Upload-Header-Content-Length, X-Goog-Upload-Header-Content-Type, X-Goog-Upload-Header-Transfer-Encoding, X-Goog-Upload-Offset, X-Goog-Upload-Protocol, x-goog-user-project, X-Goog-Visitor-Id, X-Goog-FieldMask, X-Google-Project-Override, x-goog-maps-api-salt, x-goog-maps-api-signature, x-goog-maps-client-id, X-Goog-Api-Key, x-goog-spanner-database-role, X-HTTP-Method-Override, X-JavaScript-User-Agent, X-Pan-Versionid, X-Proxied-User-IP, X-Origin, X-Referer, X-Requested-With, X-Stadia-Client-Context, X-Upload-Content-Length, X-Upload-Content-Type, X-Use-Alt-Service, X-Use-HTTP-Status-Code-Override, X-Ios-Bundle-Identifier, X-Places-Ios-Sdk, X-Android-Package, X-Android-Cert, X-Places-Android-Sdk, X-Goog-Maps-Ios-Uuid, X-Goog-Maps-Android-Uuid, X-Ariane-Xsrf-Token, X-YouTube-Bootstrap-Logged-In, X-YouTube-VVT, X-YouTube-Page-CL, X-YouTube-Page-Timestamp, X-Compass-Routing-Destination, x-framework-xsrf-token, X-Goog-Meeting-ABR, X-Goog-Meeting-Botguardid, X-Goog-Meeting-ClientInfo, X-Goog-Meeting-ClientVersion, X-Goog-Meeting-Debugid, X-Goog-Meeting-Identifier, X-Goog-Meeting-Interop-Cohorts, X-Goog-Meeting-Interop-Type, X-Goog-Meeting-OidcIdToken, X-Goog-Meeting-RtcClient, X-Goog-Meeting-StartSource, X-Goog-Meeting-Token, X-Goog-Meeting-Viewer-Token, X-Client-Data, x-sdm-id-token, X-Sfdc-Authorization, MIME-Version, Content-Transfer-Encoding, X-Earth-Engine-App-ID-Token, X-Earth-Engine-Computation-Profile, X-Earth-Engine-Computation-Profiling, X-Play-Console-Experiments-Override, X-Play-Console-Session-Id, x-alkali-account-key, x-alkali-application-key, x-alkali-auth-apps-namespace, x-alkali-auth-entities-namespace, x-alkali-auth-entity, x-alkali-client-locale, EES-S7E-MODE, cast-device-capabilities, X-Server-Timeout, x-foyer-client-environment, x-goog-greenenergyuserappservice-metadata, x-goog-sherlog-context, X-Server-Token, x-rfui-request-context, x-goog-nest-jwt, X-Cloud-Trace-Context, traceparent, x-goog-chat-space-id, x-goog-pan-request-context, X-AppInt-Credentials', 'Access-Control-Allow-Methods': 'GET,HEAD,OPTIONS', 'Accept-Ranges': 'bytes', 'Content-Length': '3329419', 'Last-Modified': 'Sat, 03 Aug 2024 13:22:43 GMT', 'X-GUploader-UploadID': 'AHmUCY1Z0O7I_EjyJaNEaSNl4JeNTNP8ifJvhYTEmyUVG2c6gy65dLfIrz4tQQOgqWmiRohayELXHu81Cg', 'Date': 'Thu, 07 Nov 2024 13:43:15 GMT', 'Expires': 'Thu, 07 Nov 2024 13:43:15 GMT', 'Cache-Control': 'private, max-age=0', 'X-Goog-Hash': 'crc32c=zBb6Qg==', 'Server': 'UploadServer'}\n",
            "Content-Type: application/octet-stream\n",
            "Date: Thu, 07 Nov 2024 13:43:15 GMT\n",
            "File downloaded and saved as 'google_drive_downloaded.pdf'\n",
            "Extracted Text (Preview): rt \n",
            "Collector \n",
            "personality \n",
            "types\n",
            "\n",
            "\f\f\f1\n",
            "\n",
            "The Novice Collector: These are individuals just starting in the art collection \n",
            "world. They are eager, curious, and often rely on others' opinions or visible \n",
            "\n",
            "trends. For artists, understanding their tastes and guiding them can lead to \n",
            "\n",
            "a long-term patron relationship. Their inexperience can be an advantage \n",
            "\n",
            "because they might be more open to various art styles.\n",
            "\n",
            "a. Offer educational content about art, perhaps \n",
            "through workshops. Assist them in unders\n",
            "Metadata: {'CreationDate': \"D:20240802193007+05'30'\", 'Creator': 'Adobe InDesign 16.0 (Windows)', 'ModDate': \"D:20240802193011+05'30'\", 'Producer': 'Adobe PDF Library 15.0', 'Trapped': 'False', 'rdf': {}, 'xap': {'CreateDate': '2024-08-02T19:30:07+05:30', 'MetadataDate': '2024-08-02T19:30:11+05:30', 'ModifyDate': '2024-08-02T19:30:11+05:30', 'CreatorTool': 'Adobe InDesign 16.0 (Windows)'}, 'xapmm': {'InstanceID': 'uuid:08e1c542-8eaa-4ef4-818a-92cb88d86b36', 'OriginalDocumentID': 'xmp.did:836604c7-e895-204f-a543-04eee051f0f9', 'DocumentID': 'xmp.id:eef52a14-93a6-8948-a7dc-35dd0afea6cf', 'RenditionClass': 'proof:pdf'}, 'http://ns.adobe.com/xap/1.0/sType/ResourceEvent#': {'action': 'converted', 'parameters': 'from application/x-indesign to application/pdf', 'softwareAgent': 'Adobe InDesign 16.0 (Windows)', 'changed': '/', 'when': '2024-08-02T19:30:07+05:30'}, 'http://ns.adobe.com/xap/1.0/sType/ResourceRef#': {'instanceID': 'xmp.iid:6e5d11a0-15bf-d848-872d-089c3b27301b', 'documentID': 'xmp.did:836604c7-e895-204f-a543-04eee051f0f9', 'originalDocumentID': 'xmp.did:836604c7-e895-204f-a543-04eee051f0f9', 'renditionClass': 'default'}, 'dc': {'format': 'application/pdf'}, 'pdf': {'Producer': 'Adobe PDF Library 15.0', 'Trapped': 'False'}, 'Pages': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What is a Binary File?\n",
        "\n",
        "When we say that a **PDF** is a **binary file**, we are referring to the way the data in the file is stored on disk—not necessarily the kind of content it contains (text, images, etc.). Binary files are stored as sequences of bytes (0s and 1s) that can include a wide range of data types, such as text, images, metadata, and instructions for displaying the content in a particular layout. PDFs are considered **binary** because they contain much more than just plain text.\n",
        "\n",
        "Here’s a breakdown:\n",
        "\n",
        "### 1. **Binary vs. Text Files**\n",
        "- **Text files**: These contain plain, human-readable text and are stored as a sequence of characters (letters, numbers, symbols). Examples are `.txt` files or simple `.csv` files. They can be opened and read with a standard text editor (like Notepad or a code editor), and the content makes sense without any special decoding.\n",
        "  \n",
        "- **Binary files**: These are stored as raw byte data and may contain encoded text, images, font data, metadata, formatting instructions, and even compressed or encrypted data. They often require special software to interpret and render their content correctly. Examples include images (`.jpg`, `.png`), executable files (`.exe`), and complex document formats like PDFs (`.pdf`).\n",
        "\n",
        "### 2. **Why PDF is a Binary File**\n",
        "A PDF file is not just plain text; it includes a combination of:\n",
        "- **Text content**: The actual words in the document, often compressed or encoded.\n",
        "- **Images**: PDFs often contain embedded images, which are binary data.\n",
        "- **Fonts**: PDFs include font information so that the document can be displayed consistently across devices.\n",
        "- **Formatting**: Instructions for how to layout the text, images, and other elements on the page.\n",
        "- **Metadata**: Information about the document itself, like the author, title, creation date, etc.\n",
        "- **Interactive elements**: Things like forms, buttons, and links can be embedded within a PDF.\n",
        "\n",
        "All of this data is stored in binary format so that specialized PDF readers (such as Adobe Acrobat or your browser’s built-in PDF viewer) can interpret and render the content appropriately. If you were to open a PDF file in a plain text editor, you would mostly see unreadable characters, because it includes encoded and compressed data that only specialized software can interpret.\n",
        "\n",
        "### 3. **Why It’s Important to Handle PDFs as Binary Files**\n",
        "When you download or save a PDF (or any other binary file), it’s essential to use **binary mode** (`'wb'` for writing, `'rb'` for reading) to ensure that Python treats the file’s contents as raw bytes. If you handle it in text mode (e.g., `'w'` or `'r'`), Python will try to interpret the bytes as plain text, which could corrupt the file because the binary data might not map cleanly to characters.\n",
        "\n",
        "#### Example:\n",
        "- If you open a PDF in a text editor, it might look like this:\n",
        "  ```\n",
        "  %PDF-1.4\n",
        "  %âãÏÓ\n",
        "  1 0 obj\n",
        "  <<\n",
        "  /Type /Catalog\n",
        "  /Pages 2 0 R\n",
        "  >>\n",
        "  endobj\n",
        "  ...\n",
        "  ```\n",
        "  This is a mixture of human-readable parts (`/Type /Catalog`, etc.) and non-readable byte sequences (`%âãÏÓ`). The unreadable parts are binary data encoded in a way that is not meant for plain text interpretation.\n",
        "\n",
        "### 4. **PDF Structure**\n",
        "A PDF has a well-defined structure that includes:\n",
        "- **Header**: Contains the PDF version number.\n",
        "- **Body**: Contains objects such as text streams, images, and font descriptions.\n",
        "- **Cross-reference table**: Points to the locations of the objects within the file.\n",
        "- **Trailer**: Helps the PDF reader locate the cross-reference table.\n",
        "\n",
        "This complex structure is what allows PDFs to include rich content like images, vector graphics, hyperlinks, and embedded fonts.\n",
        "\n",
        "### Example: Why Binary Mode is Required\n",
        "When you download and save a PDF using Python’s `requests` library, it is fetching the **binary content** of the file from the web server. If you saved this in **text mode**, Python might alter some of the raw byte data (e.g., by interpreting line endings differently), which could corrupt the PDF file. Using `'wb'` ensures that Python writes the file exactly as it was downloaded, byte-for-byte, without modification.\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "# Download the PDF file\n",
        "url = 'https://example.com/somefile.pdf'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Save it as a binary file (to prevent corruption)\n",
        "with open('downloaded_file.pdf', 'wb') as f:\n",
        "    f.write(response.content)\n",
        "```\n",
        "\n",
        "### Summary\n",
        "- A **PDF is a binary file** because it contains not just text but also binary-encoded elements like images, fonts, and formatting information.\n",
        "- When downloading or saving binary files (including PDFs), you need to use `'wb'` mode to handle the raw byte data correctly.\n",
        "- PDFs require special software to render because they contain complex structures and embedded data that go beyond simple text.\n",
        "\n"
      ],
      "metadata": {
        "id": "yXffRCEFdH4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF Summarizer"
      ],
      "metadata": {
        "id": "ZQqMRzDU0Yw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Libraries"
      ],
      "metadata": {
        "id": "hmrfpfzM4NFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain\n",
        "# !pip install openai\n",
        "# !pip install tiktoken\n",
        "# !pip install unstructured\n",
        "# !pip install chromadb\n",
        "# !pip install Cython\n",
        "# !pip install pypdf\n",
        "# !pip install gensim\n",
        "# !pip install transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Mq4eFP3bkKUG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dependency Conflicts\n",
        "\n",
        "To avoid dependency conflicts when installing libraries initially, you can specify compatible versions of libraries that are known to work well together. Here’s a modified setup code snippet that includes compatible versions for `transformers` and `protobuf` along with your other libraries.\n",
        "\n",
        "```python\n",
        "# Install necessary libraries with compatible versions\n",
        "!pip install langchain==0.0.134\n",
        "!pip install openai==0.10.2\n",
        "!pip install tiktoken==0.2.0\n",
        "!pip install unstructured==0.2.4\n",
        "!pip install chromadb==0.3.23\n",
        "!pip install Cython==0.29.32\n",
        "!pip install pypdf==3.8.1\n",
        "!pip install gensim==4.2.0\n",
        "!pip install transformers==4.30.0  # Specify compatible version of transformers\n",
        "!pip install protobuf==3.20.3       # Specify compatible version of protobuf\n",
        "```\n",
        "\n",
        "### Explanation\n",
        "\n",
        "- **`transformers==4.30.0`**: This version is known to work with `protobuf==3.20.3`.\n",
        "- **`protobuf==3.20.3`**: This version is compatible with `transformers` and avoids the common compatibility issues with newer versions.\n",
        "\n",
        "### Alternative Solution: Using a `requirements.txt` File\n",
        "\n",
        "If you’re working in an environment that supports `requirements.txt` (like a virtual environment or Docker container), you can create a `requirements.txt` file with specific versions of your libraries and install everything with one command. Here’s how you’d set up `requirements.txt`:\n",
        "\n",
        "```\n",
        "langchain==0.0.134\n",
        "openai==0.10.2\n",
        "tiktoken==0.2.0\n",
        "unstructured==0.2.4\n",
        "chromadb==0.3.23\n",
        "Cython==0.29.32\n",
        "pypdf==3.8.1\n",
        "gensim==4.2.0\n",
        "transformers==4.30.0\n",
        "protobuf==3.20.3\n",
        "```\n",
        "\n",
        "Then, run:\n",
        "\n",
        "```python\n",
        "!pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "By specifying compatible versions from the beginning, you reduce the risk of dependency conflicts when using the `transformers` library. Let me know if this helps streamline your setup!"
      ],
      "metadata": {
        "id": "7bA9X7yO5g0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade protobuf\n",
        "# !pip install --upgrade transformers\n"
      ],
      "metadata": {
        "id": "ukMCt2Hh5JhK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HugginFace Summarizer Model"
      ],
      "metadata": {
        "id": "miFr3v_G4m_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import pipeline  # Hugging Face transformers\n",
        "import PyPDF2  # For reading PDF files\n",
        "\n",
        "# Verify the setup by loading the summarization pipeline\n",
        "try:\n",
        "    summarizer = pipeline(\"summarization\", model='sshleifer/distilbart-cnn-12-6')\n",
        "    print(\"Summarization pipeline loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"An error occurred while loading the summarization pipeline:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "d3fd533c8de24d9f83a349cab733617f",
            "926fd48d700541b2975ebdf4af23199c",
            "001d9b100d8846a89bfae26f66d33c75",
            "dac89dbd3f084885897c3e768c0bb28b",
            "134fbcf84a544140a893ebbfc17f4b9d",
            "25fbfbbe34b94c639caa50d42420ca16",
            "008231acf2784f4e86267537f1b7c995",
            "aefa69de00084a909aad873653c0ff4e",
            "8d527da7b93c4ac3ab9ef6b49482a1e6",
            "70eec555ca20479cb240952a08cc4287",
            "167c57e4c45647efaca344a702f46631",
            "3227abd82da74353b3923c9cd3236645",
            "a950e22fabcc46fb914f542576e23fd7",
            "4ef24ac80b344927a6e765400c94afaa",
            "23639c3514ac4d5a822916fc915bc262",
            "7a13062d0c40433384ff9fba69947af0",
            "f4d54ded4204439bb1a57f40d64c7753",
            "40441cdd89ea4d4ebdaf91ae92298de0",
            "f28955f664d14b818e91bb7272de3998",
            "aad68ec3d0b24537925d59c2b62eaafd",
            "bb419b1ecac945c791830a691e1f6f28",
            "eba0e4c00a7a4822bd733bece9c81f13",
            "dd23a1f498994b5c93d26708bad0d29d",
            "23dc52d699004000a1fa4efcd0878628",
            "8d8c23a42dda4e878470d9388b5b0bb7",
            "7222d046ecdf41be946971a888f91688",
            "105f1f19b82b4e9a9885d0efab6dbfd9",
            "fd8ad612f4eb4a1bbf22d993a1e1ae12",
            "f52ed950934e4e98b87a0876cb1d308d",
            "a0aa97e1757a4426b3a2404e98d3755e",
            "1ce27bf1ddb14d6e8652ca5cf998d005",
            "c15673a075414089b544c0fafd11dad5",
            "c498d48e10af4513a4660f0781517ce4",
            "236a8e7a584b48a68c1310fd8814ecce",
            "b17467e7f51c43029a192b7e8399fe0c",
            "1996c48c7d7e43f2a1e9f07572403ddc",
            "1c7e3cee7dd542d38ce934959801cdef",
            "564c73a411bc4d9f9237d2a0e44638e5",
            "d719d7a632ee4c2ca7f4f5f06fb9dda0",
            "18e5e631d8674085be315734d4f972bc",
            "b75ffff66ce54d1c97d890d7ef61f34e",
            "8762614919d94ce1820f4fccfbc1a3e5",
            "9d8d9cf7712a4eb3bd42b5cddc8786d0",
            "35c3a4fe4cc746ab9b695d5f421b22a8",
            "2e843be174d74d4eb4933b97ac817c7a",
            "2078a4b46de2475abdc2d3d7e08a1bfe",
            "a2869d41133d44ce8c861f8e3800e2d7",
            "fc599ff8b6b1453d9fdad3af7082de08",
            "38269e793aeb404ab7f15f615b41868c",
            "bbfa3d4144d64d05906a986bab820873",
            "044af525d23c498986b3ea7d11bf13cc",
            "5fbc349ca67242f5a7d4823117a9f3d3",
            "b2d531cd4e3346a4b9f8f8ce028de9fd",
            "fc3a8bb28df14623896d7df19ab52d0d",
            "c6082cb049384908a7df3861778a63b8"
          ]
        },
        "id": "so7GabP76JlO",
        "outputId": "8be26003-efe4-407d-d49c-b34277723168"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3fd533c8de24d9f83a349cab733617f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3227abd82da74353b3923c9cd3236645"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd23a1f498994b5c93d26708bad0d29d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "236a8e7a584b48a68c1310fd8814ecce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e843be174d74d4eb4933b97ac817c7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization pipeline loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Configuration\n",
        "\n",
        "This section defines the architecture, settings, and behavior of the DistilBART model used for summarization. Here’s a brief summary of the main types of information:\n",
        "\n",
        "1. **Model Identity and Purpose**:\n",
        "   - **Name and Path** (`_name_or_path`): Identifies the specific pretrained model.\n",
        "   - **Model Type** (`model_type`): Specifies the underlying model architecture (e.g., \"bart\").\n",
        "   - **Task Parameters** (`task_specific_params`): Fine-tuned parameters for summarization, like maximum summary length and repetition control.\n",
        "\n",
        "2. **Architecture Details**:\n",
        "   - **Encoder and Decoder Layers** (`encoder_layers`, `decoder_layers`): Defines the number of layers in both the encoder and decoder parts of the model.\n",
        "   - **Attention Heads** (`encoder_attention_heads`, `decoder_attention_heads`): Controls the number of attention heads, which help the model focus on different parts of the text.\n",
        "   - **Feed-Forward Dimensions** (`encoder_ffn_dim`, `decoder_ffn_dim`): Defines the size of the intermediate layers in each encoder and decoder layer.\n",
        "\n",
        "3. **Tokenization and Special Tokens**:\n",
        "   - **Token IDs** (`bos_token_id`, `eos_token_id`, `pad_token_id`): Special token IDs for marking the beginning and end of sentences and padding sequences.\n",
        "   - **Maximum Position Embeddings** (`max_position_embeddings`): Sets the maximum number of tokens in each input, limiting text length.\n",
        "\n",
        "4. **Regularization and Dropout**:\n",
        "   - **Dropouts** (`dropout`, `attention_dropout`, etc.): Controls dropout rates, adding randomness to reduce overfitting and improve generalization.\n",
        "   - **Length Penalty** (`length_penalty`): Adjusts the length of generated summaries.\n",
        "\n",
        "5. **Summarization-Specific Parameters**:\n",
        "   - **Beams and Repetition Control** (`num_beams`, `no_repeat_ngram_size`): Configures the beam search and prevents repeated phrases.\n",
        "   - **Min and Max Length** (`min_length`, `max_length`): Defines the minimum and maximum summary lengths.\n",
        "\n",
        "In essence, these settings control how the model generates summaries by defining the model’s structure, managing text handling, and fine-tuning output quality. This combination allows for effective summarization tailored to common summary requirements.\n",
        "\n",
        "### Neural Network with Multiple Layers\n",
        "\n",
        "The DistilBART model you’re working with is a **neural network with multiple layers**, specifically an encoder-decoder architecture based on the Transformer model. Here’s a high-level breakdown:\n",
        "\n",
        "1. **Encoder-Decoder Structure**:\n",
        "   - Like other Transformer models, DistilBART has both an **encoder** (to understand the input text) and a **decoder** (to generate the summarized text).\n",
        "   - The **encoder layers** process the input text, capturing its meaning in a series of internal representations.\n",
        "   - The **decoder layers** then take those representations and generate a condensed, coherent summary.\n",
        "\n",
        "2. **Layers and Attention**:\n",
        "   - DistilBART has **stacked layers** in both the encoder and decoder, which are repeated processing units in the neural network. Each layer refines the information it receives, allowing the model to capture complex relationships in the text.\n",
        "   - Each layer includes **attention heads**, which help the model focus on relevant words and phrases within the input sequence, improving understanding of context and relationships.\n",
        "\n",
        "3. **Parameter Configurations**:\n",
        "   - The configuration you saw (e.g., number of layers, attention heads, dropout rates) defines the neural network's depth, capacity, and regularization strategies. These parameters enable the model to effectively perform tasks like summarization by learning patterns in large text datasets.\n",
        "\n",
        "In summary, DistilBART is a neural network specifically designed to process and generate natural language text through a series of structured, layered transformations. It’s a “lighter” (distilled) version of the original BART model but still retains strong performance, making it efficient for tasks like summarization while keeping computational demands lower."
      ],
      "metadata": {
        "id": "lVj_eJsw7Xap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the summarizer object itself\n",
        "print(\"Summarizer Object:\\n\", summarizer)\n",
        "\n",
        "# Model configuration details\n",
        "print(\"\\nModel Configuration:\\n\", summarizer.model.config)\n",
        "\n",
        "# Tokenizer details\n",
        "print(\"\\nTokenizer Details:\\n\", summarizer.tokenizer)\n",
        "\n",
        "# Help on the summarizer function to see available parameters\n",
        "print(\"\\nSummarizer Parameters:\\n\")\n",
        "help(summarizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z0wAR2j0Rsi",
        "outputId": "1ff7b1d2-94e6-4990-863e-9deadbef97b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarizer Object:\n",
            " <transformers.pipelines.text2text_generation.SummarizationPipeline object at 0x7d125fc656c0>\n",
            "\n",
            "Model Configuration:\n",
            " BartConfig {\n",
            "  \"_attn_implementation_autoset\": true,\n",
            "  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": true,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 142,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 56,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"replacing_rate\": 0,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"student_decoder_layers\": null,\n",
            "  \"student_encoder_layers\": null,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.46.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "\n",
            "Tokenizer Details:\n",
            " BartTokenizerFast(name_or_path='sshleifer/distilbart-cnn-12-6', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
            "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
            "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
            "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
            "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
            "}\n",
            "\n",
            "Summarizer Parameters:\n",
            "\n",
            "Help on SummarizationPipeline in module transformers.pipelines.text2text_generation object:\n",
            "\n",
            "class SummarizationPipeline(Text2TextGenerationPipeline)\n",
            " |  SummarizationPipeline(*args, **kwargs)\n",
            " |  \n",
            " |  Summarize news articles and other documents.\n",
            " |  \n",
            " |  This summarizing pipeline can currently be loaded from [`pipeline`] using the following task identifier:\n",
            " |  `\"summarization\"`.\n",
            " |  \n",
            " |  The models that this pipeline can use are models that have been fine-tuned on a summarization task, which is\n",
            " |  currently, '*bart-large-cnn*', '*google-t5/t5-small*', '*google-t5/t5-base*', '*google-t5/t5-large*', '*google-t5/t5-3b*', '*google-t5/t5-11b*'. See the up-to-date\n",
            " |  list of available models on [huggingface.co/models](https://huggingface.co/models?filter=summarization). For a list\n",
            " |  of available parameters, see the [following\n",
            " |  documentation](https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.generation.GenerationMixin.generate)\n",
            " |  \n",
            " |  Usage:\n",
            " |  \n",
            " |  ```python\n",
            " |  # use bart in pytorch\n",
            " |  summarizer = pipeline(\"summarization\")\n",
            " |  summarizer(\"An apple a day, keeps the doctor away\", min_length=5, max_length=20)\n",
            " |  \n",
            " |  # use t5 in tf\n",
            " |  summarizer = pipeline(\"summarization\", model=\"google-t5/t5-base\", tokenizer=\"google-t5/t5-base\", framework=\"tf\")\n",
            " |  summarizer(\"An apple a day, keeps the doctor away\", min_length=5, max_length=20)\n",
            " |  ```\n",
            " |  Arguments:\n",
            " |      model ([`PreTrainedModel`] or [`TFPreTrainedModel`]):\n",
            " |          The model that will be used by the pipeline to make predictions. This needs to be a model inheriting from\n",
            " |          [`PreTrainedModel`] for PyTorch and [`TFPreTrainedModel`] for TensorFlow.\n",
            " |      tokenizer ([`PreTrainedTokenizer`]):\n",
            " |          The tokenizer that will be used by the pipeline to encode data for the model. This object inherits from\n",
            " |          [`PreTrainedTokenizer`].\n",
            " |      modelcard (`str` or [`ModelCard`], *optional*):\n",
            " |          Model card attributed to the model for this pipeline.\n",
            " |      framework (`str`, *optional*):\n",
            " |          The framework to use, either `\"pt\"` for PyTorch or `\"tf\"` for TensorFlow. The specified framework must be\n",
            " |          installed.\n",
            " |  \n",
            " |          If no framework is specified, will default to the one currently installed. If no framework is specified and\n",
            " |          both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is\n",
            " |          provided.\n",
            " |      task (`str`, defaults to `\"\"`):\n",
            " |          A task-identifier for the pipeline.\n",
            " |      num_workers (`int`, *optional*, defaults to 8):\n",
            " |          When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number of\n",
            " |          workers to be used.\n",
            " |      batch_size (`int`, *optional*, defaults to 1):\n",
            " |          When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of\n",
            " |          the batch to use, for inference this is not always beneficial, please read [Batching with\n",
            " |          pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching) .\n",
            " |      args_parser ([`~pipelines.ArgumentHandler`], *optional*):\n",
            " |          Reference to the object in charge of parsing supplied pipeline parameters.\n",
            " |      device (`int`, *optional*, defaults to -1):\n",
            " |          Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, a positive will run the model on\n",
            " |          the associated CUDA device id. You can pass native `torch.device` or a `str` too\n",
            " |      torch_dtype (`str` or `torch.dtype`, *optional*):\n",
            " |          Sent directly as `model_kwargs` (just a simpler shortcut) to use the available precision for this model\n",
            " |          (`torch.float16`, `torch.bfloat16`, ... or `\"auto\"`)\n",
            " |      binary_output (`bool`, *optional*, defaults to `False`):\n",
            " |          Flag indicating if the output the pipeline should happen in a serialized format (i.e., pickle) or as\n",
            " |          the raw output data e.g. text.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      SummarizationPipeline\n",
            " |      Text2TextGenerationPipeline\n",
            " |      transformers.pipelines.base.Pipeline\n",
            " |      transformers.pipelines.base._ScikitCompat\n",
            " |      abc.ABC\n",
            " |      transformers.utils.hub.PushToHubMixin\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |      Summarize the text(s) given as inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |          documents (*str* or `List[str]`):\n",
            " |              One or several articles (or one list of articles) to summarize.\n",
            " |          return_text (`bool`, *optional*, defaults to `True`):\n",
            " |              Whether or not to include the decoded texts in the outputs\n",
            " |          return_tensors (`bool`, *optional*, defaults to `False`):\n",
            " |              Whether or not to include the tensors of predictions (as token indices) in the outputs.\n",
            " |          clean_up_tokenization_spaces (`bool`, *optional*, defaults to `False`):\n",
            " |              Whether or not to clean up the potential extra spaces in the text output.\n",
            " |          generate_kwargs:\n",
            " |              Additional keyword arguments to pass along to the generate method of the model (see the generate method\n",
            " |              corresponding to your framework [here](./text_generation)).\n",
            " |      \n",
            " |      Return:\n",
            " |          A list or a list of list of `dict`: Each result comes as a dictionary with the following keys:\n",
            " |      \n",
            " |          - **summary_text** (`str`, present when `return_text=True`) -- The summary of the corresponding input.\n",
            " |          - **summary_token_ids** (`torch.Tensor` or `tf.Tensor`, present when `return_tensors=True`) -- The token\n",
            " |            ids of the summary.\n",
            " |  \n",
            " |  check_inputs(self, input_length: int, min_length: int, max_length: int) -> bool\n",
            " |      Checks whether there might be something wrong with given input with regard to the model.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  return_name = 'summary'\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from Text2TextGenerationPipeline:\n",
            " |  \n",
            " |  __init__(self, *args, **kwargs)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  postprocess(self, model_outputs, return_type=<ReturnType.TEXT: 1>, clean_up_tokenization_spaces=False)\n",
            " |      Postprocess will receive the raw outputs of the `_forward` method, generally tensors, and reformat them into\n",
            " |      something more friendly. Generally it will output a list or a dict or results (containing just strings and\n",
            " |      numbers).\n",
            " |  \n",
            " |  preprocess(self, inputs, truncation=<TruncationStrategy.DO_NOT_TRUNCATE: 'do_not_truncate'>, **kwargs)\n",
            " |      Preprocess will take the `input_` of a specific pipeline and return a dictionary of everything necessary for\n",
            " |      `_forward` to run properly. It should contain at least one tensor, but might have arbitrary other items.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from transformers.pipelines.base.Pipeline:\n",
            " |  \n",
            " |  check_model_type(self, supported_models: Union[List[str], dict])\n",
            " |      Check if the model class is in supported by the pipeline.\n",
            " |      \n",
            " |      Args:\n",
            " |          supported_models (`List[str]` or `dict`):\n",
            " |              The list of models supported by the pipeline, or a dictionary with model class values.\n",
            " |  \n",
            " |  device_placement(self)\n",
            " |      Context Manager allowing tensor allocation on the user-specified device in framework agnostic way.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Context manager\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      ```python\n",
            " |      # Explicitly ask for tensor allocation on CUDA device :0\n",
            " |      pipe = pipeline(..., device=0)\n",
            " |      with pipe.device_placement():\n",
            " |          # Every framework specific tensor allocation will be done on the request device\n",
            " |          output = pipe(...)\n",
            " |      ```\n",
            " |  \n",
            " |  ensure_tensor_on_device(self, **inputs)\n",
            " |      Ensure PyTorch tensors are on the specified device.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs (keyword arguments that should be `torch.Tensor`, the rest is ignored):\n",
            " |              The tensors to place on `self.device`.\n",
            " |          Recursive on lists **only**.\n",
            " |      \n",
            " |      Return:\n",
            " |          `Dict[str, torch.Tensor]`: The same as `inputs` but on the proper device.\n",
            " |  \n",
            " |  forward(self, model_inputs, **forward_params)\n",
            " |  \n",
            " |  get_inference_context(self)\n",
            " |  \n",
            " |  get_iterator(self, inputs, num_workers: int, batch_size: int, preprocess_params, forward_params, postprocess_params)\n",
            " |  \n",
            " |  iterate(self, inputs, preprocess_params, forward_params, postprocess_params)\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n",
            " |  \n",
            " |  push_to_hub(self, repo_id: str, use_temp_dir: Optional[bool] = None, commit_message: Optional[str] = None, private: Optional[bool] = None, token: Union[bool, str, NoneType] = None, max_shard_size: Union[int, str, NoneType] = '5GB', create_pr: bool = False, safe_serialization: bool = True, revision: str = None, commit_description: str = None, tags: Optional[List[str]] = None, **deprecated_kwargs) -> str\n",
            " |      Upload the pipeline file to the 🤗 Model Hub.\n",
            " |      \n",
            " |      Parameters:\n",
            " |          repo_id (`str`):\n",
            " |              The name of the repository you want to push your pipe to. It should contain your organization name\n",
            " |              when pushing to a given organization.\n",
            " |          use_temp_dir (`bool`, *optional*):\n",
            " |              Whether or not to use a temporary directory to store the files saved before they are pushed to the Hub.\n",
            " |              Will default to `True` if there is no directory named like `repo_id`, `False` otherwise.\n",
            " |          commit_message (`str`, *optional*):\n",
            " |              Message to commit while pushing. Will default to `\"Upload pipe\"`.\n",
            " |          private (`bool`, *optional*):\n",
            " |              Whether or not the repository created should be private.\n",
            " |          token (`bool` or `str`, *optional*):\n",
            " |              The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n",
            " |              when running `huggingface-cli login` (stored in `~/.huggingface`). Will default to `True` if `repo_url`\n",
            " |              is not specified.\n",
            " |          max_shard_size (`int` or `str`, *optional*, defaults to `\"5GB\"`):\n",
            " |              Only applicable for models. The maximum size for a checkpoint before being sharded. Checkpoints shard\n",
            " |              will then be each of size lower than this size. If expressed as a string, needs to be digits followed\n",
            " |              by a unit (like `\"5MB\"`). We default it to `\"5GB\"` so that users can easily load models on free-tier\n",
            " |              Google Colab instances without any CPU OOM issues.\n",
            " |          create_pr (`bool`, *optional*, defaults to `False`):\n",
            " |              Whether or not to create a PR with the uploaded files or directly commit.\n",
            " |          safe_serialization (`bool`, *optional*, defaults to `True`):\n",
            " |              Whether or not to convert the model weights in safetensors format for safer serialization.\n",
            " |          revision (`str`, *optional*):\n",
            " |              Branch to push the uploaded files to.\n",
            " |          commit_description (`str`, *optional*):\n",
            " |              The description of the commit that will be created\n",
            " |          tags (`List[str]`, *optional*):\n",
            " |              List of tags to push on the Hub.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      ```python\n",
            " |      from transformers import pipeline\n",
            " |      \n",
            " |      pipe = pipeline(\"google-bert/bert-base-cased\")\n",
            " |      \n",
            " |      # Push the pipe to your namespace with the name \"my-finetuned-bert\".\n",
            " |      pipe.push_to_hub(\"my-finetuned-bert\")\n",
            " |      \n",
            " |      # Push the pipe to an organization with the name \"my-finetuned-bert\".\n",
            " |      pipe.push_to_hub(\"huggingface/my-finetuned-bert\")\n",
            " |      ```\n",
            " |  \n",
            " |  run_multi(self, inputs, preprocess_params, forward_params, postprocess_params)\n",
            " |  \n",
            " |  run_single(self, inputs, preprocess_params, forward_params, postprocess_params)\n",
            " |  \n",
            " |  save_pretrained(self, save_directory: Union[str, os.PathLike], safe_serialization: bool = True, **kwargs)\n",
            " |      Save the pipeline's model and tokenizer.\n",
            " |      \n",
            " |      Args:\n",
            " |          save_directory (`str` or `os.PathLike`):\n",
            " |              A path to the directory where to saved. It will be created if it doesn't exist.\n",
            " |          safe_serialization (`str`):\n",
            " |              Whether to save the model using `safetensors` or the traditional way for PyTorch or Tensorflow.\n",
            " |          kwargs (`Dict[str, Any]`, *optional*):\n",
            " |              Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from transformers.pipelines.base.Pipeline:\n",
            " |  \n",
            " |  torch_dtype\n",
            " |      Torch dtype of the model (if it's Pytorch model), `None` otherwise.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from transformers.pipelines.base.Pipeline:\n",
            " |  \n",
            " |  default_input_names = None\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from transformers.pipelines.base._ScikitCompat:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarize PDF\n",
        "\n",
        "1. **Combine Text Extraction and Chunking**:\n",
        "   Instead of building `pdf_text` first and then chunking it, you can append each page's text directly into chunks as you go. This approach reduces memory usage for large PDFs.\n",
        "\n",
        "2. **Chunk Size and Overlap**:\n",
        "   Sometimes splitting text exactly at `chunk_size` can cut sentences in half, affecting summary quality. Adding a slight overlap between chunks helps retain context across chunks.\n",
        "\n",
        "3. **Batch Summarization**:\n",
        "   Instead of calling `summarizer` individually for each chunk, you can pass all chunks in a single call. Hugging Face `pipeline` can handle batches, which may be faster.\n",
        "\n"
      ],
      "metadata": {
        "id": "4fWn5X_L3lOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize summarizer\n",
        "summarizer = pipeline(\"summarization\", model='sshleifer/distilbart-cnn-12-6')\n",
        "\n",
        "# Load PDF\n",
        "pdf_path = '/content/Art Collector personality types_ finish.pdf'\n",
        "chunks = []\n",
        "chunk_size = 1000  # Define the chunk size\n",
        "overlap = 100      # Define overlap between chunks for better context\n",
        "\n",
        "with open(pdf_path, 'rb') as file:\n",
        "    pdf_reader = PyPDF2.PdfReader(file)\n",
        "    pdf_text = \"\"\n",
        "\n",
        "    # Process each page and split into chunks directly\n",
        "    for page in pdf_reader.pages:\n",
        "        pdf_text += page.extract_text()\n",
        "\n",
        "    # Create chunks with overlap\n",
        "    for i in range(0, len(pdf_text), chunk_size - overlap):\n",
        "        chunk = pdf_text[i:i + chunk_size]\n",
        "        chunks.append(chunk)\n",
        "\n",
        "# Generate summaries for each chunk\n",
        "for i, chunk in enumerate(chunks):\n",
        "    summary = summarizer(chunk, max_length=150, min_length=50, do_sample=False)\n",
        "    print(f\"Summary of Chunk {i + 1}:\", summary[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFWL0K2o8rUy",
        "outputId": "206069e9-fbb7-4403-e2ac-a9b3df268cde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of Chunk 1:  The Niche Enthusiast looks for very specific art forms, be it abstract, surrealism, or any niche genre . The Novice Collector is eager, curious, and often rely on others' opinions or visible  trends . For artists, aligning  with their niche preference is key to gain their attention .\n",
            "Summary of Chunk 2:  The Investment Collector buys artworks they believe will appreciate value . The Speculative Collector takes risks on unknown or lesser-known artists hoping that their value will explode in the future . Artists who’ve received media attention or have a growing  reputation will appeal to this group .\n",
            "Summary of Chunk 3:  The Emotional Buyer buys art that resonates with them on a deep, emotional level . The Trend Follower buys artworks that are trending or popular at the moment . For artists, storytelling and personal connection can be the key to attracting these collectors .\n",
            "Summary of Chunk 4:  The Philanthropic/Patron Collector: They believe in supporting artists . The Social Collector: For them, collecting art is also about socializing . They love to attend gallery openings, art fairs, and enjoy the social status that comes with being an art collector .\n",
            "Summary of Chunk 5:  The Aesthete: For these collectors, it’s all about beauty. They look for artworks that appeal to their sense of aesthetics and beauty. An artist whose work is visually stunning and aligns with their aesthetic taste will be attractive to this type of buyer .\n",
            "Summary of Chunk 6:  The Historical Collector is interested in collecting artworks that have a historical or cultural significance . The Heritage Collector is a subcategory of the historical colleciate collector . For the Historical Collector, contextualizing their art in a broader historical  narrative can appeal to these collectors .\n",
            "Summary of Chunk 7:  Thematic Collector: These collectors are driven by specific themes, such as love, nature, war, or other motifs . Artists who create works that tap into these themes might resonate deeply with these collectors . The Global Collector: Open to various cultures and styles, they look for artworks from different parts of the world .\n",
            "Summary of Chunk 8:  Artists who create art around distinct themes might resonate deeply with collectors . Artists who specialize in a specific medium can target these collectors effectively . Organize exhibitions or series based on popular themes that resonate with these collectors . Host or participate in medium-specific exhibitions or workshops .\n",
            "Summary of Chunk 9:  Emerging artists might find it challenging to break into their radar, but those with a reputation or accolades can find favor . Engage in high-profile art events or collaborate with influencers on social media . Aim for recognition in prestigious art awards or affiliations with renowned art institutions .\n",
            "Summary of Chunk 10:  A modern collector is intrigued by art that incorporates or is centered around technology, such as digital art, VR art, or AI-generated art . Artists who blend tech into their creations can appeal to this forward-thinking group . With the rise of NFTs, this collector is focused solely on digital artworks .\n",
            "Summary of Chunk 11:  The Pop-Culture Enthusiast is drawn to art that references or is inspired by popular culture, movies, music, or current events . The Eco-Focused Collector is passionate about sustainability and sustainability . Artists with a green approach can find patrons here .\n",
            "Summary of Chunk 12:  The Experimental Collector is always on the lookout for unique, unique, or experimental art . Artists can connect with collectors by participating in local events or highlighting local themes . The Design-Driven Collecto focuses on supporting and buying art from local artists or their community .\n",
            "Summary of Chunk 13:  Artists whose work aligns  with popular interior design trends or timeless styles can capture this audience . Businesses buy art to complement specific design aesthetics or to make a statement in a living space . Artists who can create large-scale works or pieces that resonate  with corporate values can find opportunities .\n",
            "Summary of Chunk 14:  Artists who can personalize works or capture emotions appeal to collectors who buy art to commemorate important milestones in their lives . Artists who create art that aligns with corporate values are often linked to or own galleries . Offer corporate packages or create art for corporate commissions .\n",
            "Summary of Chunk 15:  Artists who can agicallypersonalize works or capture emotions will appeal to collectors . Artists who produce thought-provoking works can find a niche with this group . The Cause-Supporting Collector buys art to support specific causes or charities . The Educator Collector: Buy art to teach, for research, or to promote artistic appreciation among students .\n",
            "Summary of Chunk 16:  Artists who collect art from places they’ve visited can be seen at major art fairs . Artists who have a history of collecting art can be found at major events . They can also be found in museums and galleries across the globe . They are often used to collect art and sell it at major venues .\n",
            "Summary of Chunk 17:  The Bargain Hunter is always on the lookout for undervalued pieces, estate sales, or artists who haven’t ‘discovered’ yet . They pride themselves on getting art at a lower price point and potentially finding hidden gems .\n",
            "Summary of Chunk 18:  The art becomes a representation of their ability to find undervalued things . Research historic art trends and create complementary pieces that align with such traditions . Offer occasional discounts, bundle deals, or spotlight emerging talents with affordable  affordable art .\n",
            "Summary of Chunk 19:  The Artist Formula explains how I use this to make an offer  that is irresistible to collectors . Aim to  have your works featured in avant-garde galleries or spaces  known for cutting-edge contemporary art . Join panels, symposiums, or talks focusing on the future of art .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjust Summary Length\n",
        "\n",
        "Setting `max_length=50` and `min_length=10` should work for producing shorter summaries. These parameters tell the summarizer to aim for a summary with a length between 10 and 50 tokens (words or subwords, depending on the tokenizer). Just keep in mind:\n",
        "\n",
        "1. **Context Loss**: With shorter summaries, there’s a chance of losing important context, especially if the chunked text is lengthy. You might need to adjust the `chunk_size` to balance this, ensuring each chunk contains focused information.\n",
        "\n",
        "2. **Model Constraints**: If the summarizer doesn’t have enough content to summarize within the set length constraints, it may produce summaries that don’t fully reflect the intended range. Adjust `max_length` and `min_length` based on the content complexity.\n",
        "\n",
        "3. **Summarization Quality**: Shorter summaries are more concise but may miss finer details. Experimenting with values (like `min_length=20` and `max_length=70`) can help you find the balance that best captures key points in shorter text.\n",
        "\n",
        "\n",
        "This setup will attempt to generate shorter, more concise summaries for each chunk, fitting the range you've specified. Adjusting `max_length` and `min_length` lets you control the detail level and length of each summary as needed."
      ],
      "metadata": {
        "id": "JDsWToE9_CzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize summarizer\n",
        "summarizer = pipeline(\"summarization\", model='sshleifer/distilbart-cnn-12-6')\n",
        "\n",
        "# Define desired summary length\n",
        "max_length = 50\n",
        "min_length = 20\n",
        "\n",
        "# Load PDF\n",
        "pdf_path = '/content/Art Collector personality types_ finish.pdf'\n",
        "chunks = []\n",
        "chunk_size = 500  # Smaller chunk size for more compact context\n",
        "overlap = 50      # Smaller overlap if chunks are smaller\n",
        "\n",
        "with open(pdf_path, 'rb') as file:\n",
        "    pdf_reader = PyPDF2.PdfReader(file)\n",
        "    pdf_text = \"\"\n",
        "\n",
        "    # Process each page and split into chunks directly\n",
        "    for page in pdf_reader.pages:\n",
        "        pdf_text += page.extract_text()\n",
        "\n",
        "    # Create compact chunks with overlap\n",
        "    for i in range(0, len(pdf_text), chunk_size - overlap):\n",
        "        chunk = pdf_text[i:i + chunk_size]\n",
        "        chunks.append(chunk)\n",
        "\n",
        "# Generate summaries for each chunk with shorter lengths\n",
        "for i, chunk in enumerate(chunks):\n",
        "    summary = summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)\n",
        "    print(f\"Summary of Chunk {i + 1}:\", summary[0]['summary_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EebFuKu-Uf6",
        "outputId": "06838d84-8e81-434d-b7fa-bb3c681af322"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of Chunk 1:  Novice Collector: These are individuals just starting in art collection . Niche Enthusiast: This collector looks for very specific art forms, be it abstract, surrealism, or surrealism .\n",
            "Summary of Chunk 2:  For artists, aligning with their niche preference is key to gain their attention . They’re well-informed about their  purposefully chosen niche and appreciate artists who excel within it .\n",
            "Summary of Chunk 3:  The Investment Collector is driven by the potential return on artworks they believe will appreciate value . Artists who’ve received media attention or have a growing reputation will appeal to this group . The Speculative Collector buys artworks he believes\n",
            "Summary of Chunk 4:  The speculative collector takes risks on unknown or lesser-known artists hoping that their value will explode in the future . Provide data on past art sales, auction results, and press coverage to highlight potential ROI .\n",
            "Summary of Chunk 5:  The Trend Follower: Buy artworks that are trending or popular at the moment . Offer limited editions or exclusive previews to entice them to emerging talents with unique potential .\n",
            "Summary of Chunk 6:  The Emotional Buyer buys art that resonates with them on a deep, emotional level . For artists, storytelling and personal connection can be the key to attracting these collectors . Engage actively on social media platforms and ensure presence in\n",
            "Summary of Chunk 7:  The Social Collector: For them, collecting art is also about socializing . They love to attend gallery openi. ry galleries . Share the personal stories and inspirations behind each artwork .\n",
            "Summary of Chunk 8:  The Philanthropic/Patron Collector: They believe in supporting artists . They often buy from emerging talents, providing them with the necessary financial support . Artists who are socially active and participate in events may draw their attention .\n",
            "Summary of Chunk 9:  Forming a relationship with such a collector can provide a  significant support . Organize or participate in gallery openings, art events, and artist meet-and-greets . These collectors may  provide artists with resources, or commission specific\n",
            "Summary of Chunk 10:  An artist whose work is visually stunning and aligns with the collector’s aesthetic taste will be attractive to collectors . Artists should seek mentorship or sponsorship opportunities with collectors .\n",
            "Summary of Chunk 11:  The Historical Collector is interested in collecting artworks that have a historical or cultural significance . Focus on creating visually appealing exhibitions and providing high-quality visuals of art pieces .\n",
            "Summary of Chunk 12:  Provide detailed descriptions, emphasizing the  historical and cultural significance of the artworks . Talk to people from the academic fields about those historical references and build connections out with them .\n",
            "Summary of Chunk 13:  The Global Collector looks for artworks from different parts of the world . Artists who tap into these narratives can find a dedicated audience here .\n",
            "Summary of Chunk 14:  Artists from diverse backgrounds or those whose work reflects global themes can appeal to this group . Connect with community events or institutions to  highlight works that showcase heritage and culture .\n",
            "Summary of Chunk 15:  Artists who create work around distinct themes might resonate deeply with these collectors . Artists who specialize in a specific medium can target these collectors effectively . Host or participate in medium-specific exhibitions or series based on popular themes .\n",
            "Summary of Chunk 16:  Celebrity Collector: Often high-profile individuals or celebrities buy art as an investment and statement . Prestige Collector: Driven by brand names and established artists, they often aim to buy art from established artists . Become an expert in your\n",
            "Summary of Chunk 17:  Emerging artists might find it difficult to break into established artists' radar . Engage in high-profile art events or collaborate with influencers on social media .\n",
            "Summary of Chunk 18:  Celebrities know that buying from you will strengthen their brand . Aim for recognition in prestigious art awards or affiliations with renowned art institutions . Dedicate a portion of you social media to  showcasing the connections you make and the people\n",
            "Summary of Chunk 19:  This modern collector is intrigued by art that incorporates or is centered around technology . Artists who blend tech into their creations can appeal to this forward-thinking group .\n",
            "Summary of Chunk 20:  Artists who work in the NFT space might find this category relevant . They might be interested in using digital art to create artworks or create digital artworks .\n",
            "Summary of Chunk 21:  The Pop-Culture Enthusiast is drawn to art that references or is inspired by popular culture, movies, music, or current events . Artists who tap into contemporary pop culture can attract artists who are passionate about sustainability .\n",
            "Summary of Chunk 22:  Artists with a green approach can find patrons here . Incorporate contemporary references in artworks and  actively engage with pop culture communities . Emphasize sustainable methods or materials  used and perhaps collaborate with eco-focused organizations .\n",
            "Summary of Chunk 23:  The Experimental Collector is always on the lookout for unique, unique, or experimental art . Artists can connect with collectors by participating in local events or highlighting local themes . They focus primarily on supporting and buying art from local artists .\n",
            "Summary of Chunk 24:  For artists who aren’t afraid to try unconventional methods or ideas, these collectors could become staunch supporters . Engage in local art communities, participate in community events, and emphasize local themes . Host experimental art  exhibitions or collaborative\n",
            "Summary of Chunk 25:  Artists whose work aligns  with popular interior design trends or timeless styles can capture this audience . The Corporate Collector: These are businesses or corporate entities buying art for their offices .\n",
            "Summary of Chunk 26:  Artists  who can create large-scale works or pieces that resonate with corporate values can find opportunities here . Collaborate with interior designers or offer art pieces that align  with current design trends .\n",
            "Summary of Chunk 27:  The Gallery Affiliate is an affiliate of The Gallery at The Gallery, The Gallery.com . The Gallery’s social media accounts should include a portion of your social media efforts in  showcasing interiors .\n",
            "Summary of Chunk 28:  Gallery Affiliate: These collectors look for artists who fit their gallery’s theme and have potential for future exhibitions . Commemorative Collector: They buy art to commemorate important milestones in their lives .\n",
            "Summary of Chunk 29:  Artists who can personalize works or capture emotions will appeal to educators . Artists who produce thought-provoking or historical works can find a n.e.a.\n",
            "Summary of Chunk 30:  These collectors purchase art to support specific causes or charities . Artists who align with these values or contribute to these causes can attract artists' attention . Offer educational discounts and make it easy for educational institutions to collaborate with you .\n",
            "Summary of Chunk 31:  The Traveler Collector collects art from places they’ve visited . Partner with NGOs or create art series that  support specific causes . Create exhibitions within educational institutions that encourage viewer interaction .\n",
            "Summary of Chunk 32:  These collectors are frequent visitors to prominent art fairs looking for new talents and pieces to add to their collections . Artists from tourist destinations or those capturing the essence of a location can cater to these collectors .\n",
            "Summary of Chunk 33:  Family Legacy Collector: They inherit and continue the art collection legacy of their families . They often look for artworks that complement their existing collection . Artists whose style or theme aligns with historic or time-honored traditions .\n",
            "Summary of Chunk 34:  Collector is always on the lookout for undervalued pieces, estate sales, or artists who haven’t ‘discovered’ yet . They pride themselves on getting art  at a lower price point and potentially finding hidden gems .\n",
            "Summary of Chunk 35:  The art becomes a representation of their ability to find undervalued things . Research historic art trends and create complementary pieces that align with such traditions . Offer occasional discounts, bundle deals, or spotlight emerging talents .\n",
            "Summary of Chunk 36:  The reality is that most collectors are a combination of several personality types . They have a vision about what art and beauty should be in the future, and they collect in line with that vision .\n",
            "Summary of Chunk 37:  This is a game  that is won through psychology. I’m sure you will be able to use this collector personality type list without my help . I have a section in The Artist Formula where I explain how I use this\n",
            "Summary of Chunk 38:  Aim to have your works featured in avant-garde galleries or spaces known for cutting-edge contemporary art . Join panels, symposiums, or talks focusing on the future of art .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vhcOkJUL-UdD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}