{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/LLMs/blob/main/LLM_042_langchain_transform_chain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain\n",
        "# !pip install openai\n",
        "# !pip install python-dotenv\n",
        "# !pip install langchain-openai"
      ],
      "metadata": {
        "id": "Eyqq-4TIVCMw"
      },
      "id": "Eyqq-4TIVCMw",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "import json\n",
        "import langchain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import TransformChain, LLMChain, SimpleSequentialChain, SequentialChain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "# Load environment variables from .env file\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "# Set the environment variable globally for libraries like LangChain\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "# Print the API key to confirm it's loaded correctly\n",
        "print(\"API Key loaded from .env:\",os.environ[\"OPENAI_API_KEY\"][0:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQyA84-cVFTb",
        "outputId": "5bad8ae4-adf1-4f85-a94d-a2a5f60b8812"
      },
      "id": "ZQyA84-cVFTb",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key loaded from .env: sk-proj-e1GUWruINPRnrozmiakkRM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "728f1747-b8fc-4d31-96c2-047fc83c079d",
      "metadata": {
        "id": "728f1747-b8fc-4d31-96c2-047fc83c079d"
      },
      "source": [
        "### **Transform Chains in LangChain**\n",
        "\n",
        "**Transform chains** are a type of chain in LangChain that allow for **custom data transformations** during a workflow. These chains are particularly useful when you need to preprocess, manipulate, or reformat data before or after passing it to an LLM or another chain.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Features of Transform Chains**\n",
        "1. **Custom Transformations**:\n",
        "   - Apply custom logic or functions to modify inputs, outputs, or intermediate data.\n",
        "   - Example: Cleaning text, extracting keywords, or splitting inputs into smaller parts.\n",
        "\n",
        "2. **Reusable Logic**:\n",
        "   - Encapsulate reusable transformations to maintain cleaner and more modular code.\n",
        "\n",
        "3. **Non-LLM Operations**:\n",
        "   - Perform operations that do not require a language model, such as mathematical computations or format conversions.\n",
        "\n",
        "4. **Flexibility**:\n",
        "   - Easily integrate with other chains to preprocess input or post-process output in a larger pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "### **How They Work**\n",
        "\n",
        "- **Input Transformation**: Modify input data before passing it to the next chain.\n",
        "- **Output Transformation**: Adjust output data after itâ€™s processed by another chain.\n",
        "\n",
        "---\n",
        "\n",
        "### **Example Use Cases**\n",
        "1. **Preprocessing Inputs**:\n",
        "   - Removing unnecessary whitespace, normalizing text, or extracting key fields.\n",
        "2. **Postprocessing Outputs**:\n",
        "   - Formatting LLM responses into structured data (e.g., JSON) or applying additional logic to results.\n",
        "3. **Custom Logic**:\n",
        "   - Applying domain-specific calculations or filtering results.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Benefits**\n",
        "- **Improved Workflow**:\n",
        "   - Allows intermediate transformations to prepare data for specific tasks.\n",
        "- **Modularity**:\n",
        "   - Keeps data transformation logic separate from other chains, ensuring clean and reusable workflows.\n",
        "- **Customizability**:\n",
        "   - Enables domain-specific preprocessing and postprocessing without modifying core logic.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_fun(inputs: dict) -> dict:\n",
        "    '''\n",
        "    This function takes a dictionary of inputs and performs custom transformations\n",
        "    on the \"text\" input. It extracts the part of the text after \"REVIEW:\",\n",
        "    converts it to lowercase, and returns the result as a dictionary.\n",
        "    '''\n",
        "    # GRAB INCOMING CHAIN TEXT\n",
        "    text = inputs['text']  # Access the \"text\" input from the dictionary\n",
        "\n",
        "    # Extract only the part of the text after \"REVIEW:\"\n",
        "    only_review_text = text.split('REVIEW:')[-1]\n",
        "\n",
        "    # Convert the extracted text to lowercase\n",
        "    lower_case_text = only_review_text.lower()\n",
        "\n",
        "    # Return the transformed text in a dictionary\n",
        "    return {'output': lower_case_text}\n",
        "\n",
        "# Step 1: Create a TransformChain to preprocess the input\n",
        "transform_chain = TransformChain(\n",
        "    input_variables=['text'],  # Specify the expected input variable\n",
        "    output_variables=['output'],  # Specify the output variable after transformation\n",
        "    transform=transformer_fun  # Use the custom transformation function defined above\n",
        ")\n",
        "\n",
        "# Step 2: Define the prompt template for summarizing the review\n",
        "template = \"Create a one sentence summary of this review:\\n{review_text}\"\n",
        "\n",
        "# Step 3: Initialize the Language Learning Model (LLM)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)  # Specify the LLM configuration\n",
        "\n",
        "# Step 4: Create a prompt template for the LLM\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# Step 5: Create a chain to generate a summary from the transformed review\n",
        "summary_chain = LLMChain(\n",
        "    llm=llm,  # The LLM to process the input\n",
        "    prompt=prompt,  # The prompt template used to format the input\n",
        "    output_key=\"review_summary\"  # The key for storing the summary output\n",
        ")\n",
        "\n",
        "# Step 6: Combine the TransformChain and LLMChain into a SequentialChain\n",
        "sequential_chain = SimpleSequentialChain(\n",
        "    chains=[transform_chain, summary_chain],  # Execute the chains sequentially\n",
        "    verbose=True  # Enable verbose mode to log each step\n",
        ")\n",
        "\n",
        "# Step 7: Run the sequential chain with a Yelp review as input\n",
        "result = sequential_chain.invoke(yelp_review)  # \"yelp_review\" is the input dictionary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv2iPL83WVKH",
        "outputId": "d8c3403a-f8ca-487d-9999-642248db6392"
      },
      "id": "Nv2iPL83WVKH",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "oh my goodness, where do i begin? this restaurant is absolutely phenomenal! i went there last night with my friends, and we were blown away by the experience!\n",
            "\n",
            "first of all, the ambiance is out of this world! the moment you step inside, you're greeted with a warm and inviting atmosphere. the decor is stunning, and it immediately sets the tone for an unforgettable dining experience.\n",
            "\n",
            "now, let's talk about the food! wow, just wow! the menu is a paradise for food lovers. every dish we ordered was a masterpiece. the flavors were bold, vibrant, and exploded in our mouths. from starters to desserts, every bite was pure bliss!\n",
            "\n",
            "their seafood platter is a must-try! the freshness of the seafood is unmatched, and the presentation is simply stunning. i have never tasted such delicious and perfectly cooked seafood in my life. it's a seafood lover's dream come true!\n",
            "\n",
            "the service was exemplary. the staff was attentive, friendly, and extremely knowledgeable about the menu. they went above and beyond to ensure that we had the best dining experience possible.\n",
            "\n",
            "and let's not forget about the desserts! oh my, oh my! i had their signature chocolate lava cake, and it was pure heaven. the cake was moist, and when i cut into it, the warm chocolate ooozed out, creating an explosion of flavor in my mouth. it was like a symphony of chocolatey goodness!\n",
            "\n",
            "in conclusion, this restaurant is a hidden gem! if you want to indulge in a memorable dining experience, do yourself a favor and visit this place. you won't regret it! i can't wait to go back and try more of their delectable dishes. kudos to the entire team for creating such a culinary haven!\n",
            "\n",
            "all i can say is... woohoo!\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mThis review enthusiastically praises a restaurant for its stunning ambiance, exceptional seafood, exquisite desserts, and outstanding service, declaring it a hidden gem and a must-visit for anyone seeking a memorable dining experience.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "52a400a3-0a38-4042-ae8e-3a48d11b2223",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "52a400a3-0a38-4042-ae8e-3a48d11b2223",
        "outputId": "4b3e8894-6af8-4d92-c584-30e7034ffd2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"TITLE: AN ABSOLUTE DELIGHT! A CULINARY HAVEN!\\n\\nREVIEW:\\nOH MY GOODNESS, WHERE DO I BEGIN? THIS RESTAURANT IS ABSOLUTELY PHENOMENAL! I WENT THERE LAST NIGHT WITH MY FRIENDS, AND WE WERE BLOWN AWAY BY THE EXPERIENCE!\\n\\nFIRST OF ALL, THE AMBIANCE IS OUT OF THIS WORLD! THE MOMENT YOU STEP INSIDE, YOU'RE GREETED WITH A WARM AND INVITING ATMOSPHERE. THE DECOR IS STUNNING, AND IT IMMEDIATELY SETS THE TONE FOR AN UNFORGETTABLE DINING EXPERIENCE.\\n\\nNOW, LET'S TALK ABOUT THE FOOD! WOW, JUST WOW! THE MENU IS A PARADISE FOR FOOD LOVERS. EVERY DISH WE ORDERED WAS A MASTERPIECE. THE FLAVORS WERE BOLD, VIBRANT, AND EXPLODED IN OUR MOUTHS. FROM STARTERS TO DESSERTS, EVERY BITE WAS PURE BLISS!\\n\\nTHEIR SEAFOOD PLATTER IS A MUST-TRY! THE FRESHNESS OF THE SEAFOOD IS UNMATCHED, AND THE PRESENTATION IS SIMPLY STUNNING. I HAVE NEVER TASTED SUCH DELICIOUS AND PERFECTLY COOKED SEAFOOD IN MY LIFE. IT'S A SEAFOOD LOVER'S DREAM COME TRUE!\\n\\nTHE SERVICE WAS EXEMPLARY. THE STAFF WAS ATTENTIVE, FRIENDLY, AND EXTREMELY KNOWLEDGEABLE ABOUT THE MENU. THEY WENT ABOVE AND BEYOND TO ENSURE THAT WE HAD THE BEST DINING EXPERIENCE POSSIBLE.\\n\\nAND LET'S NOT FORGET ABOUT THE DESSERTS! OH MY, OH MY! I HAD THEIR SIGNATURE CHOCOLATE LAVA CAKE, AND IT WAS PURE HEAVEN. THE CAKE WAS MOIST, AND WHEN I CUT INTO IT, THE WARM CHOCOLATE OOOZED OUT, CREATING AN EXPLOSION OF FLAVOR IN MY MOUTH. IT WAS LIKE A SYMPHONY OF CHOCOLATEY GOODNESS!\\n\\nIN CONCLUSION, THIS RESTAURANT IS A HIDDEN GEM! IF YOU WANT TO INDULGE IN A MEMORABLE DINING EXPERIENCE, DO YOURSELF A FAVOR AND VISIT THIS PLACE. YOU WON'T REGRET IT! I CAN'T WAIT TO GO BACK AND TRY MORE OF THEIR DELECTABLE DISHES. KUDOS TO THE ENTIRE TEAM FOR CREATING SUCH A CULINARY HAVEN!\\n\\nALL I CAN SAY IS... WOOHOO!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "result['input']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "04919296-ae05-4600-becd-e41724827f32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "04919296-ae05-4600-becd-e41724827f32",
        "outputId": "ab126a48-4622-4576-9b85-39ba915d8298"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This review enthusiastically praises a restaurant for its stunning ambiance, exceptional seafood, exquisite desserts, and outstanding service, declaring it a hidden gem and a must-visit for anyone seeking a memorable dining experience.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "result['output']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Step-by-Step Explanation**\n",
        "\n",
        "1. **Custom Transformation (`transformer_fun`)**:\n",
        "   - This function extracts and processes text from the input dictionary:\n",
        "     - Splits the text to isolate the review part (everything after `\"REVIEW:\"`).\n",
        "     - Converts the extracted review text to lowercase.\n",
        "   - Returns a dictionary containing the transformed text (`'output': lower_case_text`).\n",
        "\n",
        "2. **TransformChain**:\n",
        "   - Uses the `transformer_fun` function to preprocess the input.\n",
        "   - Specifies:\n",
        "     - `input_variables`: The input key (`'text'`) expected in the input dictionary.\n",
        "     - `output_variables`: The key (`'output'`) to store the transformed text.\n",
        "\n",
        "3. **Prompt Template**:\n",
        "   - Defines how the transformed text will be passed to the LLM:\n",
        "     - Example: `\"Create a one sentence summary of this review:\\n{review_text}\"`.\n",
        "\n",
        "4. **LLMChain**:\n",
        "   - Takes the transformed review text as input and generates a one-sentence summary.\n",
        "   - Uses:\n",
        "     - An LLM (`ChatOpenAI`) for natural language processing.\n",
        "     - A prompt to format the input before passing it to the LLM.\n",
        "     - `output_key`: Stores the generated summary under `'review_summary'`.\n",
        "\n",
        "5. **SequentialChain**:\n",
        "   - Combines the `TransformChain` and the `LLMChain` into a sequential workflow.\n",
        "   - Steps:\n",
        "     1. `TransformChain` preprocesses the input review text.\n",
        "     2. The transformed text (`'output'`) is passed to the `LLMChain`.\n",
        "     3. The `LLMChain` generates a one-sentence summary.\n",
        "\n",
        "6. **Running the Chain**:\n",
        "   - `sequential_chain(yelp_review)`:\n",
        "     - Passes a Yelp review (e.g., `{'text': 'Some text including REVIEW: This place was amazing!'}`) as input.\n",
        "     - Executes the chains sequentially and produces a final summary.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Concepts**\n",
        "\n",
        "1. **Modularity**:\n",
        "   - The workflow is broken into reusable components:\n",
        "     - `TransformChain` handles data preprocessing.\n",
        "     - `LLMChain` focuses on task-specific processing (e.g., generating a summary).\n",
        "\n",
        "2. **Data Transformation**:\n",
        "   - Custom transformations (`transformer_fun`) allow for domain-specific preprocessing, ensuring clean and structured input for downstream tasks.\n",
        "\n",
        "3. **Sequential Execution**:\n",
        "   - The `SimpleSequentialChain` ensures that the output of one chain serves as the input for the next, creating a seamless pipeline.\n",
        "\n",
        "4. **Scalability**:\n",
        "   - Additional chains can be added to the pipeline for more complex workflows (e.g., sentiment analysis after summarization).\n",
        "\n"
      ],
      "metadata": {
        "id": "yq_0EtZOX08z"
      },
      "id": "yq_0EtZOX08z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting and Processing Ratings"
      ],
      "metadata": {
        "id": "4qS3X1q1YMC0"
      },
      "id": "4qS3X1q1YMC0"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c25cb99b-2e7a-4764-a767-f84e38e4ec39",
      "metadata": {
        "id": "c25cb99b-2e7a-4764-a767-f84e38e4ec39"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import TransformChain, LLMChain, SimpleSequentialChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Step 1: Define a custom transformation function\n",
        "def extract_rating(inputs: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Extract numerical ratings (out of 5) from the input text.\n",
        "    Returns the extracted rating as part of the output dictionary.\n",
        "    \"\"\"\n",
        "    # Grab the input text\n",
        "    review_text = inputs[\"text\"]\n",
        "\n",
        "    # Extract the rating (assumes a format like \"Rating: X/5\")\n",
        "    if \"Rating:\" in review_text:\n",
        "        rating = review_text.split(\"Rating:\")[-1].split(\"/\")[0].strip()\n",
        "        numeric_rating = int(rating)  # Convert to integer\n",
        "    else:\n",
        "        numeric_rating = 3  # Default rating if none is found\n",
        "\n",
        "    return {\"rating\": numeric_rating}\n",
        "\n",
        "# Step 2: Create a TransformChain for extracting the rating\n",
        "rating_extraction_chain = TransformChain(\n",
        "    input_variables=[\"text\"],  # Input key expected in the input dictionary\n",
        "    output_variables=[\"rating\"],  # Output key for the extracted rating\n",
        "    transform=extract_rating  # Custom transformation function\n",
        ")\n",
        "\n",
        "# Step 3: Define the prompt template for sentiment summary\n",
        "template = \"The user gave a rating of {rating} out of 5. Write a brief comment summarizing the sentiment.\"\n",
        "\n",
        "# Step 4: Initialize the LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "\n",
        "# Step 5: Create an LLMChain for sentiment summary generation\n",
        "sentiment_chain = LLMChain(\n",
        "    llm=llm,  # The LLM to process the input\n",
        "    prompt=ChatPromptTemplate.from_template(template),  # Prompt template\n",
        "    output_key=\"sentiment_summary\"  # Output key for the summary\n",
        ")\n",
        "\n",
        "# Step 6: Combine the chains into a sequential pipeline\n",
        "pipeline = SimpleSequentialChain(\n",
        "    chains=[rating_extraction_chain, sentiment_chain],  # Execute chains sequentially\n",
        "    verbose=True  # Enable detailed logging\n",
        ")\n",
        "\n",
        "# Step 7: Run the pipeline with a review as input\n",
        "review_input = {\"text\": \"The food was delicious, and the service was excellent! Rating: 5/5\"}\n",
        "result = pipeline.(review_input)\n",
        "\n",
        "# Print the final output\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import TransformChain, LLMChain, SimpleSequentialChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Step 1: Define a custom transformation function\n",
        "def extract_rating(inputs: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Extract numerical ratings (out of 5) from the input text.\n",
        "    Returns the extracted rating as part of the output dictionary.\n",
        "    \"\"\"\n",
        "    # Grab the input text\n",
        "    review_text = inputs[\"input\"]  # Expecting the key to be 'input' for compatibility\n",
        "\n",
        "    # Extract the rating (assumes a format like \"Rating: X/5\")\n",
        "    if \"Rating:\" in review_text:\n",
        "        rating = review_text.split(\"Rating:\")[-1].split(\"/\")[0].strip()\n",
        "        numeric_rating = int(rating)  # Convert to integer\n",
        "    else:\n",
        "        numeric_rating = 3  # Default rating if none is found\n",
        "\n",
        "    return {\"rating\": numeric_rating}\n",
        "\n",
        "# Step 2: Create a TransformChain for extracting the rating\n",
        "rating_extraction_chain = TransformChain(\n",
        "    input_variables=[\"input\"],  # Updated input key to match SequentialChain requirements\n",
        "    output_variables=[\"rating\"],  # Output key for the extracted rating\n",
        "    transform=extract_rating  # Custom transformation function\n",
        ")\n",
        "\n",
        "# Step 3: Define the prompt template for sentiment summary\n",
        "template = \"The user gave a rating of {rating} out of 5. Write a brief comment summarizing the sentiment.\"\n",
        "\n",
        "# Step 4: Initialize the LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "\n",
        "# Step 5: Create an LLMChain for sentiment summary generation\n",
        "sentiment_chain = LLMChain(\n",
        "    llm=llm,  # The LLM to process the input\n",
        "    prompt=ChatPromptTemplate.from_template(template),  # Prompt template\n",
        "    output_key=\"sentiment_summary\"  # Output key for the summary\n",
        ")\n",
        "\n",
        "# Step 6: Combine the chains into a sequential pipeline\n",
        "pipeline = SimpleSequentialChain(\n",
        "    chains=[rating_extraction_chain, sentiment_chain],  # Execute chains sequentially\n",
        "    verbose=True  # Enable detailed logging\n",
        ")\n",
        "\n",
        "# Step 7: Run the pipeline with a review as input\n",
        "review_input = {\"input\": \"The food was delicious, and the service was excellent! Rating: 5/5\"}\n",
        "result = pipeline.invoke(review_input)\n",
        "\n",
        "# Print the final output\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ro2adE2YcrZ",
        "outputId": "07358a10-7abe-4e2e-ab6a-bb75e23ffc1b"
      },
      "id": "7Ro2adE2YcrZ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m5\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mThe user expressed a highly positive sentiment with a perfect rating of 5 out of 5, indicating complete satisfaction and approval.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'The food was delicious, and the service was excellent! Rating: 5/5', 'output': 'The user expressed a highly positive sentiment with a perfect rating of 5 out of 5, indicating complete satisfaction and approval.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GGEhHbrYtUE",
        "outputId": "bb1eeea6-87f9-4cb8-af4b-35ee2d9ee4b4"
      },
      "id": "7GGEhHbrYtUE",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input', 'output'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Extract the rating\n",
        "rating_result = rating_extraction_chain.invoke({\"input\": \"The food was delicious, and the service was excellent! Rating: 5/5\"})\n",
        "print(f\"Extracted Rating: {rating_result['rating']}\")  # Access the 'rating' key\n",
        "\n",
        "# Step 2: Generate the sentiment analysis\n",
        "sentiment_result = sentiment_chain.invoke({\"rating\": rating_result[\"rating\"]})\n",
        "print(f\"Sentiment Analysis: {sentiment_result['sentiment_summary']}\")  # Access the 'sentiment_summary' key\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd_cke4oY1az",
        "outputId": "06d11671-c296-4965-b235-8bf852cd0cac"
      },
      "id": "vd_cke4oY1az",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Rating: 5\n",
            "Sentiment Analysis: The user expressed a highly positive sentiment with a perfect rating of 5 out of 5, indicating complete satisfaction and appreciation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XZ_ctLI4ZYyb"
      },
      "id": "XZ_ctLI4ZYyb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}