{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/LLMs/blob/main/LLM_0010_chatbots_customer_service_chatbot_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75e2ef28-594f-4c18-9d22-c6b8cd40ead2",
      "metadata": {
        "id": "75e2ef28-594f-4c18-9d22-c6b8cd40ead2"
      },
      "source": [
        "#Chatbots!\n",
        "\n",
        "Chatbots have a wide range of practical applications across industries, and thinking through different use cases will not only help you sharpen your technical skills but also inspire creative solutions for businesses.\n",
        "\n",
        "Here are some **practical use cases** for chatbots that can help you learn and build real-world applications:\n",
        "\n",
        "### 1. **Customer Service & Support Bots**:\n",
        "   - **What you learn**: Handling FAQ-style conversations, connecting with databases or knowledge bases, escalating issues to human agents.\n",
        "   - **Business Solution**: Automating first-level customer service for e-commerce, retail, telecom, or any company with customer-facing operations. You can implement a chatbot that answers common queries, processes returns, or tracks orders.\n",
        "   - **Advanced Features**: Sentiment analysis to detect frustration, handover to human support, multilingual support.\n",
        "   \n",
        "   **Example**: A chatbot that helps customers in an online clothing store by answering sizing queries, providing product recommendations, and tracking orders.\n",
        "\n",
        "### 2. **Sales & Product Recommendation Bots**:\n",
        "   - **What you learn**: Recommending products based on user input, integrating with sales/CRM systems, upselling, and cross-selling products.\n",
        "   - **Business Solution**: For retailers and online marketplaces, a chatbot could act as a personal shopping assistant, guiding customers through options based on preferences or offering special promotions based on their interests.\n",
        "   - **Advanced Features**: Personalized product suggestions based on browsing history, targeted promotions, lead qualification for B2B sales.\n",
        "   \n",
        "   **Example**: A chatbot that asks customers about their preferences, budget, and needs, then recommends relevant products and offers.\n",
        "\n",
        "### 3. **Lead Generation & Qualification Bots**:\n",
        "   - **What you learn**: Collecting user information, qualifying leads, storing data in a CRM, scheduling follow-ups.\n",
        "   - **Business Solution**: For B2B companies or service-based industries (like insurance, real estate, or financial services), a chatbot can ask key qualifying questions and pass qualified leads to sales teams.\n",
        "   - **Advanced Features**: Lead scoring, appointment scheduling, follow-up reminders, and personalized messages based on the lead’s profile.\n",
        "   \n",
        "   **Example**: A chatbot that collects basic information (like company size, needs, and budget), qualifies the lead, and schedules a call with a sales representative.\n",
        "\n",
        "### 4. **Internal Company Knowledge Base Bots**:\n",
        "   - **What you learn**: Integrating with company databases, answering questions based on company policies, onboarding employees.\n",
        "   - **Business Solution**: For large organizations, chatbots can serve as internal support systems, helping employees find information about HR policies, IT troubleshooting, or company procedures.\n",
        "   - **Advanced Features**: Integration with intranet systems, role-based access to specific information, real-time updates from internal documents.\n",
        "   \n",
        "   **Example**: An HR assistant bot that helps employees find information about vacation policies, healthcare benefits, or submit requests.\n",
        "\n",
        "### 5. **Appointment Scheduling & Reminders**:\n",
        "   - **What you learn**: Managing time-based events, integrating with calendars, sending reminders, handling rescheduling or cancellations.\n",
        "   - **Business Solution**: For businesses in healthcare, beauty, fitness, or professional services, a chatbot can handle appointment bookings, rescheduling, and reminders, reducing the need for manual coordination.\n",
        "   - **Advanced Features**: Automated reminder messages (SMS or email), calendar integration (Google Calendar, Outlook), reminders for upcoming appointments, cancellations.\n",
        "   \n",
        "   **Example**: A chatbot for a doctor's office that helps patients schedule appointments and sends reminders a day before.\n",
        "\n",
        "### 6. **Event Registration & RSVP Bots**:\n",
        "   - **What you learn**: Collecting user information, sending confirmations, managing RSVP lists.\n",
        "   - **Business Solution**: For businesses or organizations hosting events (webinars, conferences, etc.), a chatbot can handle the entire registration process, from collecting attendee details to sending reminders.\n",
        "   - **Advanced Features**: Event reminders, personalized event recommendations, integration with video conferencing tools, follow-up messages after events.\n",
        "   \n",
        "   **Example**: A chatbot that helps users register for a webinar, provides event details, and sends reminders leading up to the event.\n",
        "\n",
        "### 7. **Health and Wellness Bots**:\n",
        "   - **What you learn**: Personalized interaction, goal tracking, providing information, responding to common health questions.\n",
        "   - **Business Solution**: For wellness, fitness, or healthcare companies, chatbots can provide personalized health tips, daily reminders for medication or exercises, and track users’ wellness goals.\n",
        "   - **Advanced Features**: Daily goal tracking, health data input, integrating with wearables (like FitBit), and providing data-driven suggestions.\n",
        "   \n",
        "   **Example**: A fitness chatbot that asks about the user’s goals and schedules reminders for workouts or nutrition tips.\n",
        "\n",
        "### 8. **Survey and Feedback Bots**:\n",
        "   - **What you learn**: Collecting structured data from users, processing responses, generating reports.\n",
        "   - **Business Solution**: For companies looking to improve customer satisfaction or employee engagement, chatbots can collect feedback, perform surveys, and analyze data for insights.\n",
        "   - **Advanced Features**: Generating dynamic questions based on responses, real-time analytics, segmenting responses by user type.\n",
        "   \n",
        "   **Example**: A chatbot that surveys customers after a service interaction and reports on the overall satisfaction score.\n",
        "\n",
        "### 9. **E-learning or Educational Assistant Bots**:\n",
        "   - **What you learn**: Providing information, interactive learning experiences, integrating with learning platforms.\n",
        "   - **Business Solution**: For educational institutions or online learning platforms, chatbots can guide students through learning materials, answer questions, and offer practice quizzes.\n",
        "   - **Advanced Features**: Adaptive learning paths, quiz scoring, real-time feedback on performance.\n",
        "   \n",
        "   **Example**: A chatbot that helps students with study materials, provides practice problems, and tracks progress.\n",
        "\n",
        "### 10. **AI-Powered Personal Assistant Bots**:\n",
        "   - **What you learn**: Handling tasks like setting reminders, managing to-do lists, integrating with APIs for productivity tools.\n",
        "   - **Business Solution**: For individuals or professionals, a chatbot can act as a personal assistant by handling tasks like scheduling, sending reminders, or organizing to-do lists.\n",
        "   - **Advanced Features**: Integration with external services (like task management tools, email clients), providing summaries or reminders.\n",
        "   \n",
        "   **Example**: A personal productivity assistant that helps users track tasks, set goals, and provides productivity tips.\n",
        "\n",
        "### Strategic Next Steps:\n",
        "1. **Pick One or Two Use Cases**: Start by choosing a couple of use cases that resonate with you or your target audience. Implement simple versions first (e.g., a customer service FAQ bot or a personal assistant).\n",
        "2. **Expand with Features**: Once you’ve mastered the basics, expand by integrating more advanced features (like reminders, API integrations, or sentiment analysis).\n",
        "3. **Explore Industry-Specific Use Cases**: Think about the industries you are interested in and tailor the chatbot use case to the specific challenges of that field (e.g., legal, finance, healthcare).\n",
        "\n",
        "These ideas will give you a good foundation to learn chatbot development while thinking about real-world applications and creative solutions for businesses."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Libraries"
      ],
      "metadata": {
        "id": "xYtTpEjjA8hD"
      },
      "id": "xYtTpEjjA8hD"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install python-dotenv\n",
        "# !pip install openai\n",
        "# !pip install google-generativeai\n",
        "# !pip install anthropic\n",
        "# !pip install gradio"
      ],
      "metadata": {
        "id": "ifw0J2E4A2Ex"
      },
      "id": "ifw0J2E4A2Ex",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "m7TZSjRQA517"
      },
      "id": "m7TZSjRQA517"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "70e39cd8-ec79-4e3e-9c26-5659d42d0861",
      "metadata": {
        "id": "70e39cd8-ec79-4e3e-9c26-5659d42d0861"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import requests\n",
        "import json\n",
        "from typing import List\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Environment Variables"
      ],
      "metadata": {
        "id": "33QZ6MgqBGbd"
      },
      "id": "33QZ6MgqBGbd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the environment variables from the .env file\n",
        "load_dotenv('/content/API_KEYS.env')  # Ensure this is the correct path to your file\n",
        "\n",
        "# Get the API keys from the environment\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
        "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# Check if the keys are loaded correctly and print a portion of them\n",
        "if openai_api_key:\n",
        "    print(f\"OpenAI API Key loaded: {openai_api_key[0:10]}...\")  # Only print part of the key\n",
        "else:\n",
        "    print(\"OpenAI API key not loaded correctly.\")\n",
        "\n",
        "if anthropic_api_key:\n",
        "    print(f\"Anthropic API Key loaded: {anthropic_api_key[0:10]}...\")\n",
        "else:\n",
        "    print(\"Anthropic API key not loaded correctly.\")\n",
        "\n",
        "if google_api_key:\n",
        "    print(f\"Google API Key loaded: {google_api_key[0:10]}...\")\n",
        "else:\n",
        "    print(\"Google API key not loaded correctly.\")"
      ],
      "metadata": {
        "id": "IFJKU1REww17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459ab8e3-e243-4da2-95a5-3eb899864d69"
      },
      "id": "IFJKU1REww17",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API Key loaded: sk-proj-e1...\n",
            "Anthropic API Key loaded: sk-ant-api...\n",
            "Google API Key loaded: AIzaSyDh3a...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import anthropic\n",
        "import google.generativeai\n",
        "\n",
        "# Connect to OpenAI\n",
        "openai.api_key = openai_api_key  # Set OpenAI API key\n",
        "\n",
        "# Connect to Anthropic (Claude)\n",
        "claude = anthropic.Anthropic(api_key=anthropic_api_key)  # Set Anthropic API key\n",
        "\n",
        "# Connect to Google Generative AI\n",
        "google.generativeai.configure(api_key=google_api_key)  # Set Google API key"
      ],
      "metadata": {
        "id": "_tvSBQa3BSGB"
      },
      "id": "_tvSBQa3BSGB",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Customer Service Chatbot\n",
        "\n",
        "Let's start building a **customer service chatbot** for Stanley's popular store, focusing on handling FAQ-style conversations. The chatbot will be able to handle common customer queries like product availability, returns, shipping, and possibly escalate issues to human support.\n",
        "\n",
        "### Strategy:\n",
        "- **Handle common questions**: FAQs about products, returns, shipping times, etc.\n",
        "- **Escalation**: Detect when a user needs human support.\n",
        "- **Sentiment analysis** (optional, advanced feature): Detect frustration and automatically offer human support or apologies.\n",
        "\n",
        "### Step 1: Define Common Queries (FAQ)\n",
        "We’ll build the chatbot to handle the following common queries:\n",
        "- **Product Availability**: Is the Stanley Cup available in certain colors or sizes?\n",
        "- **Returns**: How to return a product?\n",
        "- **Shipping Times**: How long does shipping take?\n",
        "- **Order Tracking**: Where is my order?\n",
        "- **Escalation**: When the user asks for human support or gets frustrated.\n",
        "\n",
        "### Step 2: Implement the Chatbot Functionality\n",
        "We’ll create a basic chatbot function that can answer these queries based on the user's input. Later, we can enhance it with sentiment analysis and multilingual support.\n",
        "\n",
        "### How It Works:\n",
        "1. **Predefined FAQs**: The chatbot has built-in answers for common customer service queries like product availability, returns, shipping, and order tracking. If the user's message contains keywords related to those topics, it will return a pre-programmed response.\n",
        "   \n",
        "2. **Handling Complex Queries**: If the user asks a question that doesn't match the predefined FAQs, the chatbot passes the query to OpenAI's GPT model to generate a response.\n",
        "\n",
        "3. **Escalation to Human Support**: If the user mentions wanting to speak with a human representative, the chatbot will offer an escalation message, informing the user that a human can be connected.\n",
        "\n",
        "### Next Steps:\n",
        "1. **Sentiment Analysis**: We can integrate a basic sentiment analysis function to detect frustration (e.g., if the user is unhappy with the bot's answers) and automatically suggest human assistance.\n",
        "   \n",
        "2. **Multilingual Support**: Later, we can add language detection and handle conversations in multiple languages.\n",
        "\n",
        "3. **API Integration**: For order tracking or real-time availability, we can integrate actual APIs from Stanley’s website or database to provide more personalized responses.\n",
        "\n"
      ],
      "metadata": {
        "id": "_v-qD7JZO6oY"
      },
      "id": "_v-qD7JZO6oY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yeild (Stream) Response\n",
        "\n",
        "You can modify the function to consistently use `yield` even when an FAQ response is returned. Now, if the FAQ condition is met, the response is yielded directly, maintaining a consistent generator flow in both cases.\n",
        "\n",
        "```python\n",
        "  # If the question is not in FAQs, generate response from the AI\n",
        "  if not response:\n",
        "      stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "      for chunk in stream:\n",
        "          response += chunk.choices[0].delta.content or ''\n",
        "          yield response\n",
        "  else:\n",
        "      # Yield the FAQ response as a single output\n",
        "      yield response\n",
        "```\n",
        ""
      ],
      "metadata": {
        "id": "H2em9dVP2ODw"
      },
      "id": "H2em9dVP2ODw"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import json\n",
        "import openai\n",
        "\n",
        "MODEL = 'gpt-4o-mini'\n",
        "system_message = \"You are a helpful customer service assistant for the Stanley store. You assist customers with queries about products, returns, shipping, and orders.\"\n",
        "history_file = \"chat_history.json\"\n",
        "\n",
        "# Function to save chat history to a JSON file\n",
        "def save_chat_history(history, file_path):\n",
        "    with open(file_path, \"w\") as file:\n",
        "        json.dump(history, file, indent=4)\n",
        "\n",
        "# Sample FAQs for the Stanley store\n",
        "faq_responses = {\n",
        "    \"availability\": \"The Stanley Cup is available in multiple colors and sizes, but some items may be out of stock due to high demand. You can check the latest availability on our website.\",\n",
        "    \"returns\": \"You can return any Stanley product within 30 days of purchase. Just visit our Returns page for more details and to start the process.\",\n",
        "    \"shipping\": \"Shipping typically takes between 3-5 business days for standard delivery. Expedited options are also available.\",\n",
        "    \"order tracking\": \"You can track your order by visiting the 'Order Tracking' page on our website. Just enter your order number to get the latest updates.\",\n",
        "    \"human support\": \"I can help you with most questions, but if you need further assistance, I can connect you to a human representative.\"\n",
        "}\n",
        "\n",
        "# Chat function\n",
        "def chat(message, history):\n",
        "    # Start the message list with the system message\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "\n",
        "    # Iterate through the history, adding user and assistant messages using OpenAI-style format\n",
        "    for msg in history:\n",
        "        messages.append(msg)\n",
        "\n",
        "    # Add the latest user message to the conversation\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    # Check for common FAQs first\n",
        "    response = \"\"\n",
        "    if \"availability\" in message.lower():\n",
        "        response = faq_responses[\"availability\"]\n",
        "    elif \"return\" in message.lower():\n",
        "        response = faq_responses[\"returns\"]\n",
        "    elif \"shipping\" in message.lower():\n",
        "        response = faq_responses[\"shipping\"]\n",
        "    elif \"track\" in message.lower():\n",
        "        response = faq_responses[\"order tracking\"]\n",
        "    elif \"human\" in message.lower() or \"representative\" in message.lower():\n",
        "        response = faq_responses[\"human support\"]\n",
        "\n",
        "    # If the question is not in FAQs, generate response from the AI\n",
        "    if not response:\n",
        "        stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "        for chunk in stream:\n",
        "            response += chunk.choices[0].delta.content or ''\n",
        "            yield response\n",
        "    else:\n",
        "        # Yield the FAQ response as a single output\n",
        "        yield response\n",
        "\n",
        "\n",
        "    # Add the current user message and assistant response to the history\n",
        "    history.append({\"role\": \"user\", \"content\": message})\n",
        "    history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    # Save updated history to a JSON file\n",
        "    save_chat_history(history, history_file)\n",
        "\n",
        "# Gradio interface\n",
        "gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "M5joRB_UvzrF",
        "outputId": "1c4e71e1-0b71-485f-98e9-8e94a80a4008"
      },
      "id": "M5joRB_UvzrF",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://bdda640b6f5d6228cf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bdda640b6f5d6228cf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7866 <> https://bdda640b6f5d6228cf.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read Chat Log"
      ],
      "metadata": {
        "id": "Z9GY622y02EL"
      },
      "id": "Z9GY622y02EL"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def print_chat_history(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, \"r\") as file:\n",
        "            history = json.load(file)\n",
        "\n",
        "        print(\"\\nChat History:\\n\" + \"=\" * 50)\n",
        "        turn = 1\n",
        "        for msg in history:\n",
        "            if msg[\"role\"] == \"user\":\n",
        "                # print(f\"Turn {turn}:\")\n",
        "                print(f\"User: {msg['content']}\")\n",
        "            elif msg[\"role\"] == \"assistant\":\n",
        "                print(f\"Assistant: {msg['content']}\")\n",
        "                print(\"-\" * 50)\n",
        "                turn += 1\n",
        "    else:\n",
        "        print(\"No chat history found.\")\n",
        "\n",
        "print_chat_history(\"/content/chat_history.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeZNGDiy0zSS",
        "outputId": "b224e85b-810d-46ad-f1d4-f7eb5c3dc524"
      },
      "id": "yeZNGDiy0zSS",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chat History:\n",
            "==================================================\n",
            "User: hello\n",
            "Assistant: Hello! How can I assist you today?\n",
            "--------------------------------------------------\n",
            "User: I need to make a return\n",
            "Assistant: You can return any Stanley product within 30 days of purchase. Just visit our Returns page for more details and to start the process.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis\n",
        "\n",
        "To add sentiment analysis to your chatbot, you can use OpenAI's models, which can be prompted to analyze sentiment directly. Here’s a step-by-step guide on implementing sentiment analysis with your OpenAI and Gradio setup\n"
      ],
      "metadata": {
        "id": "Z8sbiPjg57f4"
      },
      "id": "Z8sbiPjg57f4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Define a Sentiment Analysis Function\n",
        "\n",
        "First, create a function that sends text to the OpenAI model and asks it to classify the sentiment.\n",
        "\n",
        "This function sends the user’s message to OpenAI’s model and asks it to classify the sentiment."
      ],
      "metadata": {
        "id": "yBi7ypVB9g0S"
      },
      "id": "yBi7ypVB9g0S"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "MODEL = 'gpt-4o-mini'\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant for sentiment analysis.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Please classify the sentiment of this text: '{text}'. Indicate if it's Positive, Negative, or Neutral.\"}\n",
        "        ]\n",
        "    )\n",
        "    sentiment = response['choices'][0]['message']['content'].strip()\n",
        "    return sentiment"
      ],
      "metadata": {
        "id": "PsNaUYEi9vNp"
      },
      "id": "PsNaUYEi9vNp",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Integrate Sentiment Analysis with Your Chatbot\n",
        "\n",
        "Modify your chatbot to call `analyze_sentiment()` whenever a user sends a message. You can add this to the response function in your Gradio chatbot setup to analyze each message before responding.\n"
      ],
      "metadata": {
        "id": "IGsd0bAq9jig"
      },
      "id": "IGsd0bAq9jig"
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(user_message):\n",
        "    # Analyze sentiment\n",
        "    sentiment = analyze_sentiment(user_message)\n",
        "\n",
        "    # Generate a response based on the user message and sentiment\n",
        "    response = openai.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a friendly and helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"The user message sentiment is '{sentiment}'. Respond accordingly: '{user_message}'\"}\n",
        "        ]\n",
        "    )\n",
        "    chatbot_reply = response['choices'][0]['message']['content'].strip()\n",
        "    return f\"Sentiment: {sentiment}\\n\\nChatbot: {chatbot_reply}\""
      ],
      "metadata": {
        "id": "SGfj911L9sNL"
      },
      "id": "SGfj911L9sNL",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 3. Displaying Sentiment Analysis in Gradio\n",
        "\n",
        "With Gradio, you can format the output to show both the sentiment and the chatbot’s response. For example:\n",
        "\n",
        "\n",
        "### 4. Testing and Tuning\n",
        "\n",
        "You can test this integration by running your Gradio interface. Fine-tune the prompt in the `analyze_sentiment` function if the sentiment responses need adjusting.\n",
        "\n",
        "This setup will help your chatbot detect sentiment and generate more context-aware responses. Let me know if you want to customize the sentiment analysis or add specific responses based on sentiment!"
      ],
      "metadata": {
        "id": "vgi2VWt1wdrN"
      },
      "id": "vgi2VWt1wdrN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customer Service Chat Bot with Sentiment Analysis\n",
        "\n",
        "To integrate sentiment analysis with your shopping assistant bot, you can analyze the user’s sentiment in tandem with the FAQ and AI-generated responses to customize your chatbot's replies. For example, if a user is frustrated (negative sentiment), you might provide additional reassurance or connect them more quickly to human support.\n",
        "\n",
        "Here’s how you can add sentiment analysis to your setup:\n",
        "\n",
        "1. **Analyze Sentiment on Each User Message**: Run the `analyze_sentiment` function to determine if the sentiment is Positive, Negative, or Neutral.\n",
        "2. **Adjust Bot Responses Based on Sentiment**: Modify the response slightly depending on the sentiment, especially if it's negative.\n",
        "\n",
        "\n",
        "### Explanation of the Changes:\n",
        "1. **Sentiment Analysis**: `analyze_sentiment` function determines the sentiment for each user message.\n",
        "2. **Response Adjustment**: If the sentiment is negative, the bot adds a reassuring prefix to the FAQ response or can choose to prioritize connecting the user with human support.\n",
        "3. **Yield Statement**: Both FAQ and AI responses yield text to maintain responsiveness in the interface.\n",
        "\n",
        "This integration enables your chatbot to be more context-aware and empathetic, which can significantly improve the user experience, especially when users are frustrated or need additional assistance."
      ],
      "metadata": {
        "id": "gpdMAt86EXVh"
      },
      "id": "gpdMAt86EXVh"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import json\n",
        "import openai\n",
        "\n",
        "MODEL = 'gpt-4o-mini'\n",
        "system_message = \"You are a helpful customer service assistant for the Stanley store. You assist customers with queries about products, returns, shipping, and orders.\"\n",
        "history_file = \"chat_history.json\"\n",
        "\n",
        "# Function to save chat history to a JSON file\n",
        "def save_chat_history(history, file_path):\n",
        "    with open(file_path, \"w\") as file:\n",
        "        json.dump(history, file, indent=4)\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant for sentiment analysis.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"Please classify the sentiment of this text: '{text}'. Indicate if it's Positive, Negative, or Neutral.\"}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Print response for debugging\n",
        "        print(\"Response from OpenAI API:\", response)\n",
        "\n",
        "        # Extract sentiment from response\n",
        "        sentiment = response['choices'][0]['message']['content'].strip()\n",
        "        return sentiment\n",
        "\n",
        "    except TypeError as e:\n",
        "        print(\"TypeError encountered:\", e)\n",
        "        print(\"Response object:\", response)\n",
        "        return \"Neutral\"  # Default value if extraction fails\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", e)\n",
        "        return \"Neutral\"\n",
        "\n",
        "\n",
        "# Sample FAQs for the Stanley store\n",
        "faq_responses = {\n",
        "    \"availability\": \"The Stanley Cup is available in multiple colors and sizes, but some items may be out of stock due to high demand. You can check the latest availability on our website.\",\n",
        "    \"returns\": \"You can return any Stanley product within 30 days of purchase. Just visit our Returns page for more details and to start the process.\",\n",
        "    \"shipping\": \"Shipping typically takes between 3-5 business days for standard delivery. Expedited options are also available.\",\n",
        "    \"order tracking\": \"You can track your order by visiting the 'Order Tracking' page on our website. Just enter your order number to get the latest updates.\",\n",
        "    \"human support\": \"I can help you with most questions, but if you need further assistance, I can connect you to a human representative.\"\n",
        "}\n",
        "\n",
        "# Chat function\n",
        "def chat(message, history):\n",
        "    # Start the message list with the system message\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "\n",
        "    # Iterate through the history, adding user and assistant messages using OpenAI-style format\n",
        "    for msg in history:\n",
        "        messages.append(msg)\n",
        "\n",
        "    # Analyze the sentiment of the user's message\n",
        "    sentiment = analyze_sentiment(message)\n",
        "\n",
        "    # Add the latest user message to the conversation\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    # Check for common FAQs first\n",
        "    response = \"\"\n",
        "    if \"availability\" in message.lower():\n",
        "        response = faq_responses[\"availability\"]\n",
        "    elif \"return\" in message.lower():\n",
        "        response = faq_responses[\"returns\"]\n",
        "    elif \"shipping\" in message.lower():\n",
        "        response = faq_responses[\"shipping\"]\n",
        "    elif \"track\" in message.lower():\n",
        "        response = faq_responses[\"order tracking\"]\n",
        "    elif \"human\" in message.lower() or \"representative\" in message.lower():\n",
        "        response = faq_responses[\"human support\"]\n",
        "\n",
        "    # If the question is not in FAQs, generate response from the AI\n",
        "    if not response:\n",
        "        stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "        for chunk in stream:\n",
        "            response += chunk.choices[0].delta.content or ''\n",
        "            yield response\n",
        "    else:\n",
        "        # Yield the FAQ response as a single output\n",
        "        yield response\n",
        "\n",
        "\n",
        "    # Add the current user message and assistant response to the history\n",
        "    history.append({\"role\": \"user\", \"content\": message})\n",
        "    history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    # Save updated history to a JSON file\n",
        "    save_chat_history(history, history_file)\n",
        "\n",
        "# Gradio interface\n",
        "gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "kz8swQnTETyL",
        "outputId": "9766cf27-72e0-46fc-e346-f7214bd10486"
      },
      "id": "kz8swQnTETyL",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://da8d802cb0da76f2a9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://da8d802cb0da76f2a9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from OpenAI API: ChatCompletion(id='chatcmpl-AMgFCvuhI22K5E3QRhzOm8vu9ampY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The text 'hello' is considered as Neutral.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729968966, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=43, total_tokens=53, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
            "TypeError encountered: 'ChatCompletion' object is not subscriptable\n",
            "Response object: ChatCompletion(id='chatcmpl-AMgFCvuhI22K5E3QRhzOm8vu9ampY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The text 'hello' is considered as Neutral.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729968966, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=43, total_tokens=53, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
            "Response from OpenAI API: ChatCompletion(id='chatcmpl-AMgFZoBH3zLVJ8WjhbU9t9sFpEWcL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Neutral', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729968989, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=49, total_tokens=50, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
            "TypeError encountered: 'ChatCompletion' object is not subscriptable\n",
            "Response object: ChatCompletion(id='chatcmpl-AMgFZoBH3zLVJ8WjhbU9t9sFpEWcL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Neutral', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729968989, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=49, total_tokens=50, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
            "Response from OpenAI API: ChatCompletion(id='chatcmpl-AMgFxk3OXQQsp6sd1EgxXrfISjoMW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Sentiment: Negative.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729969013, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=5, prompt_tokens=52, total_tokens=57, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
            "TypeError encountered: 'ChatCompletion' object is not subscriptable\n",
            "Response object: ChatCompletion(id='chatcmpl-AMgFxk3OXQQsp6sd1EgxXrfISjoMW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Sentiment: Negative.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729969013, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=5, prompt_tokens=52, total_tokens=57, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7868 <> https://da8d802cb0da76f2a9.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read Chat Logs"
      ],
      "metadata": {
        "id": "K1Ow9DKYMRXq"
      },
      "id": "K1Ow9DKYMRXq"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def print_chat_history(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, \"r\") as file:\n",
        "            history = json.load(file)\n",
        "\n",
        "        print(\"\\nChat History:\\n\" + \"=\" * 50)\n",
        "        turn = 1\n",
        "        for msg in history:\n",
        "            if msg[\"role\"] == \"user\":\n",
        "                # print(f\"Turn {turn}:\")\n",
        "                print(f\"User: {msg['content']}\")\n",
        "            elif msg[\"role\"] == \"assistant\":\n",
        "                print(f\"Assistant: {msg['content']}\")\n",
        "                print(\"-\" * 50)\n",
        "                turn += 1\n",
        "    else:\n",
        "        print(\"No chat history found.\")\n",
        "\n",
        "print_chat_history(\"/content/chat_history.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsCcni1qETuQ",
        "outputId": "45059f75-fa36-4380-c102-9acca386e079"
      },
      "id": "nsCcni1qETuQ",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chat History:\n",
            "==================================================\n",
            "User: hello\n",
            "Assistant: Hello! How can I assist you today?\n",
            "--------------------------------------------------\n",
            "User: i need to return a Stanley cup\n",
            "Assistant: You can return any Stanley product within 30 days of purchase. Just visit our Returns page for more details and to start the process.\n",
            "--------------------------------------------------\n",
            "User: I am very unhappy and just want me money back\n",
            "Assistant: I'm sorry to hear that you're unhappy. I can help you with the return process. Please provide me with your order number and the reason for the return, and I'll guide you through it to ensure you get your refund as quickly as possible.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis with TextBlob\n",
        "Adding **sentiment analysis** to your chatbot is a great way to gauge the user's mood or emotional state and adjust the chatbot's responses accordingly. For example, if the user seems frustrated, the chatbot can apologize or offer to escalate the conversation to human support.\n",
        "\n",
        "### Approach:\n",
        "1. **Sentiment Analysis**: We can use pre-trained models from libraries like `TextBlob`, `VADER` (from `nltk`), or even `transformers` from Hugging Face to analyze the sentiment of user messages.\n",
        "2. **Adjust Responses**: Based on the sentiment (positive, neutral, or negative), the chatbot can modify its behavior (e.g., offer human support when the user is frustrated).\n",
        "\n",
        "### Step 1: Install the Necessary Libraries\n",
        "If you’re using **Google Colab**, you might need to install the libraries. For this example, we’ll use `TextBlob` for sentiment analysis (since it’s lightweight and easy to use).\n",
        "\n",
        "\n",
        "### Key Additions:\n",
        "1. **Sentiment Analysis with `TextBlob`**:\n",
        "   - The `analyze_sentiment()` function uses `TextBlob` to evaluate the user's message.\n",
        "   - The **polarity score** ranges from `-1` (very negative) to `1` (very positive). We’ve defined thresholds:\n",
        "     - If the score is below `-0.2`, the sentiment is classified as \"negative\".\n",
        "     - If the score is above `0.2`, it's classified as \"positive\".\n",
        "     - Otherwise, it’s considered \"neutral.\"\n",
        "\n",
        "2. **Adjusting Responses Based on Sentiment**:\n",
        "   - If the user’s sentiment is detected as **negative**, the chatbot will apologize and offer to escalate the conversation to a human representative.\n",
        "\n",
        "### Step 3: View the Sentiment in Action:\n",
        "- When a user expresses frustration (e.g., “I’m upset with the shipping delay”), the bot will detect the negative sentiment and offer to connect to human support.\n",
        "- In neutral or positive cases, the bot proceeds normally.\n",
        "\n",
        "### Customization Ideas:\n",
        "- **Multilingual Support**: `TextBlob` works best with English, but if you're dealing with other languages, you could use a model from Hugging Face for sentiment analysis.\n",
        "- **Advanced Sentiment Detection**: Use more sophisticated models for analyzing complex emotions like sarcasm or varying levels of frustration.\n",
        "\n"
      ],
      "metadata": {
        "id": "s2bSf43zj31m"
      },
      "id": "s2bSf43zj31m"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install textblob"
      ],
      "metadata": {
        "id": "f5VYIqCjg9rv"
      },
      "id": "f5VYIqCjg9rv",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You’ll also need to download the necessary datasets for `TextBlob`\n",
        "# !python -m textblob.download_corpora"
      ],
      "metadata": {
        "id": "sDZrgtEIg9pI"
      },
      "id": "sDZrgtEIg9pI",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from textblob import TextBlob  # For sentiment analysis\n",
        "import json\n",
        "\n",
        "MODEL = 'gpt-4o-mini'\n",
        "system_message = \"You are a helpful customer service assistant for the Stanley store. You assist customers with queries about products, returns, shipping, and orders.\"\n",
        "history_file = \"chat_history.json\"\n",
        "\n",
        "# Function to save chat history to a JSON file\n",
        "def save_chat_history(history, file_path):\n",
        "    with open(file_path, \"w\") as file:\n",
        "        json.dump(history, file, indent=4)\n",
        "\n",
        "# Sample FAQs for the Stanley store\n",
        "faq_responses = {\n",
        "    \"availability\": \"The Stanley Cup is available in multiple colors and sizes, but some items may be out of stock due to high demand. You can check the latest availability on our website.\",\n",
        "    \"returns\": \"You can return any Stanley product within 30 days of purchase. Just visit our Returns page for more details and to start the process.\",\n",
        "    \"shipping\": \"Shipping typically takes between 3-5 business days for standard delivery. Expedited options are also available.\",\n",
        "    \"order tracking\": \"You can track your order by visiting the 'Order Tracking' page on our website. Just enter your order number to get the latest updates.\",\n",
        "    \"human support\": \"I can help you with most questions, but if you need further assistance, I can connect you to a human representative.\"\n",
        "}\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentiment_score = blob.sentiment.polarity  # Returns a score between -1 (negative) and 1 (positive)\n",
        "\n",
        "    if sentiment_score < -0.2:\n",
        "        return \"negative\"\n",
        "    elif sentiment_score > 0.2:\n",
        "        return \"positive\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "# Chat function with sentiment analysis\n",
        "def stanley_chat(message, history):\n",
        "    # System message at the start\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "\n",
        "    # Add the conversation history\n",
        "    for msg in history:\n",
        "        messages.append(msg)\n",
        "\n",
        "    # Analyze the sentiment of the user's message\n",
        "    sentiment = analyze_sentiment(message)\n",
        "\n",
        "    # Add the current user message\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    # Check for common FAQs\n",
        "    response = \"\"\n",
        "    if \"availability\" in message.lower():\n",
        "        response = faq_responses[\"availability\"]\n",
        "    elif \"return\" in message.lower():\n",
        "        response = faq_responses[\"returns\"]\n",
        "    elif \"shipping\" in message.lower():\n",
        "        response = faq_responses[\"shipping\"]\n",
        "    elif \"track\" in message.lower():\n",
        "        response = faq_responses[\"order tracking\"]\n",
        "    elif \"human\" in message.lower() or \"representative\" in message.lower():\n",
        "        response = faq_responses[\"human support\"]\n",
        "    else:\n",
        "        # Use the AI to handle more complex or unknown questions\n",
        "        stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "        for chunk in stream:\n",
        "            response += chunk.choices[0].delta.content or ''\n",
        "\n",
        "    # Modify response based on sentiment analysis\n",
        "    if sentiment == \"negative\":\n",
        "        response += \"\\n\\nI'm sorry if you're feeling frustrated. Would you like to speak to a human representative?\"\n",
        "\n",
        "    return response\n",
        "\n",
        "    # Add the current user message and assistant response to the history\n",
        "    history.append({\"role\": \"user\", \"content\": message})\n",
        "    history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    # Save updated history to a JSON file\n",
        "    save_chat_history(history, history_file)\n",
        "\n",
        "# Gradio interface\n",
        "gr.ChatInterface(fn=stanley_chat, type=\"messages\").launch(share=True)"
      ],
      "metadata": {
        "id": "PaFTKC0ulahQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "d009c4d3-9867-4583-a6e1-320fb3669b14"
      },
      "id": "PaFTKC0ulahQ",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e00c97487ac180c4cf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e00c97487ac180c4cf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from textblob import TextBlob  # For sentiment analysis\n",
        "import json\n",
        "\n",
        "MODEL = 'gpt-4o-mini'\n",
        "system_message = \"You are a helpful customer service assistant for the Stanley store. You assist customers with queries about products, returns, shipping, and orders.\"\n",
        "history_file = \"chat_history.json\"\n",
        "\n",
        "# Function to save chat history to a JSON file\n",
        "def save_chat_history(history, file_path):\n",
        "    with open(file_path, \"w\") as file:\n",
        "        json.dump(history, file, indent=4)\n",
        "\n",
        "# Sample FAQs for the Stanley store\n",
        "faq_responses = {\n",
        "    \"availability\": \"The Stanley Cup is available in multiple colors and sizes, but some items may be out of stock due to high demand. You can check the latest availability on our website.\",\n",
        "    \"returns\": \"You can return any Stanley product within 30 days of purchase. Just visit our Returns page for more details and to start the process.\",\n",
        "    \"shipping\": \"Shipping typically takes between 3-5 business days for standard delivery. Expedited options are also available.\",\n",
        "    \"order tracking\": \"You can track your order by visiting the 'Order Tracking' page on our website. Just enter your order number to get the latest updates.\",\n",
        "    \"human support\": \"I can help you with most questions, but if you need further assistance, I can connect you to a human representative.\"\n",
        "}\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentiment_score = blob.sentiment.polarity  # Returns a score between -1 (negative) and 1 (positive)\n",
        "\n",
        "    if sentiment_score < -0.2:\n",
        "        return \"negative\"\n",
        "    elif sentiment_score > 0.2:\n",
        "        return \"positive\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "# Chat function with sentiment analysis\n",
        "def stanley_chat(message, history):\n",
        "    # System message at the start\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "\n",
        "    # Add the conversation history\n",
        "    for msg in history:\n",
        "        messages.append(msg)\n",
        "\n",
        "    # Analyze the sentiment of the user's message\n",
        "    sentiment = analyze_sentiment(message)\n",
        "\n",
        "    # Add the current user message\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    # Check for common FAQs\n",
        "    response = \"\"\n",
        "    if \"availability\" in message.lower():\n",
        "        response = faq_responses[\"availability\"]\n",
        "    elif \"return\" in message.lower():\n",
        "        response = faq_responses[\"returns\"]\n",
        "    elif \"shipping\" in message.lower():\n",
        "        response = faq_responses[\"shipping\"]\n",
        "    elif \"track\" in message.lower():\n",
        "        response = faq_responses[\"order tracking\"]\n",
        "    elif \"human\" in message.lower() or \"representative\" in message.lower():\n",
        "        response = faq_responses[\"human support\"]\n",
        "    # If no FAQ match, generate response from AI\n",
        "    if not response:\n",
        "        stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "        for chunk in stream:\n",
        "            response += chunk.choices[0].delta.content or ''\n",
        "        # Modify response based on sentiment before yielding\n",
        "        if sentiment == \"negative\":\n",
        "            response += \"\\n\\nI'm sorry if you're feeling frustrated. Would you like to speak to a human representative?\"\n",
        "\n",
        "    # Yield the response (including sentiment modification if applied)\n",
        "    yield response\n",
        "\n",
        "    # Add the current user message and assistant response to the history\n",
        "    history.append({\"role\": \"user\", \"content\": message})\n",
        "    history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    # Save updated history to a JSON file\n",
        "    save_chat_history(history, history_file)\n",
        "\n",
        "# Gradio interface\n",
        "gr.ChatInterface(fn=stanley_chat, type=\"messages\").launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "xfQmfPBGOwpm",
        "outputId": "917832d5-3e71-4ce0-83ef-08cd987c1e09"
      },
      "id": "xfQmfPBGOwpm",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://15a0b38c0472965e96.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://15a0b38c0472965e96.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read Chat Logs"
      ],
      "metadata": {
        "id": "qIGFlKNBNWDU"
      },
      "id": "qIGFlKNBNWDU"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def print_chat_history(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, \"r\") as file:\n",
        "            history = json.load(file)\n",
        "\n",
        "        print(\"\\nChat History:\\n\" + \"=\" * 50)\n",
        "        turn = 1\n",
        "        for msg in history:\n",
        "            if msg[\"role\"] == \"user\":\n",
        "                # print(f\"Turn {turn}:\")\n",
        "                print(f\"User: {msg['content']}\")\n",
        "            elif msg[\"role\"] == \"assistant\":\n",
        "                print(f\"Assistant: {msg['content']}\")\n",
        "                print(\"-\" * 50)\n",
        "                turn += 1\n",
        "    else:\n",
        "        print(\"No chat history found.\")\n",
        "\n",
        "print_chat_history(\"/content/chat_history.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYTsBBybMsSs",
        "outputId": "b0528321-1402-4c66-9ef3-4d5ef2d0ed4c"
      },
      "id": "iYTsBBybMsSs",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chat History:\n",
            "==================================================\n",
            "User: hello\n",
            "Assistant: Hello! How can I assist you today?\n",
            "--------------------------------------------------\n",
            "User: i need help with a return\n",
            "Assistant: You can return any Stanley product within 30 days of purchase. Just visit our Returns page for more details and to start the process.\n",
            "--------------------------------------------------\n",
            "User: I am very unhappy with the product and want my money back\n",
            "Assistant: I’m sorry to hear that you’re unhappy with your product. To initiate a return and get your money back, please follow these steps:\n",
            "\n",
            "1. **Visit the Returns Page:** Go to our Returns portal on the website.\n",
            "2. **Provide Your Order Information:** Enter your order number and the email address used for the purchase.\n",
            "3. **Follow the Instructions:** You will receive the necessary steps to print a return shipping label and details on how to send the product back.\n",
            "\n",
            "Once we receive the returned item, we’ll process your refund promptly. If you need any further assistance or have specific questions about your return, feel free to ask!\n",
            "\n",
            "I'm sorry if you're feeling frustrated. Would you like to speak to a human representative?\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}